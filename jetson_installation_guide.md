# ðŸš€ DEMO_SITLé¡¹ç›®ç§»æ¤åˆ°Jetson Orin Nanoå®Œæ•´æŒ‡å—

## ðŸ“‹ ç›®å½•
1. [ç¡¬ä»¶å‡†å¤‡](#ç¡¬ä»¶å‡†å¤‡)
2. [ç³»ç»Ÿå®‰è£…](#ç³»ç»Ÿå®‰è£…)
3. [çŽ¯å¢ƒé…ç½®](#çŽ¯å¢ƒé…ç½®)
4. [ä¾èµ–å®‰è£…](#ä¾èµ–å®‰è£…)
5. [é¡¹ç›®ç§»æ¤](#é¡¹ç›®ç§»æ¤)
6. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
7. [æµ‹è¯•éªŒè¯](#æµ‹è¯•éªŒè¯)
8. [æ•…éšœæŽ’é™¤](#æ•…éšœæŽ’é™¤)

## ðŸ”§ ç¡¬ä»¶å‡†å¤‡

### Jetson Orin Nanoè§„æ ¼
- **GPU**: 1024 CUDAæ ¸å¿ƒï¼Œ32ä¸ªTensoræ ¸å¿ƒ
- **AIæ€§èƒ½**: 67 TOPS (Sparse), 33 TOPS (Dense)
- **CPU**: 6æ ¸Arm Cortex-A78AE @ 1.7GHz
- **å†…å­˜**: 8GB LPDDR5 @ 102 GB/s
- **å­˜å‚¨**: MicroSD + M.2 NVMe SSDæ”¯æŒ
- **åŠŸè€—**: 7W/15W/25Wå¯è°ƒæ¨¡å¼

### å¿…éœ€ç¡¬ä»¶æ¸…å•
- [ ] Jetson Orin Nanoå¼€å‘æ¿
- [ ] 64GB+ MicroSDå¡ (Class 10, U3)
- [ ] USB-Cç”µæºé€‚é…å™¨ (5V/3A)
- [ ] USBæ‘„åƒå¤´æˆ–CSIæ‘„åƒå¤´
- [ ] æ•£çƒ­å™¨å’Œé£Žæ‰‡
- [ ] ç½‘ç»œè¿žæŽ¥ (ä»¥å¤ªç½‘æˆ–WiFi)

### æŽ¨èé…ç½®
- [ ] M.2 NVMe SSD (256GB+) ç”¨äºŽå­˜å‚¨
- [ ] ä¸»åŠ¨æ•£çƒ­è§£å†³æ–¹æ¡ˆ
- [ ] é«˜è´¨é‡ç”µæºä¾›åº”

## ðŸ’¿ ç³»ç»Ÿå®‰è£…

### Step 1: ä¸‹è½½JetPack SDK
```bash
# è®¿é—®NVIDIAå®˜ç½‘ä¸‹è½½æœ€æ–°JetPack 6.1
# https://developer.nvidia.com/jetpack

# ä½¿ç”¨SDK Managerå®‰è£…ï¼ˆæŽ¨èï¼‰
# æˆ–ä¸‹è½½é¢„æž„å»ºçš„SDå¡é•œåƒ
```

### Step 2: çƒ§å½•ç³»ç»Ÿé•œåƒ
```bash
# ä½¿ç”¨Balena Etcheræˆ–ddå‘½ä»¤çƒ§å½•
# Windows: ä½¿ç”¨Balena Etcher
# Linux: 
sudo dd if=jetpack_image.img of=/dev/sdX bs=1M status=progress
```

### Step 3: é¦–æ¬¡å¯åŠ¨é…ç½®
```bash
# è¿žæŽ¥æ˜¾ç¤ºå™¨ã€é”®ç›˜ã€é¼ æ ‡
# æŒ‰ç…§å‘å¯¼å®Œæˆåˆå§‹è®¾ç½®
# åˆ›å»ºç”¨æˆ·è´¦æˆ·
# è¿žæŽ¥ç½‘ç»œ
```

## âš™ï¸ çŽ¯å¢ƒé…ç½®

### Step 1: ç³»ç»Ÿæ›´æ–°
```bash
# æ›´æ–°ç³»ç»ŸåŒ…
sudo apt update && sudo apt upgrade -y

# å®‰è£…åŸºç¡€å·¥å…·
sudo apt install -y curl wget git vim htop tree
sudo apt install -y build-essential cmake pkg-config
sudo apt install -y python3-pip python3-dev python3-venv
```

### Step 2: è®¾ç½®åŠŸè€—æ¨¡å¼
```bash
# æŸ¥çœ‹å½“å‰åŠŸè€—æ¨¡å¼
sudo nvpmodel -q

# è®¾ç½®ä¸ºæœ€å¤§æ€§èƒ½æ¨¡å¼ (25W)
sudo nvpmodel -m 2

# è®¾ç½®ä¸ºå¹³è¡¡æ¨¡å¼ (15W)
sudo nvpmodel -m 1

# è®¾ç½®ä¸ºçœç”µæ¨¡å¼ (7W)
sudo nvpmodel -m 0

# æŸ¥çœ‹CPUé¢‘çŽ‡
sudo jetson_clocks --show
```

### Step 3: å¯ç”¨æœ€å¤§æ€§èƒ½
```bash
# å¯ç”¨æœ€å¤§æ—¶é’Ÿé¢‘çŽ‡
sudo jetson_clocks

# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version
```

## ðŸ“¦ ä¾èµ–å®‰è£…

### Step 1: PythonçŽ¯å¢ƒ
```bash
# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
python3 -m venv sitl_env
source sitl_env/bin/activate

# å‡çº§pip
pip install --upgrade pip setuptools wheel
```

### Step 2: æ·±åº¦å­¦ä¹ æ¡†æž¶
```bash
# å®‰è£…PyTorch (Jetsonä¸“ç”¨ç‰ˆæœ¬)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# éªŒè¯PyTorchå®‰è£…
python3 -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
```

### Step 3: è®¡ç®—æœºè§†è§‰åº“
```bash
# å®‰è£…OpenCV (é¢„ç¼–è¯‘ç‰ˆæœ¬é€šå¸¸å·²åŒ…å«CUDAæ”¯æŒ)
pip install opencv-python opencv-contrib-python

# éªŒè¯OpenCV CUDAæ”¯æŒ
python3 -c "import cv2; print(f'OpenCVç‰ˆæœ¬: {cv2.__version__}'); print(f'CUDAè®¾å¤‡æ•°: {cv2.cuda.getCudaEnabledDeviceCount()}')"
```

### Step 4: YOLOå’ŒTensorRT
```bash
# å®‰è£…Ultralytics YOLO
pip install ultralytics

# å®‰è£…TensorRT PythonåŒ… (å¦‚æžœæœªé¢„è£…)
pip install tensorrt

# éªŒè¯TensorRT
python3 -c "import tensorrt as trt; print(f'TensorRTç‰ˆæœ¬: {trt.__version__}')"
```

### Step 5: å…¶ä»–ä¾èµ–
```bash
# å®‰è£…é¡¹ç›®ä¾èµ–
pip install numpy pandas matplotlib seaborn
pip install easyocr  # OCRè¯†åˆ«
pip install pymavlink  # MAVLinké€šä¿¡
pip install psutil  # ç³»ç»Ÿç›‘æŽ§
pip install queue-manager  # é˜Ÿåˆ—ç®¡ç†
```

### Step 6: Jetsonä¸“ç”¨åº“
```bash
# å®‰è£…Jetson Inference (å¯é€‰ï¼Œç”¨äºŽé¢å¤–åŠ é€Ÿ)
sudo apt install -y python3-jetson-inference python3-jetson-utils

# éªŒè¯å®‰è£…
python3 -c "import jetson.inference; print('Jetson Inferenceåº“å¯ç”¨')"
```

## ðŸ”„ é¡¹ç›®ç§»æ¤

### Step 1: å¤åˆ¶é¡¹ç›®æ–‡ä»¶
```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p ~/sitl_mission
cd ~/sitl_mission

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
# - dual_thread_sitl_mission_jetson.py
# - yolo_trt_utils_jetson.py
# - target_geo_calculator.py
# - weights/best1.pt (YOLOæ¨¡åž‹æ–‡ä»¶)
```

### Step 2: åˆ›å»ºé…ç½®æ–‡ä»¶
```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶
cat > config_jetson.py << 'EOF'
#!/usr/bin/env python3
# Jetson Orin Nanoä¼˜åŒ–é…ç½®

JETSON_CONFIG = {
    # æ¨¡åž‹é…ç½®
    'model_path': 'weights/best1.pt',
    'confidence_threshold': 0.25,
    'use_tensorrt': True,
    
    # é˜Ÿåˆ—é…ç½®
    'detection_queue_size': 300,
    'result_queue_size': 150,
    'queue_wait_timeout': 3.0,
    
    # æ€§èƒ½é…ç½®
    'max_fps': 30,
    'memory_cleanup_interval': 50,
    'thermal_check_interval': 100,
    
    # åŠŸè€—é…ç½®
    'power_mode': 'balanced',  # power_save, balanced, performance
    
    # æ‘„åƒå¤´é…ç½®
    'camera_width': 1920,
    'camera_height': 1080,
    'camera_fps': 30,
    
    # æ˜¾ç¤ºé…ç½®
    'display_width': 1280,
    'display_height': 720,
}
EOF
```

### Step 3: åˆ›å»ºå¯åŠ¨è„šæœ¬
```bash
# åˆ›å»ºå¯åŠ¨è„šæœ¬
cat > run_sitl_jetson.sh << 'EOF'
#!/bin/bash
# Jetson SITLä»»åŠ¡å¯åŠ¨è„šæœ¬

echo "ðŸš€ å¯åŠ¨Jetson SITLä»»åŠ¡ç³»ç»Ÿ"

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
source sitl_env/bin/activate

# è®¾ç½®çŽ¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
export OPENCV_DNN_BACKEND=CUDA
export OPENCV_DNN_TARGET=CUDA

# æ£€æŸ¥GPUçŠ¶æ€
echo "GPUçŠ¶æ€:"
nvidia-smi

# è®¾ç½®åŠŸè€—æ¨¡å¼
echo "è®¾ç½®åŠŸè€—æ¨¡å¼ä¸ºå¹³è¡¡æ¨¡å¼..."
sudo nvpmodel -m 1

# å¯ç”¨æœ€å¤§æ—¶é’Ÿé¢‘çŽ‡
echo "å¯ç”¨æœ€å¤§æ—¶é’Ÿé¢‘çŽ‡..."
sudo jetson_clocks

# è¿è¡Œç¨‹åº
echo "å¯åŠ¨SITLä»»åŠ¡..."
python3 dual_thread_sitl_mission_jetson.py

echo "ä»»åŠ¡å®Œæˆ"
EOF

chmod +x run_sitl_jetson.sh
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### Step 1: TensorRTæ¨¡åž‹è½¬æ¢
```python
# è½¬æ¢YOLOæ¨¡åž‹ä¸ºTensorRTå¼•æ“Ž
from ultralytics import YOLO

# åŠ è½½æ¨¡åž‹
model = YOLO('weights/best1.pt')

# å¯¼å‡ºä¸ºTensorRTå¼•æ“Ž
model.export(
    format='engine',
    device=0,
    half=True,  # ä½¿ç”¨FP16ç²¾åº¦
    workspace=4,  # GB
    verbose=True
)

print("âœ… TensorRTå¼•æ“Žè½¬æ¢å®Œæˆ")
```

### Step 2: ç³»ç»Ÿä¼˜åŒ–è„šæœ¬
```bash
# åˆ›å»ºä¼˜åŒ–è„šæœ¬
cat > optimize_jetson.sh << 'EOF'
#!/bin/bash
# Jetsonç³»ç»Ÿä¼˜åŒ–è„šæœ¬

echo "ðŸ”§ ä¼˜åŒ–Jetsonç³»ç»Ÿæ€§èƒ½..."

# è®¾ç½®æœ€å¤§æ€§èƒ½æ¨¡å¼
sudo nvpmodel -m 2
sudo jetson_clocks

# ä¼˜åŒ–å†…å­˜ç®¡ç†
echo 1 | sudo tee /proc/sys/vm/overcommit_memory
echo 50 | sudo tee /proc/sys/vm/swappiness

# ä¼˜åŒ–ç½‘ç»œ
echo 'net.core.rmem_max = 134217728' | sudo tee -a /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' | sudo tee -a /etc/sysctl.conf

# ä¼˜åŒ–æ–‡ä»¶ç³»ç»Ÿ
echo 'vm.dirty_ratio = 5' | sudo tee -a /etc/sysctl.conf
echo 'vm.dirty_background_ratio = 2' | sudo tee -a /etc/sysctl.conf

# åº”ç”¨è®¾ç½®
sudo sysctl -p

echo "âœ… ç³»ç»Ÿä¼˜åŒ–å®Œæˆ"
EOF

chmod +x optimize_jetson.sh
```

### Step 3: æ¸©åº¦ç›‘æŽ§è„šæœ¬
```bash
# åˆ›å»ºæ¸©åº¦ç›‘æŽ§è„šæœ¬
cat > monitor_temp.sh << 'EOF'
#!/bin/bash
# Jetsonæ¸©åº¦ç›‘æŽ§è„šæœ¬

while true; do
    echo "=== $(date) ==="
    echo "CPUæ¸©åº¦: $(cat /sys/class/thermal/thermal_zone0/temp | awk '{print $1/1000}')Â°C"
    echo "GPUæ¸©åº¦: $(cat /sys/class/thermal/thermal_zone1/temp | awk '{print $1/1000}')Â°C"
    echo "åŠŸè€—æ¨¡å¼: $(sudo nvpmodel -q | grep 'NV Power Mode')"
    echo "å†…å­˜ä½¿ç”¨: $(free -h | grep Mem)"
    echo "GPUçŠ¶æ€:"
    nvidia-smi --query-gpu=temperature.gpu,utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits
    echo "------------------------"
    sleep 5
done
EOF

chmod +x monitor_temp.sh
```

## ðŸ§ª æµ‹è¯•éªŒè¯

### Step 1: åŸºç¡€åŠŸèƒ½æµ‹è¯•
```bash
# æµ‹è¯•PythonçŽ¯å¢ƒ
python3 -c "
import torch
import cv2
import numpy as np
import tensorrt as trt
print('âœ… æ‰€æœ‰ä¾èµ–åº“å¯¼å…¥æˆåŠŸ')
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'OpenCVç‰ˆæœ¬: {cv2.__version__}')
print(f'TensorRTç‰ˆæœ¬: {trt.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
"
```

### Step 2: YOLOæ¨¡åž‹æµ‹è¯•
```python
# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > test_yolo_jetson.py << 'EOF'
#!/usr/bin/env python3
import time
import cv2
from yolo_trt_utils_jetson import YOLOTRTDetectorJetson

def test_yolo():
    print("ðŸ§ª æµ‹è¯•YOLOæ£€æµ‹å™¨...")
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = YOLOTRTDetectorJetson(
        model_path='weights/best1.pt',
        use_trt=True
    )
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = cv2.imread('test_image.jpg')  # éœ€è¦å‡†å¤‡æµ‹è¯•å›¾åƒ
    if test_image is None:
        # åˆ›å»ºéšæœºæµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
    
    # é¢„çƒ­
    detector.warmup()
    
    # æµ‹è¯•æ£€æµ‹
    start_time = time.time()
    detections = detector.detect(test_image)
    end_time = time.time()
    
    print(f"æ£€æµ‹ç»“æžœ: {len(detections)}ä¸ªç›®æ ‡")
    print(f"æŽ¨ç†æ—¶é—´: {(end_time - start_time)*1000:.1f}ms")
    
    # æ€§èƒ½ç»Ÿè®¡
    stats = detector.get_performance_stats()
    print(f"å¹³å‡FPS: {stats.get('fps', 0):.1f}")
    print(f"ä½¿ç”¨TensorRT: {stats.get('using_tensorrt', False)}")
    
    print("âœ… YOLOæµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_yolo()
EOF
```

### Step 3: å®Œæ•´ç³»ç»Ÿæµ‹è¯•
```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python3 dual_thread_sitl_mission_jetson.py

# ç›‘æŽ§ç³»ç»Ÿæ€§èƒ½
./monitor_temp.sh &

# è¿è¡Œä¸€æ®µæ—¶é—´åŽæ£€æŸ¥ç»“æžœ
```

## ðŸ”§ æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. CUDAå†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘æ‰¹å¤„ç†å¤§å°ï¼Œå¯ç”¨å†…å­˜ä¼˜åŒ–
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# æˆ–åœ¨ä»£ç ä¸­è®¾ç½®
torch.cuda.empty_cache()
```

#### 2. TensorRTè½¬æ¢å¤±è´¥
```bash
# æ£€æŸ¥TensorRTç‰ˆæœ¬å…¼å®¹æ€§
python3 -c "import tensorrt as trt; print(trt.__version__)"

# æ›´æ–°åˆ°å…¼å®¹ç‰ˆæœ¬
pip install --upgrade tensorrt
```

#### 3. æ¸©åº¦è¿‡é«˜å¯¼è‡´é™é¢‘
```bash
# æ£€æŸ¥æ•£çƒ­å™¨å®‰è£…
# é™ä½ŽåŠŸè€—æ¨¡å¼
sudo nvpmodel -m 1  # 15Wæ¨¡å¼

# æˆ–æ·»åŠ å»¶æ—¶
# åœ¨ä»£ç ä¸­æ·»åŠ  time.sleep(0.1)
```

#### 4. æ‘„åƒå¤´æ— æ³•æ‰“å¼€
```bash
# æ£€æŸ¥æ‘„åƒå¤´è®¾å¤‡
ls /dev/video*

# æµ‹è¯•æ‘„åƒå¤´
v4l2-ctl --list-devices

# ä½¿ç”¨GStreamerç®¡é“ (CSIæ‘„åƒå¤´)
# ä¿®æ”¹video_sourceä¸ºGStreamerç®¡é“å­—ç¬¦ä¸²
```

#### 5. å†…å­˜æ³„æ¼
```bash
# ç›‘æŽ§å†…å­˜ä½¿ç”¨
watch -n 1 free -h

# åœ¨ä»£ç ä¸­å®šæœŸæ¸…ç†
gc.collect()
torch.cuda.empty_cache()
```

## ðŸ“Š æ€§èƒ½åŸºå‡†

### é¢„æœŸæ€§èƒ½æŒ‡æ ‡

| é…ç½® | FPS | åŠŸè€— | æ¸©åº¦ |
|------|-----|------|------|
| 7Wæ¨¡å¼ | 15-20 | 7W | 60-70Â°C |
| 15Wæ¨¡å¼ | 25-30 | 15W | 70-80Â°C |
| 25Wæ¨¡å¼ | 30-35 | 25W | 80-85Â°C |

### ä¼˜åŒ–åŽæ€§èƒ½
- **YOLOæŽ¨ç†**: 20-30ms (FP16)
- **å›¾åƒè½¬æ­£**: 5-10ms
- **OCRè¯†åˆ«**: 50-100ms
- **æ€»å¤„ç†å»¶è¿Ÿ**: <150ms
- **å†…å­˜ä½¿ç”¨**: <6GB
- **å­˜å‚¨éœ€æ±‚**: 2-5GB

## ðŸŽ¯ éƒ¨ç½²å»ºè®®

### ç”Ÿäº§çŽ¯å¢ƒé…ç½®
1. **ä½¿ç”¨NVMe SSD**: æé«˜I/Oæ€§èƒ½
2. **ä¸»åŠ¨æ•£çƒ­**: ç¡®ä¿ç¨³å®šè¿è¡Œ
3. **UPSç”µæº**: é˜²æ­¢æ„å¤–æ–­ç”µ
4. **ç½‘ç»œç›‘æŽ§**: è¿œç¨‹ç›‘æŽ§ç³»ç»ŸçŠ¶æ€
5. **è‡ªåŠ¨é‡å¯**: å¼‚å¸¸æƒ…å†µä¸‹è‡ªåŠ¨æ¢å¤

### ç»´æŠ¤å»ºè®®
1. **å®šæœŸæ¸…ç†**: æ¸…ç†ç°å°˜ï¼Œæ£€æŸ¥æ•£çƒ­
2. **ç³»ç»Ÿæ›´æ–°**: å®šæœŸæ›´æ–°JetPackå’Œä¾èµ–
3. **æ€§èƒ½ç›‘æŽ§**: ç›‘æŽ§æ¸©åº¦ã€åŠŸè€—ã€æ€§èƒ½
4. **æ•°æ®å¤‡ä»½**: å®šæœŸå¤‡ä»½é‡è¦æ•°æ®
5. **æ—¥å¿—è®°å½•**: è®°å½•ç³»ç»Ÿè¿è¡Œæ—¥å¿—

---

## ðŸ“ž æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. ç¡¬ä»¶è¿žæŽ¥æ˜¯å¦æ­£ç¡®
2. è½¯ä»¶ç‰ˆæœ¬æ˜¯å¦å…¼å®¹
3. ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³
4. æ¸©åº¦æ˜¯å¦æ­£å¸¸
5. æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯ä¿¡æ¯

**ç§»æ¤å®ŒæˆåŽï¼Œæ‚¨å°†æ‹¥æœ‰ä¸€ä¸ªåœ¨Jetson Orin Nanoä¸Šé«˜æ•ˆè¿è¡Œçš„å®žæ—¶ç›®æ ‡æ£€æµ‹å’Œå¤„ç†ç³»ç»Ÿï¼** ðŸš€ 