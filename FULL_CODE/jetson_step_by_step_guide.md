# Jetson Orin Nano é…ç½®æ“ä½œæŒ‡å— - ä¸€æ­¥æ­¥æ•™ç¨‹

## ğŸ¯ å¼€å§‹ä¹‹å‰çš„å‡†å¤‡å·¥ä½œ

### æ£€æŸ¥æ‚¨çš„ç¡¬ä»¶å’Œç³»ç»Ÿ
```bash
# 1. æ£€æŸ¥Jetsonå‹å·å’ŒJetPackç‰ˆæœ¬
cat /etc/nv_tegra_release

# 2. æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
uname -a
lsb_release -a

# 3. æ£€æŸ¥å¯ç”¨ç©ºé—´ï¼ˆè‡³å°‘éœ€è¦10GBï¼‰
df -h

# 4. æ£€æŸ¥å†…å­˜
free -h
```

**é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š**
```
# Tegraç‰ˆæœ¬åº”è¯¥æ˜¾ç¤ºç±»ä¼¼ï¼šR35 (release), REVISION: 4.1
# Ubuntuç‰ˆæœ¬åº”è¯¥æ˜¯20.04 LTS
# å¯ç”¨ç©ºé—´åº”è¯¥å¤§äº10GB
```

---

## ğŸ“‹ ç¬¬ä¸€æ­¥ï¼šç³»ç»ŸåŸºç¡€é…ç½®

### 1.1 æ›´æ–°ç³»ç»ŸåŒ…
```bash
# æ›´æ–°åŒ…åˆ—è¡¨
sudo apt update

# å‡çº§æ‰€æœ‰åŒ…ï¼ˆè¿™å¯èƒ½éœ€è¦5-10åˆ†é’Ÿï¼‰
sudo apt upgrade -y

# å®‰è£…åŸºç¡€å·¥å…·
sudo apt install -y curl wget git vim htop tree build-essential
```

**éªŒè¯ï¼š**
```bash
# æ£€æŸ¥å·¥å…·æ˜¯å¦å®‰è£…æˆåŠŸ
git --version
curl --version
```

### 1.2 è®¾ç½®æ€§èƒ½æ¨¡å¼
```bash
# æŸ¥çœ‹å½“å‰åŠŸè€—æ¨¡å¼
sudo nvpmodel -q

# è®¾ç½®ä¸ºæœ€å¤§æ€§èƒ½æ¨¡å¼ï¼ˆæ¨¡å¼0 - MAXNï¼‰
sudo nvpmodel -m 0

# é”å®šæœ€é«˜æ—¶é’Ÿé¢‘ç‡
sudo jetson_clocks

# éªŒè¯è®¾ç½®ï¼ˆè®©å®ƒè¿è¡Œå‡ ç§’é’Ÿç„¶åæŒ‰Ctrl+Cåœæ­¢ï¼‰
sudo tegrastats
```

**é¢„æœŸè¾“å‡ºï¼š**
```
NV Power Mode: MAXN
```

---

## ğŸ ç¬¬äºŒæ­¥ï¼šå®‰è£…Condaï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰

### 2.1 æ£€æŸ¥æ˜¯å¦å·²å®‰è£…Conda
```bash
# æ£€æŸ¥condaæ˜¯å¦å­˜åœ¨
conda --version
```

### 2.2 å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œä¸‹è½½å¹¶å®‰è£…Miniconda
```bash
# ä¸‹è½½Miniconda for ARM64
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh

# å®‰è£…Miniconda
bash Miniconda3-latest-Linux-aarch64.sh

# é‡æ–°åŠ è½½bashé…ç½®
source ~/.bashrc

# éªŒè¯å®‰è£…
conda --version
```

**éªŒè¯ï¼š**
```bash
# åº”è¯¥æ˜¾ç¤ºcondaç‰ˆæœ¬å·ï¼Œå¦‚ï¼šconda 23.x.x
```

---

## ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºå’Œé…ç½®Condaç¯å¢ƒ

### 3.1 åˆ›å»ºä¸“ç”¨ç¯å¢ƒ
```bash
# åˆ›å»ºåä¸ºjetson_yoloçš„ç¯å¢ƒ
conda create -n jetson_yolo python=3.8 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate jetson_yolo

# éªŒè¯ç¯å¢ƒ
python --version
which python
```

**éªŒè¯ï¼š**
```bash
# Pythonç‰ˆæœ¬åº”è¯¥æ˜¾ç¤ºï¼šPython 3.8.x
# è·¯å¾„åº”è¯¥åŒ…å«ï¼š/miniconda3/envs/jetson_yolo/
```

### 3.2 å®‰è£…åŸºç¡€ç§‘å­¦è®¡ç®—åŒ…
```bash
# ä½¿ç”¨condaå®‰è£…åŸºç¡€åŒ…
conda install -y numpy=1.21.0 scipy matplotlib pillow scikit-image seaborn

# éªŒè¯å®‰è£…
python -c "import numpy; print('NumPyç‰ˆæœ¬:', numpy.__version__)"
python -c "import scipy; print('SciPyç‰ˆæœ¬:', scipy.__version__)"
python -c "import matplotlib; print('Matplotlibç‰ˆæœ¬:', matplotlib.__version__)"
```

**é¢„æœŸè¾“å‡ºï¼š**
```
NumPyç‰ˆæœ¬: 1.21.0
SciPyç‰ˆæœ¬: 1.x.x
Matplotlibç‰ˆæœ¬: 3.x.x
```

---

## ğŸ”¥ ç¬¬å››æ­¥ï¼šå®‰è£…CUDAå’Œæ·±åº¦å­¦ä¹ æ¡†æ¶

### 4.1 éªŒè¯CUDAç¯å¢ƒ
```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥CUDAè·¯å¾„
ls /usr/local/cuda/

# è®¾ç½®CUDAç¯å¢ƒå˜é‡
echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc
echo 'export PATH=$PATH:$CUDA_HOME/bin' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_HOME/lib64' >> ~/.bashrc
source ~/.bashrc
```

### 4.2 å®‰è£…ç³»ç»Ÿä¾èµ–
```bash
# å®‰è£…PyTorchç¼–è¯‘ä¾èµ–
sudo apt install -y libopenblas-base libopenmpi-dev libomp-dev

# å®‰è£…å›¾åƒå¤„ç†ä¾èµ–
sudo apt install -y libjpeg-dev zlib1g-dev

# å®‰è£…OCRç›¸å…³ä¾èµ–
sudo apt install -y libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1
```

### 4.3 ä¸‹è½½å¹¶å®‰è£…PyTorch for Jetson
```bash
# ç¡®ä¿åœ¨jetson_yoloç¯å¢ƒä¸­
conda activate jetson_yolo

# ä¸‹è½½PyTorch wheelæ–‡ä»¶ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰
wget https://nvidia.box.com/shared/static/mp164asf3sceb570wvjsrezk1p4ftj8t.whl -O torch-2.0.0-cp38-cp38-linux_aarch64.whl

# å®‰è£…PyTorch
pip install torch-2.0.0-cp38-cp38-linux_aarch64.whl

# éªŒè¯PyTorchå®‰è£…
python -c "import torch; print('PyTorchç‰ˆæœ¬:', torch.__version__)"
python -c "import torch; print('CUDAå¯ç”¨:', torch.cuda.is_available())"
python -c "import torch; print('CUDAè®¾å¤‡æ•°:', torch.cuda.device_count())"
```

**é¢„æœŸè¾“å‡ºï¼š**
```
PyTorchç‰ˆæœ¬: 2.0.0+nv23.05
CUDAå¯ç”¨: True
CUDAè®¾å¤‡æ•°: 1
```

### 4.4 å®‰è£…torchvision
```bash
# å…‹éš†torchvisionæºç 
git clone --branch v0.15.1 https://github.com/pytorch/vision torchvision

# è¿›å…¥ç›®å½•å¹¶ç¼–è¯‘å®‰è£…ï¼ˆè¿™å¯èƒ½éœ€è¦10-15åˆ†é’Ÿï¼‰
cd torchvision
export BUILD_VERSION=0.15.1
python setup.py install --user

# è¿”å›ä¸Šçº§ç›®å½•
cd ..

# éªŒè¯torchvision
python -c "import torchvision; print('torchvisionç‰ˆæœ¬:', torchvision.__version__)"
```

### 4.5 é…ç½®TensorRTï¼ˆé‡è¦ï¼ï¼‰

#### 4.5.1 éªŒè¯TensorRTå®‰è£…
```bash
# æ£€æŸ¥TensorRTæ˜¯å¦å·²å®‰è£…ï¼ˆJetPacké€šå¸¸é¢„è£…ï¼‰
dpkg -l | grep tensorrt

# æ£€æŸ¥TensorRTç‰ˆæœ¬
/usr/src/tensorrt/bin/trtexec --help | head -5

# éªŒè¯Python TensorRTç»‘å®š
python -c "import tensorrt; print('TensorRTç‰ˆæœ¬:', tensorrt.__version__)"
```

#### 4.5.2 å®‰è£…TensorRT Pythonä¾èµ–
```bash
# ç¡®ä¿åœ¨jetson_yoloç¯å¢ƒä¸­
conda activate jetson_yolo

# å®‰è£…pycudaï¼ˆTensorRTæ¨ç†å¿…éœ€ï¼‰
pip install pycuda

# å®‰è£…torch2trtï¼ˆPyTorchåˆ°TensorRTè½¬æ¢å·¥å…·ï¼‰
git clone https://github.com/NVIDIA-AI-IOT/torch2trt
cd torch2trt
python setup.py install --user
cd ..

# éªŒè¯torch2trtå®‰è£…
python -c "import torch2trt; print('âœ… torch2trtå®‰è£…æˆåŠŸ')"
```

#### 4.5.3 æµ‹è¯•TensorRTåŠŸèƒ½
```bash
# åˆ›å»ºTensorRTæµ‹è¯•è„šæœ¬
cat << 'EOF' > test_tensorrt.py
import torch
import tensorrt as trt
import numpy as np
import time

print("âš¡ æµ‹è¯•TensorRTåŠŸèƒ½...")

# æ£€æŸ¥TensorRTç‰ˆæœ¬
print(f"TensorRTç‰ˆæœ¬: {trt.__version__}")

# æµ‹è¯•åŸºæœ¬TensorRTåŠŸèƒ½
try:
    # åˆ›å»ºTensorRT Logger
    logger = trt.Logger(trt.Logger.WARNING)
    
    # åˆ›å»ºBuilder
    builder = trt.Builder(logger)
    print("âœ… TensorRT Builderåˆ›å»ºæˆåŠŸ")
    
    # åˆ›å»ºNetwork
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    print("âœ… TensorRT Networkåˆ›å»ºæˆåŠŸ")
    
    print("âœ… TensorRTåŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
except Exception as e:
    print(f"âŒ TensorRTæµ‹è¯•å¤±è´¥: {e}")

# æµ‹è¯•torch2trtè½¬æ¢
print("\nğŸ”„ æµ‹è¯•torch2trtè½¬æ¢...")
try:
    from torch2trt import torch2trt
    
    # åˆ›å»ºç®€å•æ¨¡å‹
    class SimpleModel(torch.nn.Module):
        def __init__(self):
            super(SimpleModel, self).__init__()
            self.conv = torch.nn.Conv2d(3, 16, 3, padding=1)
            
        def forward(self, x):
            return torch.relu(self.conv(x))
    
    # åˆ›å»ºæ¨¡å‹å’Œç¤ºä¾‹è¾“å…¥
    model = SimpleModel().eval().cuda()
    x = torch.randn(1, 3, 224, 224).cuda()
    
    # è½¬æ¢ä¸ºTensorRT
    print("ğŸ”„ æ­£åœ¨è½¬æ¢æ¨¡å‹åˆ°TensorRT...")
    model_trt = torch2trt(model, [x], fp16_mode=True)
    print("âœ… æ¨¡å‹è½¬æ¢æˆåŠŸ")
    
    # æ¯”è¾ƒæ¨ç†æ—¶é—´
    # åŸå§‹PyTorchæ¨ç†
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(100):
        with torch.no_grad():
            y_torch = model(x)
    torch.cuda.synchronize()
    time_torch = (time.time() - start) / 100
    
    # TensorRTæ¨ç†
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(100):
        y_trt = model_trt(x)
    torch.cuda.synchronize()
    time_trt = (time.time() - start) / 100
    
    print(f"â±ï¸  PyTorchæ¨ç†æ—¶é—´: {time_torch*1000:.2f}ms")
    print(f"âš¡ TensorRTæ¨ç†æ—¶é—´: {time_trt*1000:.2f}ms")
    print(f"ğŸš€ åŠ é€Ÿæ¯”: {time_torch/time_trt:.2f}x")
    
    # éªŒè¯è¾“å‡ºä¸€è‡´æ€§
    max_diff = torch.max(torch.abs(y_torch - y_trt)).item()
    print(f"ğŸ“Š æœ€å¤§è¾“å‡ºå·®å¼‚: {max_diff:.6f}")
    
    if max_diff < 1e-3:
        print("âœ… è¾“å‡ºä¸€è‡´æ€§éªŒè¯é€šè¿‡")
    else:
        print("âš ï¸  è¾“å‡ºå­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œè¯·æ£€æŸ¥")
        
except Exception as e:
    print(f"âŒ torch2trtæµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\nğŸ‰ TensorRTæµ‹è¯•å®Œæˆ")
EOF

# è¿è¡ŒTensorRTæµ‹è¯•
python test_tensorrt.py
```

#### 4.5.4 å®‰è£…YOLO TensorRTæ”¯æŒ
```bash
# å®‰è£…YOLOv5çš„TensorRTå¯¼å‡ºä¾èµ–
pip install onnx onnxruntime-gpu

# å…‹éš†YOLOv5ä»“åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
if [ ! -d "yolov5" ]; then
    git clone https://github.com/ultralytics/yolov5.git
fi

# æµ‹è¯•ONNXå¯¼å‡ºåŠŸèƒ½
cd yolov5
python export.py --weights yolov5s.pt --include onnx --device 0
cd ..
```

**é¢„æœŸè¾“å‡ºï¼š**
```
TensorRTç‰ˆæœ¬: 8.5.x
âœ… TensorRT Builderåˆ›å»ºæˆåŠŸ
âœ… TensorRT Networkåˆ›å»ºæˆåŠŸ
ğŸš€ åŠ é€Ÿæ¯”: 2.0xä»¥ä¸Š
```

---

## ğŸ“· ç¬¬äº”æ­¥ï¼šé…ç½®OpenCVå’Œæ‘„åƒå¤´

### 5.1 éªŒè¯OpenCV
```bash
# æ£€æŸ¥ç³»ç»ŸOpenCVç‰ˆæœ¬
python -c "import cv2; print('OpenCVç‰ˆæœ¬:', cv2.__version__)"
python -c "import cv2; print('CUDAè®¾å¤‡æ•°é‡:', cv2.cuda.getCudaEnabledDeviceCount())"
```

### 5.2 æµ‹è¯•æ‘„åƒå¤´
```bash
# åˆ›å»ºæ‘„åƒå¤´æµ‹è¯•è„šæœ¬
cat << 'EOF' > test_camera.py
import cv2
import sys

print("ğŸ” æµ‹è¯•æ‘„åƒå¤´è¿æ¥...")

# æµ‹è¯•USBæ‘„åƒå¤´
cap = cv2.VideoCapture(0)
if cap.isOpened():
    print("âœ… USBæ‘„åƒå¤´ (ç´¢å¼•0) å¯ç”¨")
    ret, frame = cap.read()
    if ret:
        print(f"âœ… å›¾åƒå°ºå¯¸: {frame.shape}")
        print("âœ… æ‘„åƒå¤´æµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ æ— æ³•è¯»å–å›¾åƒ")
    cap.release()
else:
    print("âŒ USBæ‘„åƒå¤´ä¸å¯ç”¨ï¼Œå°è¯•å…¶ä»–ç´¢å¼•...")
    # å°è¯•å…¶ä»–æ‘„åƒå¤´ç´¢å¼•
    for i in range(1, 4):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            print(f"âœ… æ‰¾åˆ°æ‘„åƒå¤´åœ¨ç´¢å¼• {i}")
            cap.release()
            break
    else:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„USBæ‘„åƒå¤´")

print("ğŸ“· æ‘„åƒå¤´æµ‹è¯•å®Œæˆ")
EOF

# è¿è¡Œæµ‹è¯•
python test_camera.py
```

---

## ğŸ”¤ ç¬¬å…­æ­¥ï¼šå®‰è£…OCRç¯å¢ƒ

### 6.1 å®‰è£…EasyOCR
```bash
# å®‰è£…EasyOCR
pip install easyocr

# éªŒè¯å®‰è£…
python -c "import easyocr; print('âœ… EasyOCRå¯¼å…¥æˆåŠŸ')"
```

### 6.2 é¢„ä¸‹è½½OCRæ¨¡å‹
```bash
# åˆ›å»ºOCRæµ‹è¯•è„šæœ¬
cat << 'EOF' > test_ocr.py
import easyocr
import numpy as np
import time

print("ğŸ”¤ åˆå§‹åŒ–EasyOCR...")
start_time = time.time()

try:
    # å°è¯•GPUæ¨¡å¼
    reader = easyocr.Reader(['en'], gpu=True, download_enabled=True)
    print("âœ… EasyOCR GPUæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âš ï¸  GPUæ¨¡å¼å¤±è´¥: {e}")
    try:
        # å›é€€åˆ°CPUæ¨¡å¼
        reader = easyocr.Reader(['en'], gpu=False, download_enabled=True)
        print("âœ… EasyOCR CPUæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
        exit(1)

init_time = time.time() - start_time
print(f"â±ï¸  åˆå§‹åŒ–ç”¨æ—¶: {init_time:.2f}ç§’")

# æµ‹è¯•è¯†åˆ«
print("ğŸ§ª æµ‹è¯•OCRè¯†åˆ«...")
test_image = np.ones((100, 300, 3), dtype=np.uint8) * 255
results = reader.readtext(test_image)
print("âœ… OCRæµ‹è¯•å®Œæˆ")
print("ğŸ‰ EasyOCRé…ç½®æˆåŠŸ")
EOF

# è¿è¡Œæµ‹è¯•ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œéœ€è¦å‡ åˆ†é’Ÿï¼‰
python test_ocr.py
```

---

## ğŸ¯ ç¬¬ä¸ƒæ­¥ï¼šå®‰è£…YOLOç¯å¢ƒ

### 7.1 å®‰è£…YOLOç›¸å…³åŒ…
```bash
# å®‰è£…ultralyticså’Œç›¸å…³ä¾èµ–
pip install ultralytics
pip install seaborn thop

# å®‰è£…å…¶ä»–å¿…éœ€åŒ…
pip install pyclipper shapely pymavlink pycuda
```

### 7.2 æµ‹è¯•YOLOç¯å¢ƒ
```bash
# åˆ›å»ºYOLOæµ‹è¯•è„šæœ¬
cat << 'EOF' > test_yolo.py
import torch
import numpy as np
import time

print("ğŸ¯ æµ‹è¯•YOLOç¯å¢ƒ...")

# æ£€æŸ¥åŸºæœ¬ä¿¡æ¯
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

# æµ‹è¯•GPUæ¨ç†
print("ğŸ§ª æµ‹è¯•GPUæ¨ç†æ€§èƒ½...")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åˆ›å»ºæµ‹è¯•å¼ é‡
x = torch.randn(1, 3, 640, 640).to(device)

# æµ‹è¯•æ¨ç†é€Ÿåº¦
start_time = time.time()
for i in range(10):
    y = torch.nn.functional.relu(x)
    if torch.cuda.is_available():
        torch.cuda.synchronize()
inference_time = (time.time() - start_time) / 10
print(f"â±ï¸  å¹³å‡æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")

print("âœ… YOLOç¯å¢ƒæµ‹è¯•æˆåŠŸ")
EOF

# è¿è¡Œæµ‹è¯•
python test_yolo.py
```

---

## ğŸ”§ ç¬¬å…«æ­¥ï¼šç³»ç»Ÿä¼˜åŒ–é…ç½®

### 8.1 å¢åŠ Swapç©ºé—´ï¼ˆé‡è¦ï¼ï¼‰
```bash
# æ£€æŸ¥å½“å‰swap
free -h

# åˆ›å»º4GB swapæ–‡ä»¶
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# è®¾ç½®å¼€æœºè‡ªåŠ¨æŒ‚è½½
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab

# éªŒè¯swap
free -h
swapon --show
```

### 8.2 è®¾ç½®æ°¸ä¹…æ€§èƒ½æ¨¡å¼
```bash
# åˆ›å»ºå¼€æœºè‡ªåŠ¨è®¾ç½®è„šæœ¬
sudo tee /etc/systemd/system/jetson-performance.service << 'EOF'
[Unit]
Description=Jetson Performance Mode
After=multi-user.target

[Service]
Type=oneshot
ExecStart=/usr/sbin/nvpmodel -m 0
ExecStart=/usr/bin/jetson_clocks
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target
EOF

# å¯ç”¨æœåŠ¡
sudo systemctl enable jetson-performance.service
sudo systemctl start jetson-performance.service

# éªŒè¯æœåŠ¡çŠ¶æ€
sudo systemctl status jetson-performance.service
```

---

## ğŸ§ª ç¬¬ä¹æ­¥ï¼šå®Œæ•´ç¯å¢ƒæµ‹è¯•

### 9.1 åˆ›å»ºç»¼åˆæµ‹è¯•è„šæœ¬
```bash
cat << 'EOF' > final_test.py
#!/usr/bin/env python3
import sys
import time
import traceback

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„åŒ…å¯¼å…¥"""
    print("ğŸ“¦ æµ‹è¯•åŒ…å¯¼å…¥...")
    
    tests = [
        ("Python", lambda: sys.version),
        ("NumPy", lambda: __import__('numpy').__version__),
        ("SciPy", lambda: __import__('scipy').__version__),
        ("PyTorch", lambda: __import__('torch').__version__),
        ("OpenCV", lambda: __import__('cv2').__version__),
        ("EasyOCR", lambda: __import__('easyocr') and "OK"),
        ("Ultralytics", lambda: __import__('ultralytics') and "OK"),
        ("PyCUDA", lambda: __import__('pycuda') and "OK"),
        ("TensorRT", lambda: __import__('tensorrt').__version__),
        ("torch2trt", lambda: __import__('torch2trt') and "OK"),
    ]
    
    results = {}
    for name, test_func in tests:
        try:
            result = test_func()
            print(f"âœ… {name}: {result}")
            results[name] = True
        except Exception as e:
            print(f"âŒ {name}: {e}")
            results[name] = False
    
    return results

def test_cuda():
    """æµ‹è¯•CUDAåŠŸèƒ½"""
    print("\nğŸ”¥ æµ‹è¯•CUDAåŠŸèƒ½...")
    
    try:
        import torch
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"CUDAè®¾å¤‡æ•°: {torch.cuda.device_count()}")
            print(f"å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
            print(f"è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
            
            # æµ‹è¯•GPUå†…å­˜
            device = torch.device('cuda')
            x = torch.randn(1000, 1000).to(device)
            y = torch.mm(x, x.t())
            print("âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ")
            return True
    except Exception as e:
        print(f"âŒ CUDAæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_camera():
    """æµ‹è¯•æ‘„åƒå¤´"""
    print("\nğŸ“· æµ‹è¯•æ‘„åƒå¤´...")
    
    try:
        import cv2
        cap = cv2.VideoCapture(0)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret:
                print(f"âœ… æ‘„åƒå¤´å·¥ä½œæ­£å¸¸ï¼Œå›¾åƒå°ºå¯¸: {frame.shape}")
                cap.release()
                return True
            else:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´å›¾åƒ")
                cap.release()
                return False
        else:
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return False
    except Exception as e:
        print(f"âŒ æ‘„åƒå¤´æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ocr():
    """æµ‹è¯•OCRåŠŸèƒ½"""
    print("\nğŸ”¤ æµ‹è¯•OCRåŠŸèƒ½...")
    
    try:
        import easyocr
        import numpy as np
        
        # å°è¯•GPUæ¨¡å¼
        try:
            reader = easyocr.Reader(['en'], gpu=True)
            print("âœ… OCR GPUæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
        except:
            reader = easyocr.Reader(['en'], gpu=False)
            print("âœ… OCR CPUæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•è¯†åˆ«
        test_image = np.ones((100, 300, 3), dtype=np.uint8) * 255
        results = reader.readtext(test_image)
        print("âœ… OCRåŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ OCRæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_tensorrt():
    """æµ‹è¯•TensorRTåŠŸèƒ½"""
    print("\nâš¡ æµ‹è¯•TensorRTåŠŸèƒ½...")
    
    try:
        import tensorrt as trt
        import torch
        from torch2trt import torch2trt
        
        print(f"TensorRTç‰ˆæœ¬: {trt.__version__}")
        
        # æµ‹è¯•åŸºæœ¬TensorRTåŠŸèƒ½
        logger = trt.Logger(trt.Logger.WARNING)
        builder = trt.Builder(logger)
        print("âœ… TensorRTåŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        
        # æµ‹è¯•ç®€å•æ¨¡å‹è½¬æ¢
        class TestModel(torch.nn.Module):
            def forward(self, x):
                return torch.relu(x)
        
        model = TestModel().eval().cuda()
        x = torch.randn(1, 3, 32, 32).cuda()
        
        # å¿«é€Ÿè½¬æ¢æµ‹è¯•
        model_trt = torch2trt(model, [x], max_batch_size=1)
        y_trt = model_trt(x)
        
        print("âœ… TensorRTæ¨¡å‹è½¬æ¢å’Œæ¨ç†æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ TensorRTæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    print("ğŸ§ª å¼€å§‹å®Œæ•´ç¯å¢ƒæµ‹è¯•...\n")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    import_results = test_imports()
    cuda_ok = test_cuda()
    camera_ok = test_camera()
    ocr_ok = test_ocr()
    tensorrt_ok = test_tensorrt()
    
    # æ€»ç»“ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("="*50)
    
    total_tests = len(import_results) + 4  # å¯¼å…¥æµ‹è¯• + CUDA + æ‘„åƒå¤´ + OCR + TensorRT
    passed_tests = sum(import_results.values()) + sum([cuda_ok, camera_ok, ocr_ok, tensorrt_ok])
    
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
    print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒé…ç½®æˆåŠŸï¼")
        print("æ‚¨ç°åœ¨å¯ä»¥è¿è¡ŒYOLO+OCRæ¨ç†ä»£ç äº†ã€‚")
    else:
        print(f"\nâš ï¸  æœ‰ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
    
    print("\nğŸ’¡ æ¿€æ´»ç¯å¢ƒå‘½ä»¤: conda activate jetson_yolo")

if __name__ == "__main__":
    main()
EOF

# è¿è¡Œæœ€ç»ˆæµ‹è¯•
python final_test.py
```

---

## âœ… ç¬¬åæ­¥ï¼šéªŒè¯å’Œæ¸…ç†

### 10.1 åˆ›å»ºç¯å¢ƒæ¿€æ´»è„šæœ¬
```bash
# åˆ›å»ºä¾¿æ·çš„ç¯å¢ƒæ¿€æ´»è„šæœ¬
cat << 'EOF' > activate_jetson_env.sh
#!/bin/bash
echo "ğŸš€ æ¿€æ´»Jetson YOLOç¯å¢ƒ..."

# æ¿€æ´»condaç¯å¢ƒ
source $(conda info --base)/etc/profile.d/conda.sh
conda activate jetson_yolo

# æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
echo "âœ… ç¯å¢ƒå·²æ¿€æ´»ï¼š"
echo "Python: $(python --version)"
echo "ç¯å¢ƒè·¯å¾„: $(which python)"

# è®¾ç½®æ€§èƒ½æ¨¡å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
echo "ğŸ”§ æ£€æŸ¥æ€§èƒ½æ¨¡å¼..."
sudo nvpmodel -q

echo "ğŸ¯ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼å¯ä»¥å¼€å§‹è¿è¡Œä»£ç äº†ã€‚"
EOF

chmod +x activate_jetson_env.sh
```

### 10.2 æ¸…ç†ä¸´æ—¶æ–‡ä»¶
```bash
# æ¸…ç†ä¸‹è½½çš„æ–‡ä»¶
rm -f torch-2.0.0-cp38-cp38-linux_aarch64.whl
rm -f Miniconda3-latest-Linux-aarch64.sh

# æ¸…ç†ç¼–è¯‘ç›®å½•ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦èŠ‚çœç©ºé—´ï¼‰
# rm -rf torchvision

echo "ğŸ§¹ æ¸…ç†å®Œæˆ"
```

### 10.3 ä¿å­˜ç¯å¢ƒé…ç½®
```bash
# å¯¼å‡ºcondaç¯å¢ƒé…ç½®
conda env export > jetson_yolo_environment.yml

# åˆ›å»ºpip requirementsæ–‡ä»¶
pip freeze > requirements_jetson.txt

echo "ğŸ’¾ ç¯å¢ƒé…ç½®å·²ä¿å­˜"
```

---

## ğŸ‰ å®Œæˆï¼

**æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†Jetson Orin Nanoçš„å®Œæ•´ç¯å¢ƒé…ç½®ã€‚**

### ä¸‹æ¬¡ä½¿ç”¨æ—¶çš„å¿«é€Ÿå¯åŠ¨ï¼š
```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate jetson_yolo

# æˆ–ä½¿ç”¨è„šæœ¬
./activate_jetson_env.sh

# æ£€æŸ¥æ€§èƒ½æ¨¡å¼
sudo nvpmodel -q

# è¿è¡Œæ‚¨çš„ä»£ç 
python your_inference_script.py
```

### å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. **é‡æ–°è¿è¡Œæµ‹è¯•**ï¼š`python final_test.py`
2. **æ£€æŸ¥ç¯å¢ƒ**ï¼š`conda list`
3. **æŸ¥çœ‹ç³»ç»Ÿèµ„æº**ï¼š`htop` å’Œ `sudo tegrastats`
4. **é‡æ–°æ¿€æ´»ç¯å¢ƒ**ï¼š`conda deactivate && conda activate jetson_yolo`

**æ‚¨çš„Jetsonç°åœ¨å·²ç»å‡†å¤‡å¥½è¿è¡Œé«˜æ€§èƒ½çš„YOLO+OCRæ¨ç†ä»»åŠ¡äº†ï¼** ğŸš€ 