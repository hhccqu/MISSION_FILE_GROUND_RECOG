# train_yolo_improved.py
# æ”¹è¿›çš„YOLOè®­ç»ƒè„šæœ¬ - é’ˆå¯¹åœ°é¢ç›®æ ‡è¯†åˆ«ä¼˜åŒ–

import os
import sys
from ultralytics import YOLO
import torch
import yaml
from pathlib import Path

def check_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # æ£€æŸ¥æ•°æ®é›†
    data_yaml = "datasets/data.yaml"
    if not os.path.exists(data_yaml):
        print(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
        return False
    
    with open(data_yaml, 'r', encoding='utf-8') as f:
        data_config = yaml.safe_load(f)
    
    # æ£€æŸ¥è®­ç»ƒå’ŒéªŒè¯ç›®å½•
    train_images = Path("datasets/train/images")
    valid_images = Path("datasets/valid/images")
    
    if train_images.exists():
        train_count = len(list(train_images.glob("*")))
        print(f"âœ… è®­ç»ƒå›¾åƒ: {train_count}å¼ ")
    else:
        print("âŒ è®­ç»ƒå›¾åƒç›®å½•ä¸å­˜åœ¨")
        return False
    
    if valid_images.exists():
        valid_count = len(list(valid_images.glob("*")))
        print(f"âœ… éªŒè¯å›¾åƒ: {valid_count}å¼ ")
    else:
        print("âŒ éªŒè¯å›¾åƒç›®å½•ä¸å­˜åœ¨")
        return False
    
    print(f"âœ… æ•°æ®é›†æ£€æŸ¥å®Œæˆ")
    return True

def update_data_yaml():
    """æ›´æ–°æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„"""
    print("ğŸ”§ æ›´æ–°æ•°æ®é…ç½®æ–‡ä»¶...")
    
    # è·å–ç»å¯¹è·¯å¾„
    current_dir = os.getcwd()
    train_path = os.path.join(current_dir, "datasets/train/images")
    valid_path = os.path.join(current_dir, "datasets/valid/images")
    
    # åˆ›å»ºæ–°çš„é…ç½®
    data_config = {
        'train': train_path.replace('\\', '/'),
        'val': valid_path.replace('\\', '/'),
        'nc': 1,
        'names': ['-sign-']
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    with open("datasets/data_updated.yaml", 'w', encoding='utf-8') as f:
        yaml.dump(data_config, f, default_flow_style=False)
    
    print(f"âœ… æ•°æ®é…ç½®å·²æ›´æ–°: datasets/data_updated.yaml")
    return "datasets/data_updated.yaml"

def get_optimal_batch_size():
    """æ ¹æ®æ˜¾å­˜è‡ªåŠ¨é€‰æ‹©æ‰¹æ¬¡å¤§å°"""
    if not torch.cuda.is_available():
        return 4  # CPUæ¨¡å¼ä½¿ç”¨å°æ‰¹æ¬¡
    
    # è·å–æ˜¾å­˜å¤§å°ï¼ˆGBï¼‰
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    
    if gpu_memory >= 8:
        return 32
    elif gpu_memory >= 6:
        return 24
    elif gpu_memory >= 4:
        return 16
    else:
        return 8

def train_improved_model():
    """è®­ç»ƒæ”¹è¿›çš„YOLOæ¨¡å‹"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ”¹è¿›çš„YOLOæ¨¡å‹")
    print("="*50)
    
    # ç¯å¢ƒæ£€æŸ¥
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†é…ç½®")
        return
    
    # æ›´æ–°æ•°æ®é…ç½®
    data_yaml = update_data_yaml()
    
    # è‡ªåŠ¨é€‰æ‹©æ‰¹æ¬¡å¤§å°
    batch_size = get_optimal_batch_size()
    print(f"ğŸ¯ è‡ªåŠ¨é€‰æ‹©æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    # é€‰æ‹©åŸºç¡€æ¨¡å‹
    base_models = ["yolov8n.pt", "yolov8s.pt"]
    selected_model = "yolov8n.pt"  # é»˜è®¤ä½¿ç”¨nanoç‰ˆæœ¬
    
    for model_path in base_models:
        if os.path.exists(model_path):
            selected_model = model_path
            break
    
    print(f"ğŸ“¦ ä½¿ç”¨åŸºç¡€æ¨¡å‹: {selected_model}")
    
    # åŠ è½½æ¨¡å‹
    model = YOLO(selected_model)
    
    # è®­ç»ƒå‚æ•°é…ç½®
    train_args = {
        'data': data_yaml,
        'epochs': 100,                    # å¢åŠ è®­ç»ƒè½®æ•°
        'batch': batch_size,              # è‡ªåŠ¨æ‰¹æ¬¡å¤§å°
        'imgsz': 640,                     # å›¾åƒå°ºå¯¸
        'name': 'improved_detector',      # é¡¹ç›®åç§°
        'project': 'runs/detect',         # ç»“æœç›®å½•
        'patience': 20,                   # æ—©åœè€å¿ƒå€¼
        'save': True,                     # ä¿å­˜æ£€æŸ¥ç‚¹
        'save_period': 10,                # æ¯10è½®ä¿å­˜ä¸€æ¬¡
        'cache': True,                    # ç¼“å­˜å›¾åƒåŠ é€Ÿè®­ç»ƒ
        'device': 0 if torch.cuda.is_available() else 'cpu',
        'workers': 8,                     # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        'exist_ok': True,                 # è¦†ç›–ç°æœ‰é¡¹ç›®
        'pretrained': True,               # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        'optimizer': 'AdamW',             # ä¼˜åŒ–å™¨
        'verbose': True,                  # è¯¦ç»†è¾“å‡º
        'seed': 42,                       # éšæœºç§å­
        'deterministic': True,            # ç¡®å®šæ€§è®­ç»ƒ
        'single_cls': True,               # å•ç±»æ£€æµ‹
        'rect': False,                    # çŸ©å½¢è®­ç»ƒ
        'cos_lr': True,                   # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
        'close_mosaic': 10,               # æœ€å10è½®å…³é—­é©¬èµ›å…‹å¢å¼º
        'resume': False,                  # ä¸æ¢å¤è®­ç»ƒ
        'amp': True,                      # æ··åˆç²¾åº¦è®­ç»ƒ
        'fraction': 1.0,                  # ä½¿ç”¨å…¨éƒ¨æ•°æ®
        'profile': False,                 # ä¸è¿›è¡Œæ€§èƒ½åˆ†æ
        'lr0': 0.01,                      # åˆå§‹å­¦ä¹ ç‡
        'lrf': 0.01,                      # æœ€ç»ˆå­¦ä¹ ç‡æ¯”ä¾‹
        'momentum': 0.937,                # åŠ¨é‡
        'weight_decay': 0.0005,           # æƒé‡è¡°å‡
        'warmup_epochs': 3.0,             # é¢„çƒ­è½®æ•°
        'warmup_momentum': 0.8,           # é¢„çƒ­åŠ¨é‡
        'warmup_bias_lr': 0.1,            # é¢„çƒ­åç½®å­¦ä¹ ç‡
        'box': 7.5,                       # è¾¹ç•Œæ¡†æŸå¤±æƒé‡
        'cls': 0.5,                       # åˆ†ç±»æŸå¤±æƒé‡
        'dfl': 1.5,                       # DFLæŸå¤±æƒé‡
        'pose': 12.0,                     # å§¿æ€æŸå¤±æƒé‡
        'kobj': 2.0,                      # å…³é”®ç‚¹å¯¹è±¡æŸå¤±æƒé‡
        'label_smoothing': 0.0,           # æ ‡ç­¾å¹³æ»‘
        'nbs': 64,                        # æ ‡å‡†æ‰¹æ¬¡å¤§å°
        'hsv_h': 0.015,                   # è‰²è°ƒå¢å¼º
        'hsv_s': 0.7,                     # é¥±å’Œåº¦å¢å¼º
        'hsv_v': 0.4,                     # æ˜åº¦å¢å¼º
        'degrees': 0.0,                   # æ—‹è½¬è§’åº¦
        'translate': 0.1,                 # å¹³ç§»æ¯”ä¾‹
        'scale': 0.5,                     # ç¼©æ”¾æ¯”ä¾‹
        'shear': 0.0,                     # å‰ªåˆ‡è§’åº¦
        'perspective': 0.0,               # é€è§†å˜æ¢
        'flipud': 0.0,                    # ä¸Šä¸‹ç¿»è½¬æ¦‚ç‡
        'fliplr': 0.5,                    # å·¦å³ç¿»è½¬æ¦‚ç‡
        'mosaic': 1.0,                    # é©¬èµ›å…‹å¢å¼ºæ¦‚ç‡
        'mixup': 0.0,                     # æ··åˆå¢å¼ºæ¦‚ç‡
        'copy_paste': 0.0,                # å¤åˆ¶ç²˜è´´å¢å¼ºæ¦‚ç‡
    }
    
    print("ğŸ¯ è®­ç»ƒå‚æ•°é…ç½®:")
    for key, value in train_args.items():
        print(f"   {key}: {value}")
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    try:
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**train_args)
        
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: runs/detect/improved_detector")
        print(f"ğŸ† æœ€ä½³æ¨¡å‹: runs/detect/improved_detector/weights/best.pt")
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        if hasattr(results, 'results_dict'):
            print("\nğŸ“Š è®­ç»ƒç»“æœ:")
            for metric, value in results.results_dict.items():
                print(f"   {metric}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return False

def copy_best_model():
    """å¤åˆ¶æœ€ä½³æ¨¡å‹åˆ°weightsç›®å½•"""
    best_model_path = "runs/detect/improved_detector/weights/best.pt"
    target_path = "weights/best1.pt"  # æ”¹ä¸ºbest1.pt
    
    if os.path.exists(best_model_path):
        import shutil
        os.makedirs("weights", exist_ok=True)
        shutil.copy2(best_model_path, target_path)
        print(f"âœ… æ–°æ¨¡å‹å·²ä¿å­˜ä¸º: {target_path}")
        
        # æ˜¾ç¤ºåŸæ¨¡å‹ä¿¡æ¯ï¼ˆä¸å¤‡ä»½ä¸æ›¿æ¢ï¼‰
        old_model = "weights/best.pt"
        if os.path.exists(old_model):
            old_size = os.path.getsize(old_model) / 1024 / 1024
            print(f"ğŸ“¦ åŸæ¨¡å‹ {old_model} ä¿æŒä¸å˜ (å¤§å°: {old_size:.1f}MB)")
        
        # æ˜¾ç¤ºæ–°æ¨¡å‹ä¿¡æ¯
        new_size = os.path.getsize(target_path) / 1024 / 1024
        print(f"ğŸ“Š æ–°æ¨¡å‹å¤§å°: {new_size:.1f}MB")
        print("ğŸš€ ç°åœ¨æ‚¨å¯ä»¥é€‰æ‹©ä½¿ç”¨æ–°æ¨¡å‹ best1.pt è¿›è¡Œæ¨ç†äº†!")
        
        return True
    else:
        print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {best_model_path}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOæ¨¡å‹é‡æ–°è®­ç»ƒå·¥å…·")
    print("="*50)
    
    # è®­ç»ƒæ¨¡å‹
    if train_improved_model():
        print("\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!")
        
        # å¤åˆ¶æ¨¡å‹
        if copy_best_model():
            print("\nâœ… æ¨¡å‹éƒ¨ç½²å®Œæˆ!")
            print("ç°åœ¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†äº†")
        else:
            print("\nâš ï¸  æ¨¡å‹å¤åˆ¶å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶æ¨¡å‹æ–‡ä»¶")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 