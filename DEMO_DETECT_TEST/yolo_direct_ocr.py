#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO + ç›´æ¥å¤šæ–¹å‘OCRè¯†åˆ«
æ— éœ€ç®­å¤´æ–¹å‘çŸ«æ­£ï¼Œç›´æ¥è¯†åˆ«ç›®æ ‡å†…çš„äºŒä½æ•°
"""

import cv2
import numpy as np
import os
import time
from ultralytics import YOLO
from multi_direction_ocr import MultiDirectionOCR
import json

class YOLODirectOCR:
    """YOLOæ£€æµ‹ + ç›´æ¥OCRè¯†åˆ«å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        print("ğŸš€ åˆå§‹åŒ–YOLOç›´æ¥OCRè¯†åˆ«å™¨...")
        
        # åŠ è½½YOLOæ¨¡å‹
        model_path = "../weights/best1.pt"
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            # å°è¯•å…¶ä»–è·¯å¾„
            alt_paths = ["../weights/best.pt", "../weights/yolov8n.pt", "yolov8n.pt"]
            for alt_path in alt_paths:
                if os.path.exists(alt_path):
                    model_path = alt_path
                    print(f"ğŸ”„ ä½¿ç”¨æ›¿ä»£æ¨¡å‹: {model_path}")
                    break
        
        try:
            self.yolo_model = YOLO(model_path)
            print(f"âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        except Exception as e:
            print(f"âŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return
        
        # åˆå§‹åŒ–å¤šæ–¹å‘OCRè¯†åˆ«å™¨
        self.ocr_processor = MultiDirectionOCR()
        print("âœ… YOLOç›´æ¥OCRè¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def process_images(self, test_dir="test_image_manuel", results_dir="yolo_direct_ocr_results"):
        """å¤„ç†æµ‹è¯•å›¾åƒ"""
        print("\nğŸ§ª å¼€å§‹YOLO + ç›´æ¥OCRæµ‹è¯•...")
        
        if not os.path.exists(test_dir):
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")
            return
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        
        # è·å–æµ‹è¯•å›¾åƒ
        image_files = [f for f in os.listdir(test_dir) if f.lower().endswith('.png')]
        image_files.sort()
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªæµ‹è¯•å›¾åƒ")
        
        # æµ‹è¯•ç»Ÿè®¡
        total_images = 0
        total_detections = 0
        successful_recognitions = 0
        high_confidence_count = 0
        
        # è¯¦ç»†ç»“æœ
        detailed_results = []
        
        print("\n" + "="*100)
        
        for i, filename in enumerate(image_files, 1):
            print(f"\nğŸ–¼ï¸  å¤„ç†å›¾åƒ {i}/{len(image_files)}: {filename}")
            print("-" * 80)
            
            filepath = os.path.join(test_dir, filename)
            image = cv2.imread(filepath)
            
            if image is None:
                print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ: {filename}")
                continue
            
            total_images += 1
            base_name = os.path.splitext(filename)[0]
            
            print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
            
            # YOLOç›®æ ‡æ£€æµ‹
            detections = self.detect_targets(image)
            
            if not detections:
                print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
                continue
            
            print(f"ğŸ¯ æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
            
            # å¤„ç†æ¯ä¸ªæ£€æµ‹ç›®æ ‡
            image_result = {
                'filename': filename,
                'image_shape': image.shape,
                'detection_count': len(detections),
                'targets': []
            }
            
            for j, detection in enumerate(detections, 1):
                print(f"\n   ğŸ“¦ å¤„ç†ç›®æ ‡ {j}/{len(detections)}")
                
                # æå–ç›®æ ‡åŒºåŸŸ
                target_roi = self.extract_target_roi(image, detection)
                
                if target_roi is None:
                    print(f"   âŒ æ— æ³•æå–ç›®æ ‡åŒºåŸŸ")
                    continue
                
                total_detections += 1
                
                print(f"   ğŸ“ ç›®æ ‡å°ºå¯¸: {target_roi.shape[1]}x{target_roi.shape[0]}")
                print(f"   ğŸ“ ç½®ä¿¡åº¦: {detection['confidence']:.3f}")
                
                # ä¿å­˜åŸå§‹ROI
                roi_filename = f"{base_name}_target_{j}_original.jpg"
                roi_path = os.path.join(results_dir, roi_filename)
                cv2.imwrite(roi_path, target_roi)
                
                # ç›´æ¥å¤šæ–¹å‘OCRè¯†åˆ«
                start_time = time.time()
                detected_number, ocr_confidence, ocr_details = self.ocr_processor.recognize_two_digit_number(target_roi)
                processing_time = time.time() - start_time
                
                # ç»Ÿè®¡æˆåŠŸè¯†åˆ«
                if detected_number != "æœªè¯†åˆ«":
                    successful_recognitions += 1
                    if ocr_confidence > 0.5:
                        high_confidence_count += 1
                
                # ä¿å­˜è¯†åˆ«ç»“æœçš„æœ€ä½³æ–¹å‘å›¾åƒ
                if ocr_details['success']:
                    best_angle = ocr_details['best_result']['angle']
                    if best_angle != 0:
                        # ç”Ÿæˆå¹¶ä¿å­˜æœ€ä½³æ–¹å‘çš„å›¾åƒ
                        if best_angle == 90:
                            best_image = cv2.rotate(target_roi, cv2.ROTATE_90_CLOCKWISE)
                        elif best_angle == 180:
                            best_image = cv2.rotate(target_roi, cv2.ROTATE_180)
                        elif best_angle == 270:
                            best_image = cv2.rotate(target_roi, cv2.ROTATE_90_COUNTERCLOCKWISE)
                        else:
                            best_image = target_roi
                        
                        best_filename = f"{base_name}_target_{j}_best_{best_angle}deg.jpg"
                        best_path = os.path.join(results_dir, best_filename)
                        cv2.imwrite(best_path, best_image)
                
                # è®°å½•ç›®æ ‡ç»“æœ
                target_result = {
                    'target_id': j,
                    'bbox': detection['bbox'],
                    'yolo_confidence': detection['confidence'],
                    'detected_number': detected_number,
                    'ocr_confidence': ocr_confidence,
                    'best_angle': ocr_details['best_result']['angle'] if ocr_details['success'] else 0,
                    'processing_time': processing_time,
                    'all_directions': {}
                }
                
                # è®°å½•æ‰€æœ‰æ–¹å‘çš„è¯†åˆ«ç»“æœ
                for angle, result in ocr_details['all_results'].items():
                    if 'error' not in result:
                        target_result['all_directions'][angle] = {
                            'text': result['text'],
                            'confidence': result['confidence'],
                            'two_digit_numbers': result['two_digit_numbers']
                        }
                
                image_result['targets'].append(target_result)
                
                # æ˜¾ç¤ºç»“æœ
                self.display_target_result(target_result, j)
            
            detailed_results.append(image_result)
            
            # åˆ›å»ºå›¾åƒæ‘˜è¦
            self.create_image_summary(image, detections, image_result['targets'], base_name, results_dir)
            
            print("=" * 80)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        self.save_detailed_results(detailed_results, results_dir)
        
        # è¾“å‡ºæµ‹è¯•æ‘˜è¦
        self.print_test_summary(total_images, total_detections, successful_recognitions, high_confidence_count, results_dir)
    
    def detect_targets(self, image):
        """ä½¿ç”¨YOLOæ£€æµ‹ç›®æ ‡"""
        try:
            results = self.yolo_model(image, conf=0.25)
            
            detections = []
            
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    
                    for box, conf in zip(boxes, confidences):
                        x1, y1, x2, y2 = map(int, box)
                        detections.append({
                            'bbox': (x1, y1, x2, y2),
                            'confidence': conf,
                            'area': (x2 - x1) * (y2 - y1)
                        })
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            detections.sort(key=lambda x: x['confidence'], reverse=True)
            
            return detections
            
        except Exception as e:
            print(f"   âŒ YOLOæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def extract_target_roi(self, image, detection):
        """æå–ç›®æ ‡åŒºåŸŸ"""
        try:
            x1, y1, x2, y2 = detection['bbox']
            
            # è®¡ç®—æ™ºèƒ½è¾¹è·
            target_width = x2 - x1
            target_height = y2 - y1
            width_margin = max(20, int(target_width * 0.3))
            height_margin = max(20, int(target_height * 0.3))
            
            if target_width < 50 or target_height < 50:
                width_margin = max(width_margin, 30)
                height_margin = max(height_margin, 30)
            
            h, w = image.shape[:2]
            
            x1_expanded = max(0, x1 - width_margin)
            y1_expanded = max(0, y1 - height_margin)
            x2_expanded = min(w, x2 + width_margin)
            y2_expanded = min(h, y2 + height_margin)
            
            roi = image[y1_expanded:y2_expanded, x1_expanded:x2_expanded]
            
            if roi.size == 0:
                return None
            
            return roi
            
        except Exception as e:
            print(f"   âŒ æå–ROIå¤±è´¥: {e}")
            return None
    
    def display_target_result(self, result, target_idx):
        """æ˜¾ç¤ºç›®æ ‡å¤„ç†ç»“æœ"""
        print(f"   ğŸ¯ è¯†åˆ«ç»“æœ: {result['detected_number']}")
        print(f"   ğŸ“Š OCRç½®ä¿¡åº¦: {result['ocr_confidence']:.3f}")
        print(f"   ğŸ”„ æœ€ä½³è§’åº¦: {result['best_angle']}Â°")
        print(f"   â±ï¸  å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
        
        # æ˜¾ç¤ºæ‰€æœ‰æ–¹å‘çš„ç»“æœ
        print(f"   ğŸ“‹ å„æ–¹å‘è¯†åˆ«:")
        for angle, dir_result in result['all_directions'].items():
            print(f"      {angle:3d}Â°: '{dir_result['text']}' (ç½®ä¿¡åº¦: {dir_result['confidence']:.2f}) äºŒä½æ•°: {dir_result['two_digit_numbers']}")
    
    def create_image_summary(self, original_image, detections, target_results, base_name, results_dir):
        """åˆ›å»ºå›¾åƒå¤„ç†æ‘˜è¦å¯è§†åŒ–"""
        try:
            annotated_image = original_image.copy()
            h, w = original_image.shape[:2]
            
            for i, (detection, target_result) in enumerate(zip(detections, target_results), 1):
                x1, y1, x2, y2 = detection['bbox']
                
                # è®¡ç®—æ‰©å±•æ¡†
                target_width = x2 - x1
                target_height = y2 - y1
                width_margin = max(20, int(target_width * 0.3))
                height_margin = max(20, int(target_height * 0.3))
                
                if target_width < 50 or target_height < 50:
                    width_margin = max(width_margin, 30)
                    height_margin = max(height_margin, 30)
                
                x1_expanded = max(0, x1 - width_margin)
                y1_expanded = max(0, y1 - height_margin)
                x2_expanded = min(w, x2 + width_margin)
                y2_expanded = min(h, y2 + height_margin)
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 0, 255), 1)
                
                # ç»˜åˆ¶æ‰©å±•æ¡†
                color = (0, 255, 0) if target_result['detected_number'] != "æœªè¯†åˆ«" else (0, 165, 255)
                cv2.rectangle(annotated_image, (x1_expanded, y1_expanded), (x2_expanded, y2_expanded), color, 2)
                
                # æ·»åŠ æ ‡ç­¾
                label = f"T{i}: {target_result['detected_number']}"
                if target_result['best_angle'] != 0:
                    label += f" ({target_result['best_angle']}Â°)"
                
                info_label = f"Conf:{target_result['ocr_confidence']:.2f}"
                
                cv2.putText(annotated_image, label, (x1_expanded, y1_expanded-25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                cv2.putText(annotated_image, info_label, (x1_expanded, y1_expanded-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            # ä¿å­˜æ ‡æ³¨å›¾åƒ
            summary_filename = f"{base_name}_summary.jpg"
            summary_path = os.path.join(results_dir, summary_filename)
            cv2.imwrite(summary_path, annotated_image)
            
            print(f"   ğŸ’¾ å¤„ç†æ‘˜è¦å·²ä¿å­˜: {summary_filename}")
            
        except Exception as e:
            print(f"   âš ï¸  åˆ›å»ºæ‘˜è¦å¤±è´¥: {e}")
    
    def save_detailed_results(self, results, results_dir):
        """ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶"""
        json_path = os.path.join(results_dir, "detailed_results.json")
        
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {json_path}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è¯¦ç»†ç»“æœå¤±è´¥: {e}")
    
    def print_test_summary(self, total_images, total_detections, successful_recognitions, high_confidence_count, results_dir):
        """è¾“å‡ºæµ‹è¯•æ‘˜è¦"""
        print(f"\nğŸ“‹ YOLO + ç›´æ¥OCRæµ‹è¯•æ‘˜è¦")
        print("=" * 100)
        print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒæ€»æ•°: {total_images}")
        print(f"ğŸ¯ æ£€æµ‹ç›®æ ‡æ€»æ•°: {total_detections}")
        print(f"âœ… æˆåŠŸè¯†åˆ«æ•°é‡: {successful_recognitions} ({successful_recognitions/max(1,total_detections)*100:.1f}%)")
        print(f"ğŸ“ˆ é«˜ç½®ä¿¡åº¦è¯†åˆ«: {high_confidence_count} ({high_confidence_count/max(1,total_detections)*100:.1f}%)")
        print(f"ğŸ“ ç»“æœä¿å­˜ç›®å½•: {results_dir}/")
        
        # åˆ›å»ºæ–‡æœ¬æŠ¥å‘Š
        self.create_text_report(total_images, total_detections, successful_recognitions, high_confidence_count, results_dir)
    
    def create_text_report(self, total_images, total_detections, successful_recognitions, high_confidence_count, results_dir):
        """åˆ›å»ºæ–‡æœ¬æµ‹è¯•æŠ¥å‘Š"""
        report_path = os.path.join(results_dir, "test_report.txt")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("YOLO + ç›´æ¥å¤šæ–¹å‘OCRè¯†åˆ«æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ğŸ“Š æµ‹è¯•ç»Ÿè®¡\n")
            f.write("-" * 40 + "\n")
            f.write(f"å¤„ç†å›¾åƒæ€»æ•°: {total_images}\n")
            f.write(f"æ£€æµ‹ç›®æ ‡æ€»æ•°: {total_detections}\n")
            f.write(f"æˆåŠŸè¯†åˆ«æ•°é‡: {successful_recognitions}\n")
            f.write(f"é«˜ç½®ä¿¡åº¦è¯†åˆ«: {high_confidence_count}\n")
            f.write(f"è¯†åˆ«æˆåŠŸç‡: {successful_recognitions/max(1,total_detections)*100:.1f}%\n")
            f.write(f"é«˜ç½®ä¿¡åº¦ç‡: {high_confidence_count/max(1,total_detections)*100:.1f}%\n\n")
            
            f.write("ğŸ”§ æŠ€æœ¯æ–¹æ¡ˆ\n")
            f.write("-" * 40 + "\n")
            f.write("1. YOLOç›®æ ‡æ£€æµ‹: ä½¿ç”¨best1.ptæ¨¡å‹ï¼Œç½®ä¿¡åº¦é˜ˆå€¼0.25\n")
            f.write("2. å¤šæ–¹å‘OCR: å¹¶è¡Œè¯†åˆ«0Â°ã€90Â°ã€180Â°ã€270Â°å››ä¸ªæ–¹å‘\n")
            f.write("3. æ™ºèƒ½é€‰æ‹©: åŸºäºç½®ä¿¡åº¦å’ŒäºŒä½æ•°æ•°é‡çš„ç»¼åˆè¯„åˆ†\n")
            f.write("4. æ— éœ€çŸ«æ­£: ç›´æ¥è¯†åˆ«ï¼Œé¿å…ç®­å¤´æ–¹å‘åˆ¤æ–­çš„å¤æ‚æ€§\n\n")
            
            f.write("ğŸ’¡ ç®—æ³•ä¼˜åŠ¿\n")
            f.write("-" * 40 + "\n")
            f.write("- ç®€åŒ–æµç¨‹: è·³è¿‡ç®­å¤´æ–¹å‘æ£€æµ‹æ­¥éª¤\n")
            f.write("- å¹¶è¡Œå¤„ç†: å››æ–¹å‘åŒæ—¶OCRï¼Œæé«˜æ•ˆç‡\n")
            f.write("- é²æ£’æ€§å¼º: ä¸ä¾èµ–ç®­å¤´é¢œè‰²å’Œå½¢çŠ¶ç‰¹å¾\n")
            f.write("- é€‚åº”æ€§å¥½: å¯å¤„ç†ä»»æ„æ–¹å‘çš„æ•°å­—ç›®æ ‡\n")
        
        print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨YOLO + ç›´æ¥OCRè¯†åˆ«æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    processor = YOLODirectOCR()
    
    # è¿è¡Œæµ‹è¯•
    processor.process_images()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main() 