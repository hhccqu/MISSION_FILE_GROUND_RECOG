#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾åƒè½¬æ­£å’ŒOCRè¯†åˆ«ä¼˜åŒ–æµ‹è¯•
ä»è§†é¢‘ä¸­æˆªå–YOLOæ£€æµ‹åˆ°çš„ç›®æ ‡å›¾åƒï¼Œæµ‹è¯•ä¸åŒçš„è½¬æ­£ç®—æ³•å’ŒOCRè¯†åˆ«æ•ˆæœ
"""

import cv2
import numpy as np
import os
import time
import math
from ultralytics import YOLO
import easyocr
import re
from pathlib import Path

class ImageRotationTester:
    """å›¾åƒè½¬æ­£æµ‹è¯•å™¨"""
    
    def __init__(self, video_path, output_dir="test_images"):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            video_path: æµ‹è¯•è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        self.video_path = video_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / "original").mkdir(exist_ok=True)
        (self.output_dir / "rotated_red").mkdir(exist_ok=True)
        (self.output_dir / "rotated_edge").mkdir(exist_ok=True)
        (self.output_dir / "rotated_contour").mkdir(exist_ok=True)
        (self.output_dir / "comparison").mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = None
        self.ocr_reader = None
        
        # æµ‹è¯•ç»“æœ
        self.test_results = []
        
    def initialize_models(self):
        """åˆå§‹åŒ–YOLOå’ŒOCRæ¨¡å‹"""
        print("ğŸ¯ åˆå§‹åŒ–YOLOæ¨¡å‹...")
        model_paths = ['best1.pt', 'best.pt', 'yolov8n.pt', 'yolov8s.pt']
        
        for model_path in model_paths:
            try:
                self.model = YOLO(model_path)
                print(f"âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
                break
            except:
                continue
        
        if not self.model:
            print("âŒ æ— æ³•åŠ è½½YOLOæ¨¡å‹")
            return False
        
        print("ğŸ”¤ åˆå§‹åŒ–OCRè¯†åˆ«å™¨...")
        try:
            self.ocr_reader = easyocr.Reader(['en', 'ch_sim'])
            print("âœ… OCRè¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def extract_targets_from_video(self, max_frames=100, frame_interval=10):
        """ä»è§†é¢‘ä¸­æå–ç›®æ ‡å›¾åƒ"""
        print(f"ğŸ“¹ å¼€å§‹ä»è§†é¢‘æå–ç›®æ ‡å›¾åƒ...")
        print(f"   è§†é¢‘è·¯å¾„: {self.video_path}")
        print(f"   æœ€å¤§å¸§æ•°: {max_frames}")
        print(f"   å¸§é—´éš”: {frame_interval}")
        
        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {self.video_path}")
            return False
        
        frame_count = 0
        saved_count = 0
        
        try:
            while frame_count < max_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                
                # æŒ‰é—´éš”å¤„ç†å¸§
                if frame_count % frame_interval != 0:
                    continue
                
                print(f"ğŸ” å¤„ç†ç¬¬{frame_count}å¸§...")
                
                # YOLOæ£€æµ‹
                results = self.model(frame)
                
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for i, box in enumerate(boxes):
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            confidence = box.conf[0].cpu().numpy()
                            
                            if confidence > 0.25:  # ç½®ä¿¡åº¦é˜ˆå€¼
                                # æå–ç›®æ ‡ROI
                                roi = frame[int(y1):int(y2), int(x1):int(x2)]
                                
                                if roi.size > 0 and roi.shape[0] > 20 and roi.shape[1] > 20:
                                    # ä¿å­˜åŸå§‹å›¾åƒ
                                    filename = f"frame_{frame_count:04d}_target_{i}_conf_{confidence:.2f}"
                                    original_path = self.output_dir / "original" / f"{filename}.jpg"
                                    cv2.imwrite(str(original_path), roi)
                                    
                                    # æµ‹è¯•ä¸åŒçš„è½¬æ­£æ–¹æ³•
                                    self.test_rotation_methods(roi, filename)
                                    
                                    saved_count += 1
                                    print(f"   ğŸ’¾ ä¿å­˜ç›®æ ‡å›¾åƒ: {filename}")
                
                if saved_count >= 50:  # é™åˆ¶ä¿å­˜æ•°é‡
                    break
        
        finally:
            cap.release()
        
        print(f"âœ… å®Œæˆå›¾åƒæå–ï¼Œå…±ä¿å­˜ {saved_count} ä¸ªç›®æ ‡å›¾åƒ")
        return True
    
    def test_rotation_methods(self, roi, filename):
        """æµ‹è¯•ä¸åŒçš„è½¬æ­£æ–¹æ³•"""
        
        # æ–¹æ³•1: åŸºäºçº¢è‰²ç®­å¤´çš„è½¬æ­£ï¼ˆå½“å‰æ–¹æ³•ï¼‰
        rotated_red = self.rotate_by_red_arrow(roi.copy())
        red_path = self.output_dir / "rotated_red" / f"{filename}_red.jpg"
        cv2.imwrite(str(red_path), rotated_red)
        
        # æ–¹æ³•2: åŸºäºè¾¹ç¼˜æ£€æµ‹çš„è½¬æ­£
        rotated_edge = self.rotate_by_edge_detection(roi.copy())
        edge_path = self.output_dir / "rotated_edge" / f"{filename}_edge.jpg"
        cv2.imwrite(str(edge_path), rotated_edge)
        
        # æ–¹æ³•3: åŸºäºè½®å»“åˆ†æçš„è½¬æ­£
        rotated_contour = self.rotate_by_contour_analysis(roi.copy())
        contour_path = self.output_dir / "rotated_contour" / f"{filename}_contour.jpg"
        cv2.imwrite(str(contour_path), rotated_contour)
        
        # åˆ›å»ºå¯¹æ¯”å›¾åƒ
        comparison = self.create_comparison_image(roi, rotated_red, rotated_edge, rotated_contour)
        comp_path = self.output_dir / "comparison" / f"{filename}_comparison.jpg"
        cv2.imwrite(str(comp_path), comparison)
        
        # OCRæµ‹è¯•
        ocr_results = self.test_ocr_on_images(roi, rotated_red, rotated_edge, rotated_contour)
        
        # è®°å½•æµ‹è¯•ç»“æœ
        self.test_results.append({
            'filename': filename,
            'ocr_results': ocr_results,
            'paths': {
                'original': str(self.output_dir / "original" / f"{filename}.jpg"),
                'red': str(red_path),
                'edge': str(edge_path),
                'contour': str(contour_path),
                'comparison': str(comp_path)
            }
        })
    
    def rotate_by_red_arrow(self, image):
        """æ–¹æ³•1: åŸºäºçº¢è‰²ç®­å¤´çš„è½¬æ­£ï¼ˆå½“å‰ä½¿ç”¨çš„æ–¹æ³•ï¼‰"""
        if image is None or image.size == 0:
            return image
        
        try:
            # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # æ£€æµ‹çº¢è‰²åŒºåŸŸ
            lower_red1 = np.array([0, 30, 30])
            upper_red1 = np.array([30, 255, 255])
            lower_red2 = np.array([150, 30, 30])  
            upper_red2 = np.array([179, 255, 255])
            
            mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            red_mask = cv2.bitwise_or(mask1, mask2)
            
            # å½¢æ€å­¦æ“ä½œ
            kernel = np.ones((3,3), np.uint8)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                rect = cv2.minAreaRect(largest_contour)
                angle = rect[2]
                
                # è°ƒæ•´è§’åº¦
                if angle < -45:
                    angle = 90 + angle
                elif angle > 45:
                    angle = angle - 90
                
                if abs(angle) > 5:
                    center = (image.shape[1]//2, image.shape[0]//2)
                    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                    rotated = cv2.warpAffine(image, rotation_matrix, 
                                           (image.shape[1], image.shape[0]))
                    return rotated
            
            return image
            
        except Exception as e:
            print(f"âš ï¸ çº¢è‰²ç®­å¤´è½¬æ­£å¤±è´¥: {e}")
            return image
    
    def rotate_by_edge_detection(self, image):
        """æ–¹æ³•2: åŸºäºè¾¹ç¼˜æ£€æµ‹çš„è½¬æ­£"""
        if image is None or image.size == 0:
            return image
        
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # è¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            
            # éœå¤«å˜æ¢æ£€æµ‹ç›´çº¿
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=30)
            
            if lines is not None and len(lines) > 0:
                # è®¡ç®—ä¸»è¦ç›´çº¿çš„è§’åº¦
                angles = []
                for line in lines:
                    rho, theta = line[0]
                    angle = math.degrees(theta) - 90  # è½¬æ¢ä¸ºæ—‹è½¬è§’åº¦
                    angles.append(angle)
                
                # ä½¿ç”¨è§’åº¦çš„ä¸­ä½æ•°
                median_angle = np.median(angles)
                
                # é™åˆ¶è§’åº¦èŒƒå›´
                if median_angle < -45:
                    median_angle = 90 + median_angle
                elif median_angle > 45:
                    median_angle = median_angle - 90
                
                if abs(median_angle) > 5:
                    center = (image.shape[1]//2, image.shape[0]//2)
                    rotation_matrix = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                    rotated = cv2.warpAffine(image, rotation_matrix, 
                                           (image.shape[1], image.shape[0]))
                    return rotated
            
            return image
            
        except Exception as e:
            print(f"âš ï¸ è¾¹ç¼˜æ£€æµ‹è½¬æ­£å¤±è´¥: {e}")
            return image
    
    def rotate_by_contour_analysis(self, image):
        """æ–¹æ³•3: åŸºäºè½®å»“åˆ†æçš„è½¬æ­£"""
        if image is None or image.size == 0:
            return image
        
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # äºŒå€¼åŒ–
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # æ‰¾åˆ°æœ€å¤§è½®å»“
                largest_contour = max(contours, key=cv2.contourArea)
                
                # è®¡ç®—è½®å»“çš„ä¸»è¦æ–¹å‘
                if len(largest_contour) >= 5:  # éœ€è¦è‡³å°‘5ä¸ªç‚¹æ¥æ‹Ÿåˆæ¤­åœ†
                    ellipse = cv2.fitEllipse(largest_contour)
                    angle = ellipse[2]
                    
                    # è°ƒæ•´è§’åº¦
                    if angle > 90:
                        angle = angle - 180
                    
                    if abs(angle) > 5:
                        center = (image.shape[1]//2, image.shape[0]//2)
                        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                        rotated = cv2.warpAffine(image, rotation_matrix, 
                                               (image.shape[1], image.shape[0]))
                        return rotated
            
            return image
            
        except Exception as e:
            print(f"âš ï¸ è½®å»“åˆ†æè½¬æ­£å¤±è´¥: {e}")
            return image
    
    def create_comparison_image(self, original, red_rotated, edge_rotated, contour_rotated):
        """åˆ›å»ºå¯¹æ¯”å›¾åƒ"""
        try:
            # è°ƒæ•´æ‰€æœ‰å›¾åƒåˆ°ç›¸åŒå¤§å°
            target_size = (150, 150)
            
            orig_resized = cv2.resize(original, target_size)
            red_resized = cv2.resize(red_rotated, target_size)
            edge_resized = cv2.resize(edge_rotated, target_size)
            contour_resized = cv2.resize(contour_rotated, target_size)
            
            # åˆ›å»º2x2ç½‘æ ¼
            top_row = np.hstack([orig_resized, red_resized])
            bottom_row = np.hstack([edge_resized, contour_resized])
            comparison = np.vstack([top_row, bottom_row])
            
            # æ·»åŠ æ ‡ç­¾
            font = cv2.FONT_HERSHEY_SIMPLEX
            cv2.putText(comparison, "Original", (5, 20), font, 0.5, (255, 255, 255), 1)
            cv2.putText(comparison, "Red Arrow", (155, 20), font, 0.5, (0, 0, 255), 1)
            cv2.putText(comparison, "Edge Detection", (5, 170), font, 0.5, (0, 255, 0), 1)
            cv2.putText(comparison, "Contour Analysis", (155, 170), font, 0.5, (255, 0, 0), 1)
            
            return comparison
            
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºå¯¹æ¯”å›¾åƒå¤±è´¥: {e}")
            return original
    
    def test_ocr_on_images(self, original, red_rotated, edge_rotated, contour_rotated):
        """å¯¹æ‰€æœ‰å›¾åƒè¿›è¡ŒOCRæµ‹è¯•"""
        images = {
            'original': original,
            'red_rotated': red_rotated,
            'edge_rotated': edge_rotated,
            'contour_rotated': contour_rotated
        }
        
        results = {}
        
        for method, image in images.items():
            try:
                ocr_results = self.ocr_reader.readtext(image)
                
                # æå–æœ€ä½³ç»“æœ
                best_text = ""
                best_confidence = 0.0
                
                if ocr_results:
                    best_result = max(ocr_results, key=lambda x: x[2])
                    best_text = best_result[1]
                    best_confidence = best_result[2]
                
                # æå–æ•°å­—
                numbers = re.findall(r'\d+', best_text)
                detected_number = numbers[0] if numbers else "æœªè¯†åˆ«"
                
                results[method] = {
                    'text': best_text,
                    'confidence': best_confidence,
                    'number': detected_number,
                    'all_results': ocr_results
                }
                
            except Exception as e:
                results[method] = {
                    'text': "",
                    'confidence': 0.0,
                    'number': "é”™è¯¯",
                    'error': str(e)
                }
        
        return results
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        report_path = self.output_dir / "test_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("å›¾åƒè½¬æ­£å’ŒOCRè¯†åˆ«æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_tests = len(self.test_results)
            f.write(f"æ€»æµ‹è¯•å›¾åƒæ•°: {total_tests}\n\n")
            
            # å„æ–¹æ³•æˆåŠŸç‡ç»Ÿè®¡
            methods = ['original', 'red_rotated', 'edge_rotated', 'contour_rotated']
            method_names = ['åŸå§‹å›¾åƒ', 'çº¢è‰²ç®­å¤´è½¬æ­£', 'è¾¹ç¼˜æ£€æµ‹è½¬æ­£', 'è½®å»“åˆ†æè½¬æ­£']
            
            for method, name in zip(methods, method_names):
                successful = sum(1 for result in self.test_results 
                               if result['ocr_results'][method]['number'] != "æœªè¯†åˆ«" 
                               and result['ocr_results'][method]['number'] != "é”™è¯¯")
                success_rate = successful / total_tests * 100 if total_tests > 0 else 0
                f.write(f"{name}: {successful}/{total_tests} ({success_rate:.1f}%)\n")
            
            f.write("\n" + "=" * 50 + "\n\n")
            
            # è¯¦ç»†ç»“æœ
            f.write("è¯¦ç»†æµ‹è¯•ç»“æœ:\n\n")
            
            for i, result in enumerate(self.test_results, 1):
                f.write(f"æµ‹è¯• {i}: {result['filename']}\n")
                f.write("-" * 30 + "\n")
                
                for method, name in zip(methods, method_names):
                    ocr_result = result['ocr_results'][method]
                    f.write(f"{name}:\n")
                    f.write(f"  è¯†åˆ«æ–‡æœ¬: {ocr_result['text']}\n")
                    f.write(f"  æå–æ•°å­—: {ocr_result['number']}\n")
                    f.write(f"  ç½®ä¿¡åº¦: {ocr_result['confidence']:.2f}\n")
                
                f.write("\n")
        
        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # æ‰“å°ç®€è¦ç»Ÿè®¡
        print("\nğŸ“ˆ æµ‹è¯•ç»“æœç»Ÿè®¡:")
        for method, name in zip(methods, method_names):
            successful = sum(1 for result in self.test_results 
                           if result['ocr_results'][method]['number'] != "æœªè¯†åˆ«" 
                           and result['ocr_results'][method]['number'] != "é”™è¯¯")
            success_rate = successful / len(self.test_results) * 100 if self.test_results else 0
            print(f"   {name}: {successful}/{len(self.test_results)} ({success_rate:.1f}%)")
    
    def run_test(self, max_frames=100, frame_interval=10):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å›¾åƒè½¬æ­£å’ŒOCRè¯†åˆ«ä¼˜åŒ–æµ‹è¯•")
        print("=" * 60)
        
        # åˆå§‹åŒ–æ¨¡å‹
        if not self.initialize_models():
            return False
        
        # æå–ç›®æ ‡å›¾åƒ
        if not self.extract_targets_from_video(max_frames, frame_interval):
            return False
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report()
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        print(f"   åŸå§‹å›¾åƒ: {self.output_dir}/original/")
        print(f"   çº¢è‰²ç®­å¤´è½¬æ­£: {self.output_dir}/rotated_red/")
        print(f"   è¾¹ç¼˜æ£€æµ‹è½¬æ­£: {self.output_dir}/rotated_edge/")
        print(f"   è½®å»“åˆ†æè½¬æ­£: {self.output_dir}/rotated_contour/")
        print(f"   å¯¹æ¯”å›¾åƒ: {self.output_dir}/comparison/")
        print(f"   æµ‹è¯•æŠ¥å‘Š: {self.output_dir}/test_report.txt")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    # è§†é¢‘è·¯å¾„
    video_path = "../video2.mp4"  # ç›¸å¯¹äºDEMO_DETECT_TESTç›®å½•çš„è·¯å¾„
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        print("è¯·ç¡®è®¤è§†é¢‘è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ImageRotationTester(video_path, "rotation_test_results")
    
    # è¿è¡Œæµ‹è¯•
    tester.run_test(max_frames=200, frame_interval=5)

if __name__ == "__main__":
    main() 