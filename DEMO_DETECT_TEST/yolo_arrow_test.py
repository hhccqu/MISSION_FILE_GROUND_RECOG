#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOç›®æ ‡æ£€æµ‹ + ç®­å¤´æ–¹å‘ä¿®æ­£ç»¼åˆæµ‹è¯•
å…ˆä½¿ç”¨best1æ¨¡å‹æ£€æµ‹å›¾åƒä¸­çš„ç›®æ ‡ï¼Œç„¶åå¯¹æ¯ä¸ªç›®æ ‡è¿›è¡Œç®­å¤´æ–¹å‘ä¿®æ­£æµ‹è¯•
"""

import cv2
import numpy as np
import os
import time
from ultralytics import YOLO
from arrow_orientation_fix import ArrowOrientationFixer
import easyocr

class YOLOArrowTester:
    """YOLOæ£€æµ‹ä¸ç®­å¤´ä¿®æ­£ç»¼åˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        print("ğŸš€ åˆå§‹åŒ–YOLOç®­å¤´æµ‹è¯•å™¨...")
        
        # åŠ è½½YOLOæ¨¡å‹
        model_path = "../weights/best1.pt"
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            # å°è¯•å…¶ä»–è·¯å¾„
            alt_paths = ["../weights/best.pt", "../weights/yolov8n.pt"]
            for alt_path in alt_paths:
                if os.path.exists(alt_path):
                    model_path = alt_path
                    print(f"ğŸ”„ ä½¿ç”¨æ›¿ä»£æ¨¡å‹: {model_path}")
                    break
        
        try:
            self.yolo_model = YOLO(model_path)
            print(f"âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        except Exception as e:
            print(f"âŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return
        
        # åˆå§‹åŒ–ç®­å¤´æ–¹å‘ä¿®æ­£å™¨
        self.arrow_fixer = ArrowOrientationFixer()
        print("âœ… ç®­å¤´æ–¹å‘ä¿®æ­£å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–OCR
        self.ocr_reader = easyocr.Reader(['en', 'ch_sim'])
        print("âœ… OCRè¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def test_manual_images_with_yolo(self):
        """ä½¿ç”¨YOLOæ£€æµ‹æµ‹è¯•æ‰‹åŠ¨å›¾åƒ"""
        print("\nğŸ§ª å¼€å§‹YOLO + ç®­å¤´ä¿®æ­£ç»¼åˆæµ‹è¯•...")
        
        # æµ‹è¯•å›¾åƒç›®å½•
        test_dir = "test_image_manuel"
        
        if not os.path.exists(test_dir):
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")
            return
        
        # è·å–æ‰€æœ‰PNGå›¾åƒ
        image_files = [f for f in os.listdir(test_dir) if f.lower().endswith('.png')]
        image_files.sort()
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªæµ‹è¯•å›¾åƒ")
        
        # åˆ›å»ºç»“æœç›®å½•
        results_dir = "yolo_arrow_test_results"
        os.makedirs(results_dir, exist_ok=True)
        
        # æµ‹è¯•ç»Ÿè®¡
        total_images = 0
        total_detections = 0
        successful_corrections = 0
        high_confidence_ocr = 0
        
        print("\n" + "="*100)
        
        for i, filename in enumerate(image_files, 1):
            print(f"\nğŸ–¼ï¸  å¤„ç†å›¾åƒ {i}/{len(image_files)}: {filename}")
            print("-" * 80)
            
            filepath = os.path.join(test_dir, filename)
            image = cv2.imread(filepath)
            
            if image is None:
                print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ: {filename}")
                continue
            
            total_images += 1
            base_name = os.path.splitext(filename)[0]
            
            print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {image.shape[1]}x{image.shape[0]}")
            
            # æ­¥éª¤1: YOLOç›®æ ‡æ£€æµ‹
            detections = self.detect_targets(image)
            
            if not detections:
                print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
                continue
            
            print(f"ğŸ¯ æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
            
            # æ­¥éª¤2: å¯¹æ¯ä¸ªæ£€æµ‹ç›®æ ‡è¿›è¡Œå¤„ç†
            image_results = []
            
            for j, detection in enumerate(detections, 1):
                print(f"\n   ğŸ“¦ å¤„ç†ç›®æ ‡ {j}/{len(detections)}")
                
                # æå–ç›®æ ‡åŒºåŸŸ
                target_roi = self.extract_target_roi(image, detection)
                
                if target_roi is None:
                    print(f"   âŒ æ— æ³•æå–ç›®æ ‡åŒºåŸŸ")
                    continue
                
                total_detections += 1
                
                # ä¿å­˜åŸå§‹ROI
                roi_filename = f"{base_name}_target_{j}_original.jpg"
                roi_path = os.path.join(results_dir, roi_filename)
                cv2.imwrite(roi_path, target_roi)
                
                print(f"   ğŸ“ ç›®æ ‡å°ºå¯¸: {target_roi.shape[1]}x{target_roi.shape[0]}")
                print(f"   ğŸ“ ç½®ä¿¡åº¦: {detection['confidence']:.3f}")
                
                # æ­¥éª¤3: ç®­å¤´æ–¹å‘æ£€æµ‹å’Œä¿®æ­£
                result = self.process_target_arrow(target_roi, base_name, j, results_dir)
                
                if result['corrected']:
                    successful_corrections += 1
                
                if result['ocr_confidence'] > 0.5:
                    high_confidence_ocr += 1
                
                image_results.append(result)
                
                # æ˜¾ç¤ºå¤„ç†ç»“æœ
                self.display_target_result(result, j)
            
            # æ­¥éª¤4: åˆ›å»ºç»¼åˆå¯è§†åŒ–
            self.create_image_summary(image, detections, image_results, base_name, results_dir)
            
            print("=" * 80)
        
        # è¾“å‡ºæµ‹è¯•æ‘˜è¦
        self.print_test_summary(total_images, total_detections, successful_corrections, high_confidence_ocr, results_dir)
    
    def detect_targets(self, image):
        """ä½¿ç”¨YOLOæ£€æµ‹ç›®æ ‡"""
        try:
            # è¿è¡ŒYOLOæ£€æµ‹
            results = self.yolo_model(image, conf=0.25)  # ç½®ä¿¡åº¦é˜ˆå€¼0.25
            
            detections = []
            
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    
                    for box, conf in zip(boxes, confidences):
                        x1, y1, x2, y2 = map(int, box)
                        detections.append({
                            'bbox': (x1, y1, x2, y2),
                            'confidence': conf,
                            'area': (x2 - x1) * (y2 - y1)
                        })
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            detections.sort(key=lambda x: x['confidence'], reverse=True)
            
            return detections
            
        except Exception as e:
            print(f"   âŒ YOLOæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def extract_target_roi(self, image, detection):
        """æå–ç›®æ ‡åŒºåŸŸ"""
        try:
            x1, y1, x2, y2 = detection['bbox']
            
            # è®¡ç®—ç›®æ ‡çš„å®½åº¦å’Œé«˜åº¦
            target_width = x2 - x1
            target_height = y2 - y1
            
            # æ™ºèƒ½è¾¹è·è®¡ç®—ï¼šåŸºäºç›®æ ‡å¤§å°çš„ç™¾åˆ†æ¯” + å›ºå®šæœ€å°è¾¹è·
            width_margin = max(20, int(target_width * 0.3))  # å®½åº¦30%æˆ–è‡³å°‘20åƒç´ 
            height_margin = max(20, int(target_height * 0.3))  # é«˜åº¦30%æˆ–è‡³å°‘20åƒç´ 
            
            # å¯¹äºå°ç›®æ ‡ï¼Œä½¿ç”¨æ›´å¤§çš„è¾¹è·
            if target_width < 50 or target_height < 50:
                width_margin = max(width_margin, 30)
                height_margin = max(height_margin, 30)
                print(f"   ğŸ“ å°ç›®æ ‡æ£€æµ‹ï¼Œä½¿ç”¨æ‰©å¤§è¾¹è·: {width_margin}x{height_margin}")
            
            h, w = image.shape[:2]
            
            # åº”ç”¨è¾¹è·å¹¶ç¡®ä¿ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
            x1_expanded = max(0, x1 - width_margin)
            y1_expanded = max(0, y1 - height_margin)
            x2_expanded = min(w, x2 + width_margin)
            y2_expanded = min(h, y2 + height_margin)
            
            roi = image[y1_expanded:y2_expanded, x1_expanded:x2_expanded]
            
            # æ£€æŸ¥ROIæœ‰æ•ˆæ€§
            if roi.size == 0 or roi.shape[0] < 10 or roi.shape[1] < 10:
                return None
            
            # è¾“å‡ºæ‰©å±•ä¿¡æ¯
            original_size = f"{target_width}x{target_height}"
            expanded_size = f"{roi.shape[1]}x{roi.shape[0]}"
            print(f"   ğŸ“¦ ç›®æ ‡æ¡†æ‰©å±•: {original_size} â†’ {expanded_size} (è¾¹è·: {width_margin}x{height_margin})")
            
            return roi
            
        except Exception as e:
            print(f"   âŒ ROIæå–å¤±è´¥: {e}")
            return None
    
    def process_target_arrow(self, target_roi, base_name, target_idx, results_dir):
        """å¤„ç†ç›®æ ‡çš„ç®­å¤´æ–¹å‘"""
        result = {
            'target_idx': target_idx,
            'corrected': False,
            'arrow_direction': 'unknown',
            'ocr_text': '',
            'ocr_confidence': 0.0,
            'original_ocr_text': '',
            'original_ocr_confidence': 0.0,
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # åŸå§‹å›¾åƒOCR
            try:
                original_ocr = self.ocr_reader.readtext(target_roi)
                if original_ocr:
                    best_original = max(original_ocr, key=lambda x: x[2])
                    result['original_ocr_text'] = best_original[1]
                    result['original_ocr_confidence'] = best_original[2]
            except:
                pass
            
            # ç®­å¤´æ–¹å‘æ£€æµ‹å’Œä¿®æ­£
            corrected_image, was_corrected = self.arrow_fixer.correct_arrow_orientation(target_roi)
            result['corrected'] = was_corrected
            
            if was_corrected:
                # ä¿å­˜ä¿®æ­£åçš„å›¾åƒ
                corrected_filename = f"{base_name}_target_{target_idx}_corrected.jpg"
                corrected_path = os.path.join(results_dir, corrected_filename)
                cv2.imwrite(corrected_path, corrected_image)
            
            # æ™ºèƒ½æ—‹è½¬ä¸OCRéªŒè¯
            smart_image, ocr_text, ocr_confidence = self.arrow_fixer.smart_rotate_with_ocr_validation(target_roi)
            result['ocr_text'] = ocr_text
            result['ocr_confidence'] = ocr_confidence
            
            # ä¿å­˜æ™ºèƒ½å¤„ç†ç»“æœ
            smart_filename = f"{base_name}_target_{target_idx}_smart.jpg"
            smart_path = os.path.join(results_dir, smart_filename)
            cv2.imwrite(smart_path, smart_image)
            
            # æ£€æµ‹ç®­å¤´æ–¹å‘
            result['arrow_direction'] = self.arrow_fixer.detect_arrow_orientation(target_roi)
            
        except Exception as e:
            print(f"   âŒ ç®­å¤´å¤„ç†å¤±è´¥: {e}")
        
        result['processing_time'] = time.time() - start_time
        
        return result
    
    def display_target_result(self, result, target_idx):
        """æ˜¾ç¤ºç›®æ ‡å¤„ç†ç»“æœ"""
        print(f"   ğŸ§­ ç®­å¤´æ–¹å‘: {result['arrow_direction']}")
        print(f"   ğŸ”„ æ˜¯å¦ä¿®æ­£: {'æ˜¯' if result['corrected'] else 'å¦'}")
        print(f"   ğŸ“ åŸå§‹OCR: '{result['original_ocr_text']}' (ç½®ä¿¡åº¦: {result['original_ocr_confidence']:.2f})")
        print(f"   ğŸ¯ æ™ºèƒ½OCR: '{result['ocr_text']}' (ç½®ä¿¡åº¦: {result['ocr_confidence']:.2f})")
        print(f"   â±ï¸  å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
        
        # åˆ†ææ”¹è¿›æ•ˆæœ
        if result['ocr_confidence'] > result['original_ocr_confidence']:
            improvement = result['ocr_confidence'] - result['original_ocr_confidence']
            print(f"   ğŸ“ˆ OCRæ”¹è¿›: +{improvement:.2f}")
        elif result['ocr_confidence'] < result['original_ocr_confidence']:
            decline = result['original_ocr_confidence'] - result['ocr_confidence']
            print(f"   ğŸ“‰ OCRä¸‹é™: -{decline:.2f}")
        else:
            print(f"   ğŸ“Š OCRæ— å˜åŒ–")
    
    def create_image_summary(self, original_image, detections, results, base_name, results_dir):
        """åˆ›å»ºå›¾åƒå¤„ç†æ‘˜è¦å¯è§†åŒ–"""
        try:
            # åœ¨åŸå›¾ä¸Šæ ‡æ³¨æ£€æµ‹ç»“æœ
            annotated_image = original_image.copy()
            h, w = original_image.shape[:2]
            
            for i, (detection, result) in enumerate(zip(detections, results), 1):
                x1, y1, x2, y2 = detection['bbox']
                
                # è®¡ç®—æ‰©å±•æ¡†ï¼ˆä¸extract_target_roiä¸­çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
                target_width = x2 - x1
                target_height = y2 - y1
                width_margin = max(20, int(target_width * 0.3))
                height_margin = max(20, int(target_height * 0.3))
                
                if target_width < 50 or target_height < 50:
                    width_margin = max(width_margin, 30)
                    height_margin = max(height_margin, 30)
                
                x1_expanded = max(0, x1 - width_margin)
                y1_expanded = max(0, y1 - height_margin)
                x2_expanded = min(w, x2 + width_margin)
                y2_expanded = min(h, y2 + height_margin)
                
                # ç»˜åˆ¶åŸå§‹YOLOæ£€æµ‹æ¡†ï¼ˆçº¢è‰²è™šçº¿ï¼‰
                cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 0, 255), 1)
                
                # ç»˜åˆ¶æ‰©å±•å¤„ç†æ¡†ï¼ˆç»¿è‰²å®çº¿ï¼‰
                color = (0, 255, 0) if result['corrected'] else (255, 165, 0)  # ç»¿è‰²æˆ–æ©™è‰²
                cv2.rectangle(annotated_image, (x1_expanded, y1_expanded), (x2_expanded, y2_expanded), color, 2)
                
                # æ·»åŠ æ ‡ç­¾
                label = f"T{i}: {result['arrow_direction']}"
                if result['ocr_text']:
                    label += f" [{result['ocr_text']}]"
                
                # æ˜¾ç¤ºç½®ä¿¡åº¦å’Œå°ºå¯¸ä¿¡æ¯
                info_label = f"Conf:{detection['confidence']:.2f} Size:{target_width}x{target_height}"
                
                cv2.putText(annotated_image, label, (x1_expanded, y1_expanded-25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                cv2.putText(annotated_image, info_label, (x1_expanded, y1_expanded-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            # æ·»åŠ å›¾ä¾‹
            legend_y = 30
            cv2.putText(annotated_image, "Legend:", (10, legend_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.rectangle(annotated_image, (10, legend_y+10), (30, legend_y+20), (0, 0, 255), 1)
            cv2.putText(annotated_image, "YOLO Detection", (35, legend_y+18), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            cv2.rectangle(annotated_image, (10, legend_y+25), (30, legend_y+35), (0, 255, 0), 2)
            cv2.putText(annotated_image, "Expanded ROI", (35, legend_y+33), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            # ä¿å­˜æ ‡æ³¨å›¾åƒ
            summary_filename = f"{base_name}_summary.jpg"
            summary_path = os.path.join(results_dir, summary_filename)
            cv2.imwrite(summary_path, annotated_image)
            
            print(f"   ğŸ’¾ å¤„ç†æ‘˜è¦å·²ä¿å­˜: {summary_filename}")
            
        except Exception as e:
            print(f"   âš ï¸  åˆ›å»ºæ‘˜è¦å¤±è´¥: {e}")
    
    def print_test_summary(self, total_images, total_detections, corrections, high_conf_ocr, results_dir):
        """è¾“å‡ºæµ‹è¯•æ‘˜è¦"""
        print(f"\nğŸ“‹ YOLO + ç®­å¤´ä¿®æ­£æµ‹è¯•æ‘˜è¦")
        print("=" * 100)
        print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒæ€»æ•°: {total_images}")
        print(f"ğŸ¯ æ£€æµ‹ç›®æ ‡æ€»æ•°: {total_detections}")
        print(f"ğŸ”„ æˆåŠŸä¿®æ­£æ•°é‡: {corrections} ({corrections/max(1,total_detections)*100:.1f}%)")
        print(f"ğŸ“ˆ é«˜ç½®ä¿¡åº¦OCR: {high_conf_ocr} ({high_conf_ocr/max(1,total_detections)*100:.1f}%)")
        print(f"ğŸ“ ç»“æœä¿å­˜ç›®å½•: {results_dir}/")
        
        # åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
        self.create_comprehensive_report(total_images, total_detections, corrections, high_conf_ocr, results_dir)
    
    def create_comprehensive_report(self, total_images, total_detections, corrections, high_conf_ocr, results_dir):
        """åˆ›å»ºç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        report_path = os.path.join(results_dir, "comprehensive_test_report.txt")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("YOLO + ç®­å¤´æ–¹å‘ä¿®æ­£ç»¼åˆæµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ğŸ“Š æµ‹è¯•ç»Ÿè®¡\n")
            f.write("-" * 40 + "\n")
            f.write(f"å¤„ç†å›¾åƒæ€»æ•°: {total_images}\n")
            f.write(f"æ£€æµ‹ç›®æ ‡æ€»æ•°: {total_detections}\n")
            f.write(f"æˆåŠŸä¿®æ­£æ•°é‡: {corrections}\n")
            f.write(f"é«˜ç½®ä¿¡åº¦OCR: {high_conf_ocr}\n")
            f.write(f"ä¿®æ­£æˆåŠŸç‡: {corrections/max(1,total_detections)*100:.1f}%\n")
            f.write(f"OCRæˆåŠŸç‡: {high_conf_ocr/max(1,total_detections)*100:.1f}%\n\n")
            
            f.write("ğŸ”§ æŠ€æœ¯æ–¹æ¡ˆ\n")
            f.write("-" * 40 + "\n")
            f.write("1. YOLOç›®æ ‡æ£€æµ‹: ä½¿ç”¨best1.ptæ¨¡å‹ï¼Œç½®ä¿¡åº¦é˜ˆå€¼0.25\n")
            f.write("2. ç®­å¤´æ–¹å‘æ£€æµ‹: HSVè‰²å½©ç©ºé—´ + å‡¸åŒ…ç¼ºé™·åˆ†æ\n")
            f.write("3. æ™ºèƒ½æ—‹è½¬ä¿®æ­£: å››æ–¹å‘æµ‹è¯• + OCRéªŒè¯\n")
            f.write("4. è´¨é‡ä¿è¯: é«˜ç²¾åº¦ä»¿å°„å˜æ¢ + è¾¹ç•Œè‡ªé€‚åº”\n\n")
            
            f.write("ğŸ’¡ ç®—æ³•ä¼˜åŠ¿\n")
            f.write("-" * 40 + "\n")
            f.write("- ç«¯åˆ°ç«¯å¤„ç†: ä»å®Œæ•´å›¾åƒåˆ°ç›®æ ‡è¯†åˆ«ä¿®æ­£\n")
            f.write("- é«˜ç²¾åº¦æ£€æµ‹: YOLO + ç®­å¤´æ–¹å‘åŒé‡éªŒè¯\n")
            f.write("- æ™ºèƒ½ä¼˜åŒ–: OCRç»“æœé©±åŠ¨çš„æœ€ä¼˜æ—‹è½¬é€‰æ‹©\n")
            f.write("- é²æ£’æ€§å¼º: å¤šç§å¼‚å¸¸æƒ…å†µçš„ä¼˜é›…å¤„ç†\n")
        
        print(f"ğŸ“„ ç»¼åˆæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨YOLO + ç®­å¤´æ–¹å‘ä¿®æ­£ç»¼åˆæµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = YOLOArrowTester()
    
    # è¿è¡Œæµ‹è¯•
    tester.test_manual_images_with_yolo()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main() 