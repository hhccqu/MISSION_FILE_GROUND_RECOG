#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å±•ç¤ºæ”¹è¿›åçš„ç®­å¤´æ–¹å‘çŸ«æ­£ç»“æœ
é‡ç‚¹å±•ç¤ºé¡¶ç‚¹ä½äºæœ€é«˜ä½ç½®çš„æ•ˆæœ
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import glob

def display_improved_results():
    """å±•ç¤ºæ”¹è¿›åçš„çŸ«æ­£ç»“æœ"""
    
    print("ğŸ¨ å±•ç¤ºæ”¹è¿›åçš„ç®­å¤´æ–¹å‘çŸ«æ­£ç»“æœ")
    print("ğŸ¯ é‡ç‚¹ï¼šç¡®ä¿ç®­å¤´é¡¶ç‚¹ä½äºå›¾åƒæœ€é«˜ä½ç½®")
    print("=" * 60)
    
    result_dir = "test_improved_results"
    if not os.path.exists(result_dir):
        print(f"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {result_dir}")
        return
    
    # æŸ¥æ‰¾å¤„ç†è¿‡ç¨‹å›¾åƒ
    process_images = glob.glob(os.path.join(result_dir, "*_correction_process.jpg"))
    process_images.sort()
    
    if not process_images:
        print("âŒ æœªæ‰¾åˆ°å¤„ç†è¿‡ç¨‹å›¾åƒ")
        return
    
    print(f"ğŸ“¸ æ‰¾åˆ° {len(process_images)} ä¸ªå¤„ç†è¿‡ç¨‹å›¾åƒ")
    
    # æ˜¾ç¤ºæ‰€æœ‰å¤„ç†è¿‡ç¨‹
    n_images = len(process_images)
    fig, axes = plt.subplots(n_images, 1, figsize=(16, 6*n_images))
    
    if n_images == 1:
        axes = [axes]
    
    for i, process_path in enumerate(process_images):
        img = cv2.imread(process_path)
        if img is not None:
            axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
            filename = os.path.basename(process_path)
            axes[i].set_title(f"çŸ«æ­£è¿‡ç¨‹ - {filename}", fontsize=12, pad=10)
            axes[i].axis('off')
            
            print(f"âœ… æ˜¾ç¤º: {filename}")
    
    plt.suptitle("æ”¹è¿›åçš„ç®­å¤´æ–¹å‘çŸ«æ­£ - é¡¶ç‚¹ä½äºæœ€é«˜ä½ç½®", fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

def create_before_after_comparison():
    """åˆ›å»ºå‰åå¯¹æ¯”å›¾"""
    
    print("\nğŸ”„ åˆ›å»ºå‰åå¯¹æ¯”å›¾...")
    
    # æŸ¥æ‰¾åŸå§‹å›¾åƒå’ŒçŸ«æ­£å›¾åƒ
    original_dir = "yolo_arrow_test_results"
    result_dir = "test_improved_results"
    
    # æ‰¾åˆ°æˆåŠŸçŸ«æ­£çš„æ¡ˆä¾‹
    corrected_images = glob.glob(os.path.join(result_dir, "*_corrected.jpg"))
    
    if not corrected_images:
        print("âŒ æœªæ‰¾åˆ°çŸ«æ­£åçš„å›¾åƒ")
        return
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    n_pairs = min(3, len(corrected_images))  # æœ€å¤šæ˜¾ç¤º3å¯¹
    fig, axes = plt.subplots(2, n_pairs, figsize=(n_pairs*5, 8))
    
    if n_pairs == 1:
        axes = axes.reshape(2, 1)
    
    for i, corrected_path in enumerate(corrected_images[:n_pairs]):
        # æ„é€ åŸå§‹å›¾åƒè·¯å¾„
        base_name = os.path.basename(corrected_path).replace("_corrected.jpg", ".jpg")
        original_path = os.path.join(original_dir, base_name)
        
        if os.path.exists(original_path):
            # è¯»å–å›¾åƒ
            original_img = cv2.imread(original_path)
            corrected_img = cv2.imread(corrected_path)
            
            if original_img is not None and corrected_img is not None:
                # æ˜¾ç¤ºåŸå§‹å›¾åƒ
                axes[0, i].imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))
                axes[0, i].set_title(f"åŸå§‹å›¾åƒ\n{base_name}", fontsize=10)
                axes[0, i].axis('off')
                
                # æ˜¾ç¤ºçŸ«æ­£å›¾åƒ  
                axes[1, i].imshow(cv2.cvtColor(corrected_img, cv2.COLOR_BGR2RGB))
                axes[1, i].set_title(f"çŸ«æ­£å (é¡¶ç‚¹æœä¸Š)\n{base_name}", fontsize=10)
                axes[1, i].axis('off')
                
                print(f"âœ… å¯¹æ¯”: {base_name}")
    
    plt.suptitle("ç®­å¤´æ–¹å‘çŸ«æ­£å‰åå¯¹æ¯” - é¡¶ç‚¹ä½ç½®çŸ«æ­£", fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()

def analyze_correction_effectiveness():
    """åˆ†æçŸ«æ­£æ•ˆæœ"""
    
    print("\nğŸ“Š åˆ†æçŸ«æ­£æ•ˆæœ...")
    
    from arrow_orientation_correction import ArrowOrientationCorrector
    
    result_dir = "test_improved_results"
    corrected_images = glob.glob(os.path.join(result_dir, "*_corrected.jpg"))
    
    corrector = ArrowOrientationCorrector()
    
    analysis_results = []
    
    for corrected_path in corrected_images:
        img = cv2.imread(corrected_path)
        if img is None:
            continue
            
        # æ£€æµ‹ç®­å¤´
        contours = corrector.detect_arrow_contours(img)
        if not contours:
            continue
            
        largest_contour = max(contours, key=cv2.contourArea)
        tip_point = corrector.find_arrow_tip(largest_contour)
        
        if tip_point is None:
            continue
            
        # åˆ†æé¡¶ç‚¹ä½ç½®
        contour_points = largest_contour.reshape(-1, 2)
        min_y = np.min(contour_points[:, 1])
        tip_y = tip_point[1]
        
        y_diff = abs(tip_y - min_y)
        is_at_top = y_diff <= 15
        
        analysis_results.append({
            'filename': os.path.basename(corrected_path),
            'tip_y': tip_y,
            'min_y': min_y,
            'y_diff': y_diff,
            'is_at_top': is_at_top
        })
        
        status = "âœ… æ­£ç¡®" if is_at_top else "âŒ éœ€è°ƒæ•´"
        print(f"{status} {os.path.basename(corrected_path)}: é¡¶ç‚¹y={tip_y}, æœ€é«˜ç‚¹y={min_y}, å·®å¼‚={y_diff}")
    
    # ç»Ÿè®¡ç»“æœ
    total = len(analysis_results)
    correct = sum(1 for r in analysis_results if r['is_at_top'])
    
    print(f"\nğŸ“ˆ çŸ«æ­£æ•ˆæœç»Ÿè®¡:")
    print(f"æ€»æ•°é‡: {total}")
    print(f"é¡¶ç‚¹ä½ç½®æ­£ç¡®: {correct}")
    print(f"å‡†ç¡®ç‡: {correct/total*100:.1f}%" if total > 0 else "å‡†ç¡®ç‡: 0%")
    
    return analysis_results

if __name__ == "__main__":
    # æ˜¾ç¤ºå¤„ç†è¿‡ç¨‹
    display_improved_results()
    
    # åˆ›å»ºå‰åå¯¹æ¯”
    create_before_after_comparison()
    
    # åˆ†ææ•ˆæœ
    analyze_correction_effectiveness()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ”¹è¿›åçš„ç®­å¤´æ–¹å‘çŸ«æ­£ç³»ç»Ÿå®Œæˆï¼")
    print("ğŸ¯ æ ¸å¿ƒæ”¹è¿›ï¼šç¡®ä¿ç®­å¤´é¡¶ç‚¹ä½äºå›¾åƒæœ€é«˜ä½ç½®")
    print("âœ¨ è¿™æ ·çš„çŸ«æ­£æ›´ç¬¦åˆå®é™…éœ€æ±‚ï¼Œæœ‰åŠ©äºæé«˜OCRè¯†åˆ«å‡†ç¡®ç‡")
    print("=" * 60) 