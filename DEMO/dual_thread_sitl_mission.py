#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒçº¿ç¨‹SITLä»¿çœŸæ‰“å‡»ä»»åŠ¡ç³»ç»Ÿ
ä¸»çº¿ç¨‹ï¼šå®æ—¶YOLOæ£€æµ‹ + GPSæ•°æ®æ”¶é›† + è§†é¢‘æ˜¾ç¤º
å‰¯çº¿ç¨‹ï¼šå›¾åƒè½¬æ­£ + OCRè¯†åˆ« + GPSåæ ‡è®¡ç®—
"""

import time
import sys
import os
import threading
import queue
import json
import cv2
import numpy as np
from dataclasses import dataclass, asdict
from typing import Optional, Tuple, List
from pathlib import Path

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from target_geo_calculator import FlightData, TargetGeoCalculator, TargetInfo
from yolo_trt_utils import YOLOTRTDetector
import easyocr

# MAVLinkç›¸å…³
try:
    from pymavlink import mavutil
    MAVLINK_AVAILABLE = True
    print("âœ… MAVLinkåº“å¯ç”¨")
except ImportError:
    MAVLINK_AVAILABLE = False
    print("âŒ MAVLinkåº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

@dataclass
class DetectionPackage:
    """æ£€æµ‹æ•°æ®åŒ… - ä¸»çº¿ç¨‹ä¼ é€’ç»™å‰¯çº¿ç¨‹çš„æ•°æ®ç»“æ„"""
    frame_id: int
    timestamp: float
    crop_image: np.ndarray
    detection_box: Tuple[int, int, int, int]  # x1, y1, x2, y2
    pixel_center: Tuple[int, int]  # center_x, center_y
    confidence: float
    flight_data: FlightData
    target_id: str

class ImageOrientationCorrector:
    """é«˜ç²¾åº¦å›¾åƒæ–¹å‘æ ¡æ­£å™¨"""
    
    def __init__(self, debug_mode: bool = False):
        self.debug_mode = debug_mode
        self.correction_stats = {
            'total_processed': 0,
            'successful_corrections': 0,
            'failed_corrections': 0
        }
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç†ï¼šåŸºäºçº¢è‰²é¢œè‰²è¯†åˆ«è¿›è¡ŒäºŒå€¼åŒ–"""
        if len(image.shape) != 3:
            return None
        
        # é«˜æ–¯æ»¤æ³¢å»å™ª
        blurred = cv2.GaussianBlur(image, (5, 5), 0)
        
        # å¤šé¢œè‰²ç©ºé—´çº¢è‰²æ£€æµ‹
        red_mask_bgr = self._create_red_mask_bgr(blurred)
        red_mask_hsv = self._create_red_mask_hsv(blurred)
        red_mask_lab = self._create_red_mask_lab(blurred)
        
        # ç»„åˆå¤šä¸ªé¢œè‰²ç©ºé—´çš„ç»“æœ
        combined_mask = cv2.bitwise_or(red_mask_hsv, red_mask_bgr)
        combined_mask = cv2.bitwise_or(combined_mask, red_mask_lab)
        
        # å½¢æ€å­¦æ“ä½œä¼˜åŒ–æ©ç 
        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        kernel_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        
        opened = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel_small)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel_medium)
        dilated = cv2.dilate(closed, kernel_small, iterations=1)
        
        return dilated
    
    def _create_red_mask_bgr(self, image: np.ndarray) -> np.ndarray:
        """åœ¨BGRé¢œè‰²ç©ºé—´ä¸­åˆ›å»ºçº¢è‰²æ©ç """
        lower_red1 = np.array([0, 0, 100])
        upper_red1 = np.array([80, 80, 255])
        lower_red2 = np.array([0, 0, 150])
        upper_red2 = np.array([100, 100, 255])
        
        mask1 = cv2.inRange(image, lower_red1, upper_red1)
        mask2 = cv2.inRange(image, lower_red2, upper_red2)
        return cv2.bitwise_or(mask1, mask2)
    
    def _create_red_mask_hsv(self, image: np.ndarray) -> np.ndarray:
        """åœ¨HSVé¢œè‰²ç©ºé—´ä¸­åˆ›å»ºçº¢è‰²æ©ç """
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        lower_red1 = np.array([0, 50, 50])
        upper_red1 = np.array([10, 255, 255])
        lower_red2 = np.array([170, 50, 50])
        upper_red2 = np.array([180, 255, 255])
        
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        return cv2.bitwise_or(mask1, mask2)
    
    def _create_red_mask_lab(self, image: np.ndarray) -> np.ndarray:
        """åœ¨LABé¢œè‰²ç©ºé—´ä¸­åˆ›å»ºçº¢è‰²æ©ç """
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        lower_red = np.array([20, 150, 150])
        upper_red = np.array([255, 255, 255])
        return cv2.inRange(lab, lower_red, upper_red)
    
    def find_largest_contour(self, binary_image: np.ndarray) -> Optional[np.ndarray]:
        """æ‰¾åˆ°æœ€å¤§çš„è½®å»“"""
        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None
        
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        if area < 100:
            return None
        return largest_contour
    
    def find_tip_point(self, contour: np.ndarray) -> Optional[Tuple[int, int]]:
        """æ‰¾åˆ°è½®å»“çš„å°–ç«¯ç‚¹"""
        if contour is None or len(contour) < 3:
            return None
        
        moments = cv2.moments(contour)
        if moments['m00'] == 0:
            return None
        
        # è®¡ç®—è´¨å¿ƒ
        centroid_x = int(moments['m10'] / moments['m00'])
        centroid_y = int(moments['m01'] / moments['m00'])
        
        # æ‰¾åˆ°è·ç¦»è´¨å¿ƒæœ€è¿œçš„ç‚¹
        max_distance = 0
        tip_point = None
        
        for point in contour:
            x, y = point[0]
            distance = np.sqrt((x - centroid_x)**2 + (y - centroid_y)**2)
            if distance > max_distance:
                max_distance = distance
                tip_point = (x, y)
        
        return tip_point
    
    def calculate_rotation_angle(self, tip_point: Tuple[int, int], 
                               image_center: Tuple[int, int]) -> float:
        """è®¡ç®—ä½¿å°–ç«¯æœä¸Šæ‰€éœ€çš„æ—‹è½¬è§’åº¦"""
        dx = tip_point[0] - image_center[0]
        dy = tip_point[1] - image_center[1]
        angle_rad = np.arctan2(dx, -dy)
        angle_deg = np.degrees(angle_rad)
        return angle_deg
    
    def rotate_image(self, image: np.ndarray, angle: float) -> np.ndarray:
        """æ—‹è½¬å›¾åƒ"""
        center = (image.shape[1] // 2, image.shape[0] // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        
        rotated = cv2.warpAffine(image, rotation_matrix, 
                                (image.shape[1], image.shape[0]),
                                flags=cv2.INTER_LINEAR,
                                borderMode=cv2.BORDER_CONSTANT,
                                borderValue=(255, 255, 255))
        return rotated
    
    def correct_orientation(self, image: np.ndarray) -> Tuple[np.ndarray, dict]:
        """ä¸»è¦çš„æ–¹å‘æ ¡æ­£å‡½æ•°"""
        self.correction_stats['total_processed'] += 1
        
        info = {
            'success': False,
            'rotation_angle': 0,
            'tip_point': None,
            'contour_area': 0,
            'error_message': None
        }
        
        try:
            # é¢„å¤„ç†
            processed = self.preprocess_image(image)
            if processed is None:
                info['error_message'] = "é¢„å¤„ç†å¤±è´¥"
                self.correction_stats['failed_corrections'] += 1
                return image, info
            
            # æ‰¾åˆ°æœ€å¤§è½®å»“
            contour = self.find_largest_contour(processed)
            if contour is None:
                info['error_message'] = "æœªæ‰¾åˆ°æœ‰æ•ˆè½®å»“"
                self.correction_stats['failed_corrections'] += 1
                return image, info
            
            info['contour_area'] = cv2.contourArea(contour)
            
            # æ‰¾åˆ°å°–ç«¯ç‚¹
            tip_point = self.find_tip_point(contour)
            if tip_point is None:
                info['error_message'] = "æœªæ‰¾åˆ°å°–ç«¯ç‚¹"
                self.correction_stats['failed_corrections'] += 1
                return image, info
            
            info['tip_point'] = tip_point
            
            # è®¡ç®—æ—‹è½¬è§’åº¦
            image_center = (image.shape[1] // 2, image.shape[0] // 2)
            angle = self.calculate_rotation_angle(tip_point, image_center)
            info['rotation_angle'] = angle
            
            # æ—‹è½¬å›¾åƒ
            corrected_image = self.rotate_image(image, angle)
            
            info['success'] = True
            self.correction_stats['successful_corrections'] += 1
            
            return corrected_image, info
            
        except Exception as e:
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            info['error_message'] = error_msg
            self.correction_stats['failed_corrections'] += 1
            return image, info
    
    def get_stats(self):
        """è·å–æ ¡æ­£ç»Ÿè®¡ä¿¡æ¯"""
        return self.correction_stats.copy()

class SITLFlightDataProvider:
    """SITLé£è¡Œæ•°æ®æä¾›å™¨"""
    
    def __init__(self, connection_string="tcp:localhost:5760"):
        self.connection_string = connection_string
        self.connection = None
        self.is_connected = False
        self.is_running = False
        self.latest_flight_data = None
        self.data_lock = threading.Lock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.message_count = 0
        self.gps_count = 0
        self.last_heartbeat = 0
        
    def connect(self) -> bool:
        """è¿æ¥åˆ°SITL"""
        if not MAVLINK_AVAILABLE:
            return False
            
        try:
            print(f"ğŸ”— è¿æ¥SITLä»¿çœŸ: {self.connection_string}")
            
            self.connection = mavutil.mavlink_connection(
                self.connection_string,
                source_system=255,
                source_component=0
            )
            
            print("â³ ç­‰å¾…SITLå¿ƒè·³åŒ…...")
            heartbeat = self.connection.wait_heartbeat(timeout=10)
            
            if heartbeat:
                print("âœ… SITLè¿æ¥æˆåŠŸ!")
                self.is_connected = True
                self._request_data_streams()
                self._start_monitoring()
                return True
            else:
                print("âŒ æœªæ”¶åˆ°å¿ƒè·³åŒ…")
                return False
                
        except Exception as e:
            print(f"âŒ SITLè¿æ¥å¤±è´¥: {e}")
            return False
    
    def _request_data_streams(self):
        """è¯·æ±‚æ•°æ®æµ"""
        try:
            # è¯·æ±‚ä½ç½®ä¿¡æ¯ (5Hz)
            self.connection.mav.request_data_stream_send(
                self.connection.target_system,
                self.connection.target_component,
                mavutil.mavlink.MAV_DATA_STREAM_POSITION,
                5, 1
            )
            
            # è¯·æ±‚å§¿æ€ä¿¡æ¯ (10Hz)
            self.connection.mav.request_data_stream_send(
                self.connection.target_system,
                self.connection.target_component,
                mavutil.mavlink.MAV_DATA_STREAM_EXTRA1,
                10, 1
            )
        except Exception as e:
            print(f"âš ï¸ æ•°æ®æµè¯·æ±‚å¤±è´¥: {e}")
    
    def _start_monitoring(self):
        """å¯åŠ¨æ•°æ®ç›‘æ§çº¿ç¨‹"""
        self.is_running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
    
    def _monitor_loop(self):
        """æ•°æ®ç›‘æ§å¾ªç¯"""
        while self.is_running and self.is_connected:
            try:
                msg = self.connection.recv_match(blocking=True, timeout=1)
                if msg is None:
                    continue
                
                self.message_count += 1
                msg_type = msg.get_type()
                
                if msg_type == 'HEARTBEAT':
                    self.last_heartbeat = time.time()
                elif msg_type == 'GLOBAL_POSITION_INT':
                    self._handle_gps_position(msg)
                elif msg_type == 'ATTITUDE':
                    self._handle_attitude(msg)
                    
            except Exception as e:
                print(f"âš ï¸ æ•°æ®ç›‘æ§é”™è¯¯: {e}")
                time.sleep(1)
    
    def _handle_gps_position(self, msg):
        """å¤„ç†GPSä½ç½®ä¿¡æ¯"""
        self.gps_count += 1
        
        flight_data = FlightData(
            timestamp=time.time(),
            latitude=msg.lat / 1e7,
            longitude=msg.lon / 1e7,
            altitude=msg.alt / 1000.0,
            pitch=0.0,
            roll=0.0,
            yaw=0.0,
            ground_speed=np.sqrt(msg.vx**2 + msg.vy**2) / 100.0,
            heading=msg.hdg / 100.0 if msg.hdg != 65535 else 0.0
        )
        
        with self.data_lock:
            if self.latest_flight_data:
                flight_data.pitch = self.latest_flight_data.pitch
                flight_data.roll = self.latest_flight_data.roll
                flight_data.yaw = self.latest_flight_data.yaw
            
            self.latest_flight_data = flight_data
    
    def _handle_attitude(self, msg):
        """å¤„ç†å§¿æ€ä¿¡æ¯"""
        if self.latest_flight_data:
            with self.data_lock:
                self.latest_flight_data.pitch = np.degrees(msg.pitch)
                self.latest_flight_data.roll = np.degrees(msg.roll)
                self.latest_flight_data.yaw = np.degrees(msg.yaw)
    
    def get_current_flight_data(self) -> FlightData:
        """è·å–å½“å‰é£è¡Œæ•°æ®"""
        with self.data_lock:
            if self.latest_flight_data:
                return self.latest_flight_data
            else:
                return FlightData(
                    timestamp=time.time(),
                    latitude=0.0,
                    longitude=0.0,
                    altitude=100.0,
                    pitch=0.0,
                    roll=0.0,
                    yaw=0.0,
                    ground_speed=0.0,
                    heading=0.0
                )
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        self.is_running = False
        self.is_connected = False
        
        if hasattr(self, 'monitor_thread') and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=2)
        
        if self.connection:
            self.connection.close()

class NumberExtractor:
    """æ•°å­—æå–å™¨"""
    def extract_two_digit_numbers(self, text: str) -> List[str]:
        import re
        if not text:
            return []
        numbers = re.findall(r'\b\d{1,2}\b', text)
        return numbers

class DualThreadSITLMission:
    """åŒçº¿ç¨‹SITLä»»åŠ¡ç³»ç»Ÿ"""
    
    def __init__(self, config=None):
        self.config = config or self._default_config()
        
        # ä¸»çº¿ç¨‹ç»„ä»¶
        self.detector = None
        self.flight_data_provider = None
        
        # å‰¯çº¿ç¨‹ç»„ä»¶
        self.orientation_corrector = None
        self.ocr_reader = None
        self.geo_calculator = None
        self.number_extractor = NumberExtractor()
        
        # çº¿ç¨‹é€šä¿¡
        self.detection_queue = queue.Queue(maxsize=100)  # ä¸»çº¿ç¨‹->å‰¯çº¿ç¨‹
        self.result_queue = queue.Queue(maxsize=100)     # å‰¯çº¿ç¨‹->ä¸»çº¿ç¨‹
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.frame_count = 0
        self.detection_count = 0
        self.main_thread_stats = {
            'total_detections': 0,
            'fps': 0,
            'start_time': None
        }
        self.processing_thread_stats = {
            'total_processed': 0,
            'ocr_success': 0,
            'correction_success': 0
        }
        
        # è¿è¡Œæ§åˆ¶
        self.running = False
        self.processing_thread = None
        
        # æ•°æ®å­˜å‚¨
        self.raw_detections = []  # ä¸»çº¿ç¨‹æ”¶é›†çš„åŸå§‹æ£€æµ‹æ•°æ®
        self.processed_results = []  # å‰¯çº¿ç¨‹å¤„ç†åçš„ç»“æœ
        
    def _default_config(self):
        """é»˜è®¤é…ç½®"""
        return {
            'conf_threshold': 0.25,
            'camera_fov_h': 60.0,
            'camera_fov_v': 45.0,
            'min_confidence': 0.5,
            'max_targets_per_frame': 5,
            'raw_data_file': 'raw_detections.json',
            'final_results_file': 'dual_thread_results.json',
            'median_coordinates_file': 'median_coordinates.json'
        }
    
    def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸš€ åˆå§‹åŒ–åŒçº¿ç¨‹SITLä»»åŠ¡ç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–ä¸»çº¿ç¨‹ç»„ä»¶
        print("ğŸ“¡ åˆå§‹åŒ–YOLOæ£€æµ‹å™¨...")
        model_path = self._find_model()
        if not model_path:
            raise RuntimeError("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        
        self.detector = YOLOTRTDetector(
            model_path=model_path, 
            conf_thres=self.config['conf_threshold']
        )
        
        # åˆå§‹åŒ–SITLè¿æ¥
        print("ğŸ›©ï¸ åˆå§‹åŒ–SITLè¿æ¥...")
        self.flight_data_provider = SITLFlightDataProvider()
        
        sitl_connected = False
        try:
            sitl_connected = self.flight_data_provider.connect()
        except Exception as e:
            print(f"âš ï¸ SITLè¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
        
        if not sitl_connected:
            print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿé£è¡Œæ•°æ®æ¨¡å¼")
            self.flight_data_provider = None
        
        # åˆå§‹åŒ–å‰¯çº¿ç¨‹ç»„ä»¶
        print("ğŸ”„ åˆå§‹åŒ–å›¾åƒè½¬æ­£å™¨...")
        self.orientation_corrector = ImageOrientationCorrector(debug_mode=False)
        
        print("ğŸ”¤ åˆå§‹åŒ–OCRè¯†åˆ«å™¨...")
        self.ocr_reader = easyocr.Reader(['en'], gpu=False, download_enabled=True)
        
        print("ğŸ“ åˆå§‹åŒ–åœ°ç†åæ ‡è®¡ç®—å™¨...")
        self.geo_calculator = TargetGeoCalculator(
            camera_fov_h=self.config['camera_fov_h'],
            camera_fov_v=self.config['camera_fov_v']
        )
        
        print("âœ… åŒçº¿ç¨‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    
    def _find_model(self):
        """æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶"""
        # ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹è·¯å¾„
        model_path = "D:/AirmodelingTeam/MISSION_FILE_GROUND_RECOG/weights/best1.pt"
        if os.path.exists(model_path):
            return model_path
            
        # å¤‡ç”¨è·¯å¾„
        possible_paths = [
            "../weights/best1.pt",
            "../weights/best.pt",
            "weights/best1.pt",
            "weights/best.pt",
            "best.engine",
            "../best.engine", 
            "../../best.engine",
            "../SIMPLE_TEST_ZHUANGZHENG/best.engine",
            "best.pt",
            "../best.pt",
            "../../best.pt"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        return None
    
    def start_processing_thread(self):
        """å¯åŠ¨å‰¯çº¿ç¨‹"""
        self.processing_thread = threading.Thread(target=self._processing_loop, daemon=True)
        self.processing_thread.start()
        print("ğŸ”„ å‰¯çº¿ç¨‹å·²å¯åŠ¨")
    
    def _processing_loop(self):
        """å‰¯çº¿ç¨‹å¤„ç†å¾ªç¯"""
        print("ğŸ”„ å‰¯çº¿ç¨‹å¼€å§‹å¤„ç†...")
        
        while self.running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ£€æµ‹æ•°æ®åŒ…
                package = self.detection_queue.get(timeout=1)
                if package is None:  # ç»“æŸä¿¡å·
                    break
                
                # å¤„ç†å›¾åƒè½¬æ­£
                corrected_image, correction_info = self.orientation_corrector.correct_orientation(package.crop_image)
                
                # å¤„ç†OCRè¯†åˆ«
                ocr_text = ""
                try:
                    ocr_results = self.ocr_reader.readtext(corrected_image)
                    if ocr_results:
                        ocr_text = ' '.join([result[1] for result in ocr_results])
                        self.processing_thread_stats['ocr_success'] += 1
                except Exception as e:
                    pass
                
                # æå–æ•°å­—
                numbers = self.number_extractor.extract_two_digit_numbers(ocr_text)
                detected_number = numbers[0] if numbers else "æœªè¯†åˆ«"
                
                # è®¡ç®—å®é™…GPSåæ ‡
                target_lat, target_lon = self.geo_calculator.calculate_target_position(
                    package.pixel_center[0], package.pixel_center[1], package.flight_data
                )
                
                # åˆ›å»ºæœ€ç»ˆç»“æœ
                result = TargetInfo(
                    target_id=package.target_id,
                    detected_number=detected_number,
                    pixel_x=package.pixel_center[0],
                    pixel_y=package.pixel_center[1],
                    confidence=package.confidence,
                    latitude=target_lat,
                    longitude=target_lon,
                    flight_data=package.flight_data,
                    timestamp=package.timestamp
                )
                
                # ä¿å­˜å¤„ç†ç»“æœ
                self.processed_results.append(result)
                self.processing_thread_stats['total_processed'] += 1
                
                if correction_info['success']:
                    self.processing_thread_stats['correction_success'] += 1
                
                # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—ï¼ˆç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰
                try:
                    self.result_queue.put_nowait({
                        'target_info': result,
                        'correction_info': correction_info,
                        'corrected_image': corrected_image
                    })
                except queue.Full:
                    pass  # é˜Ÿåˆ—æ»¡æ—¶å¿½ç•¥
                
                self.detection_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"å‰¯çº¿ç¨‹å¤„ç†é”™è¯¯: {e}")
                continue
        
        print("ğŸ”„ å‰¯çº¿ç¨‹å¤„ç†å®Œæˆ")
    
    def run_video_mission(self, video_source):
        """è¿è¡Œè§†é¢‘ä»»åŠ¡"""
        print(f"ğŸ¯ å¼€å§‹åŒçº¿ç¨‹ä»»åŠ¡ï¼Œè§†é¢‘æº: {video_source}")
        
        # æ‰“å¼€è§†é¢‘æº
        cap = cv2.VideoCapture(video_source)
        if not cap.isOpened():
            raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
        
        # è®¾ç½®çª—å£
        cv2.namedWindow("åŒçº¿ç¨‹SITLä»»åŠ¡", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("åŒçº¿ç¨‹SITLä»»åŠ¡", 1280, 720)
        
        self.running = True
        self.main_thread_stats['start_time'] = time.time()
        
        # å¯åŠ¨å‰¯çº¿ç¨‹
        self.start_processing_thread()
        
        print("ğŸ“‹ ä»»åŠ¡æ§åˆ¶:")
        print("  'q' - é€€å‡ºä»»åŠ¡")
        print("  's' - ä¿å­˜å½“å‰æ•°æ®")
        
        try:
            while self.running:
                ret, frame = cap.read()
                if not ret:
                    print("è§†é¢‘è¯»å–ç»“æŸ")
                    break
                
                # ä¸»çº¿ç¨‹å¤„ç†ï¼šYOLOæ£€æµ‹ + æ•°æ®æ”¶é›†
                processed_frame = self._main_thread_process(frame)
                
                # æ˜¾ç¤ºç»“æœ
                cv2.imshow("åŒçº¿ç¨‹SITLä»»åŠ¡", processed_frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    self._save_current_data()
                
        except KeyboardInterrupt:
            print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self._cleanup(cap)
    
    def _main_thread_process(self, frame):
        """ä¸»çº¿ç¨‹å¤„ç†ï¼šå®æ—¶YOLOæ£€æµ‹å’Œæ•°æ®æ”¶é›†"""
        self.frame_count += 1
        current_time = time.time()
        
        # è·å–é£è¡Œæ•°æ®
        if self.flight_data_provider:
            flight_data = self.flight_data_provider.get_current_flight_data()
        else:
            # æ¨¡æ‹Ÿé£è¡Œæ•°æ®
            flight_data = FlightData(
                timestamp=current_time,
                latitude=39.7392 + (self.frame_count * 0.0001),
                longitude=116.4074 + (self.frame_count * 0.0001),
                altitude=100.0,
                pitch=0.0,
                roll=0.0,
                yaw=45.0,
                ground_speed=15.0,
                heading=45.0
            )
        
        # YOLOæ£€æµ‹
        detections = self.detector.detect(frame)
        self.main_thread_stats['total_detections'] += len(detections)
        
        height, width = frame.shape[:2]
        self.geo_calculator.image_height = height
        self.geo_calculator.image_width = width
        
        processed_frame = frame.copy()
        current_targets = 0
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        max_targets = min(len(detections), self.config['max_targets_per_frame'])
        
        for i, det in enumerate(detections[:max_targets]):
            if det['confidence'] < self.config['min_confidence']:
                continue
                
            x1, y1, x2, y2 = map(int, det['box'])
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            
            try:
                # æ‰©å±•æ£€æµ‹æ¡†å¹¶è£å‰ªå›¾åƒ
                expand_ratio = 0.1
                w, h = x2 - x1, y2 - y1
                x1_exp = max(0, x1 - int(w * expand_ratio))
                y1_exp = max(0, y1 - int(h * expand_ratio))
                x2_exp = min(width, x2 + int(w * expand_ratio))
                y2_exp = min(height, y2 + int(h * expand_ratio))
                
                crop = frame[y1_exp:y2_exp, x1_exp:x2_exp].copy()
                if crop.size == 0:
                    continue
                
                # åˆ›å»ºæ£€æµ‹æ•°æ®åŒ…
                target_id = f"DT_T{self.detection_count:04d}"
                package = DetectionPackage(
                    frame_id=self.frame_count,
                    timestamp=current_time,
                    crop_image=crop,
                    detection_box=(x1, y1, x2, y2),
                    pixel_center=(center_x, center_y),
                    confidence=det['confidence'],
                    flight_data=flight_data,
                    target_id=target_id
                )
                
                # ä¿å­˜åŸå§‹æ£€æµ‹æ•°æ®
                raw_detection = {
                    'target_id': target_id,
                    'frame_id': self.frame_count,
                    'timestamp': current_time,
                    'detection_box': (x1, y1, x2, y2),
                    'pixel_center': (center_x, center_y),
                    'confidence': det['confidence'],
                    'flight_data': asdict(flight_data)
                }
                self.raw_detections.append(raw_detection)
                
                # å‘é€åˆ°å‰¯çº¿ç¨‹å¤„ç†é˜Ÿåˆ—
                try:
                    self.detection_queue.put_nowait(package)
                except queue.Full:
                    print("âš ï¸ æ£€æµ‹é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡å½“å‰ç›®æ ‡")
                
                # åœ¨ä¸»ç”»é¢ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                self._draw_main_detection(processed_frame, x1, y1, x2, y2, 
                                        target_id, det['confidence'])
                
                self.detection_count += 1
                current_targets += 1
                
            except Exception as e:
                print(f"å¤„ç†ç›®æ ‡ {i} æ—¶å‡ºé”™: {e}")
                continue
        
        # ç»˜åˆ¶å®æ—¶ä¿¡æ¯
        self._draw_main_thread_info(processed_frame, flight_data, current_targets)
        
        return processed_frame
    
    def _draw_main_detection(self, frame, x1, y1, x2, y2, target_id, confidence):
        """ç»˜åˆ¶ä¸»çº¿ç¨‹æ£€æµ‹ç»“æœ"""
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # ç»˜åˆ¶ç›®æ ‡ä¿¡æ¯
        info_text = f"ID:{target_id} Conf:{confidence:.2f}"
        cv2.putText(frame, info_text, (x1, y1 - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        # ç»˜åˆ¶çŠ¶æ€ï¼ˆç­‰å¾…å¤„ç†ï¼‰
        cv2.putText(frame, "ç­‰å¾…å¤„ç†...", (x1, y2 + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
    
    def _draw_main_thread_info(self, frame, flight_data, current_targets):
        """ç»˜åˆ¶ä¸»çº¿ç¨‹ä¿¡æ¯"""
        # è®¡ç®—FPS
        if self.main_thread_stats['start_time']:
            elapsed = time.time() - self.main_thread_stats['start_time']
            fps = self.frame_count / elapsed if elapsed > 0 else 0
            self.main_thread_stats['fps'] = fps
        else:
            fps = 0
        
        # é£è¡Œä¿¡æ¯
        mode_text = "ğŸ›©ï¸ SITLæ¨¡å¼" if self.flight_data_provider else "ğŸ® æ¨¡æ‹Ÿæ¨¡å¼"
        info_lines = [
            f"{mode_text}",
            f"GPS: {flight_data.latitude:.6f}, {flight_data.longitude:.6f}",
            f"é«˜åº¦: {flight_data.altitude:.1f}m",
            f"é€Ÿåº¦: {flight_data.ground_speed:.1f}m/s",
            f"å¸§æ•°: {self.frame_count} FPS: {fps:.1f}",
            f"å½“å‰ç›®æ ‡: {current_targets}",
            f"æ€»æ£€æµ‹: {self.main_thread_stats['total_detections']}",
            f"é˜Ÿåˆ—: {self.detection_queue.qsize()}/{self.detection_queue.maxsize}"
        ]
        
        for i, line in enumerate(info_lines):
            color = (0, 255, 0) if self.flight_data_provider else (255, 165, 0)
            if i >= 4:  # ç»Ÿè®¡ä¿¡æ¯ç”¨ç™½è‰²
                color = (255, 255, 255)
            cv2.putText(frame, line, (10, 25 + i * 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # å‰¯çº¿ç¨‹ç»Ÿè®¡ä¿¡æ¯
        stats_lines = [
            f"ğŸ”„ å‰¯çº¿ç¨‹ç»Ÿè®¡:",
            f"å·²å¤„ç†: {self.processing_thread_stats['total_processed']}",
            f"è½¬æ­£æˆåŠŸ: {self.processing_thread_stats['correction_success']}",
            f"OCRæˆåŠŸ: {self.processing_thread_stats['ocr_success']}"
        ]
        
        for i, line in enumerate(stats_lines):
            cv2.putText(frame, line, (frame.shape[1] - 250, 25 + i * 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
    
    def _save_current_data(self):
        """ä¿å­˜å½“å‰æ•°æ®"""
        try:
            # ä¿å­˜åŸå§‹æ£€æµ‹æ•°æ®
            with open(self.config['raw_data_file'], 'w', encoding='utf-8') as f:
                json.dump(self.raw_detections, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜å¤„ç†ç»“æœ
            processed_data = []
            for result in self.processed_results:
                processed_data.append({
                    'target_id': result.target_id,
                    'detected_number': result.detected_number,
                    'pixel_position': {'x': result.pixel_x, 'y': result.pixel_y},
                    'confidence': result.confidence,
                    'gps_position': {'latitude': result.latitude, 'longitude': result.longitude},
                    'flight_data': asdict(result.flight_data),
                    'detection_timestamp': result.timestamp
                })
            
            with open(self.config['final_results_file'], 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ•°æ®å·²ä¿å­˜:")
            print(f"   åŸå§‹æ£€æµ‹: {len(self.raw_detections)} æ¡ -> {self.config['raw_data_file']}")
            print(f"   å¤„ç†ç»“æœ: {len(self.processed_results)} æ¡ -> {self.config['final_results_file']}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
    
    def _calculate_median_coordinates(self):
        """è®¡ç®—ä¸­ä½æ•°åæ ‡"""
        if not self.processed_results:
            print("âš ï¸ æ²¡æœ‰å¤„ç†ç»“æœï¼Œæ— æ³•è®¡ç®—ä¸­ä½æ•°åæ ‡")
            return
        
        # æå–æ‰€æœ‰æœ‰æ•ˆçš„GPSåæ ‡
        valid_coords = []
        for result in self.processed_results:
            if result.latitude != 0 and result.longitude != 0:
                valid_coords.append((result.latitude, result.longitude))
        
        if not valid_coords:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„GPSåæ ‡")
            return
        
        # è®¡ç®—ä¸­ä½æ•°
        lats = sorted([coord[0] for coord in valid_coords])
        lons = sorted([coord[1] for coord in valid_coords])
        
        n = len(valid_coords)
        if n % 2 == 0:
            median_lat = (lats[n//2-1] + lats[n//2]) / 2
            median_lon = (lons[n//2-1] + lons[n//2]) / 2
        else:
            median_lat = lats[n//2]
            median_lon = lons[n//2]
        
        median_coords = {
            'median_latitude': median_lat,
            'median_longitude': median_lon,
            'total_targets': len(valid_coords),
            'calculation_time': time.time()
        }
        
        # ä¿å­˜ä¸­ä½æ•°åæ ‡
        with open(self.config['median_coordinates_file'], 'w', encoding='utf-8') as f:
            json.dump(median_coords, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ ä¸­ä½æ•°åæ ‡è®¡ç®—å®Œæˆ:")
        print(f"   çº¬åº¦: {median_lat:.8f}")
        print(f"   ç»åº¦: {median_lon:.8f}")
        print(f"   åŸºäº {len(valid_coords)} ä¸ªæœ‰æ•ˆç›®æ ‡")
        print(f"   ä¿å­˜åˆ°: {self.config['median_coordinates_file']}")
        
        return median_coords
    
    def _cleanup(self, cap):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†èµ„æº...")
        
        # åœæ­¢ä¸»çº¿ç¨‹
        self.running = False
        
        # ç­‰å¾…å‰¯çº¿ç¨‹å¤„ç†å®Œæˆ
        print("â³ ç­‰å¾…å‰¯çº¿ç¨‹å®Œæˆå¤„ç†...")
        
        # å‘é€ç»“æŸä¿¡å·ç»™å‰¯çº¿ç¨‹
        try:
            self.detection_queue.put(None, timeout=1)
        except queue.Full:
            pass
        
        # ç­‰å¾…å‰¯çº¿ç¨‹ç»“æŸ
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=5)
        
        # ä¿å­˜æœ€ç»ˆæ•°æ®
        self._save_current_data()
        
        # è®¡ç®—ä¸­ä½æ•°åæ ‡
        median_coords = self._calculate_median_coordinates()
        
        # æ–­å¼€SITLè¿æ¥
        if self.flight_data_provider:
            self.flight_data_provider.disconnect()
        
        # é‡Šæ”¾è§†é¢‘èµ„æº
        cap.release()
        cv2.destroyAllWindows()
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        print("\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
        print(f"  ğŸ¯ ä¸»çº¿ç¨‹:")
        print(f"    å¤„ç†å¸§æ•°: {self.frame_count}")
        print(f"    æ£€æµ‹æ€»æ•°: {self.main_thread_stats['total_detections']}")
        print(f"    å¹³å‡FPS: {self.main_thread_stats['fps']:.1f}")
        
        print(f"  ğŸ”„ å‰¯çº¿ç¨‹:")
        print(f"    å¤„ç†ç›®æ ‡: {self.processing_thread_stats['total_processed']}")
        print(f"    è½¬æ­£æˆåŠŸ: {self.processing_thread_stats['correction_success']}")
        print(f"    OCRæˆåŠŸ: {self.processing_thread_stats['ocr_success']}")
        
        if self.main_thread_stats['start_time']:
            elapsed = time.time() - self.main_thread_stats['start_time']
            print(f"  æ€»è¿è¡Œæ—¶é—´: {elapsed:.1f}ç§’")
        
        print("âœ… åŒçº¿ç¨‹ä»»åŠ¡å®Œæˆ!")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›©ï¸ åŒçº¿ç¨‹SITLä»¿çœŸæ‰“å‡»ä»»åŠ¡ç³»ç»Ÿ")
    print("=" * 60)
    
    # ä»»åŠ¡é…ç½®
    config = {
        'conf_threshold': 0.25,
        'camera_fov_h': 60.0,
        'camera_fov_v': 45.0,
        'min_confidence': 0.5,
        'max_targets_per_frame': 5,
        'raw_data_file': 'raw_detections.json',
        'final_results_file': 'dual_thread_results.json',
        'median_coordinates_file': 'median_coordinates.json'
    }
    
    # è§†é¢‘æº
    video_source = "D:/AirmodelingTeam/MISSION_FILE_GROUND_RECOG/video2.mp4"
    
    print("ğŸ“‹ åŒçº¿ç¨‹é…ç½®:")
    print(f"  è§†é¢‘æº: {video_source}")
    print(f"  åŸå§‹æ•°æ®: {config['raw_data_file']}")
    print(f"  å¤„ç†ç»“æœ: {config['final_results_file']}")
    print(f"  ä¸­ä½æ•°åæ ‡: {config['median_coordinates_file']}")
    print()
    
    # åˆ›å»ºä»»åŠ¡ç³»ç»Ÿ
    mission = DualThreadSITLMission(config)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        mission.initialize()
        
        print(f"\nğŸ¯ å¼€å§‹åŒçº¿ç¨‹ä»»åŠ¡...")
        print("çº¿ç¨‹åˆ†å·¥:")
        print("  ğŸ¯ ä¸»çº¿ç¨‹: YOLOæ£€æµ‹ + GPSæ”¶é›† + å®æ—¶æ˜¾ç¤º")
        print("  ğŸ”„ å‰¯çº¿ç¨‹: å›¾åƒè½¬æ­£ + OCRè¯†åˆ« + GPSè®¡ç®—")
        print()
        
        mission.run_video_mission(video_source)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ä»»åŠ¡")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 