#!/usr/bin/env python3
# performance_test.py
# æ€§èƒ½å¯¹æ¯”æµ‹è¯•è„šæœ¬

import cv2
import numpy as np
import time
import os
import sys
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor
import threading

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'LATEST_CODE'))

try:
    from yolo_trt_utils_optimized import JetsonOptimizedYOLODetector
    from yolo_trt_utils import YOLOTRTDetector  # åŸç‰ˆæ£€æµ‹å™¨
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿ç›¸å…³æ¨¡å—åœ¨æ­£ç¡®è·¯å¾„ä¸­")
    sys.exit(1)

# å°è¯•å¯¼å…¥Jetsonç›‘æ§
try:
    from jtop import jtop
    JTOP_AVAILABLE = True
except ImportError:
    JTOP_AVAILABLE = False

class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_images = []
        self.results = {}
        self.jetson_stats = {}
        
    def generate_test_images(self, count=100, size=(640, 640)):
        """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
        print(f"ğŸ“¸ ç”Ÿæˆ {count} å¼ æµ‹è¯•å›¾åƒ...")
        self.test_images = []
        
        for i in range(count):
            # ç”Ÿæˆéšæœºå›¾åƒ
            img = np.random.randint(0, 255, (*size, 3), dtype=np.uint8)
            
            # æ·»åŠ ä¸€äº›å‡ ä½•å½¢çŠ¶ä»¥æ¨¡æ‹ŸçœŸå®åœºæ™¯
            cv2.rectangle(img, (100, 100), (200, 200), (0, 255, 0), 2)
            cv2.circle(img, (300, 300), 50, (255, 0, 0), -1)
            cv2.putText(img, f"TEST{i}", (400, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            self.test_images.append(img)
        
        print(f"âœ… æµ‹è¯•å›¾åƒç”Ÿæˆå®Œæˆ")
    
    def load_real_images(self, image_dir):
        """åŠ è½½çœŸå®å›¾åƒ"""
        if not os.path.exists(image_dir):
            print(f"âš ï¸  å›¾åƒç›®å½•ä¸å­˜åœ¨: {image_dir}")
            return
        
        print(f"ğŸ“ ä» {image_dir} åŠ è½½çœŸå®å›¾åƒ...")
        image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        for img_file in image_files[:50]:  # æœ€å¤šåŠ è½½50å¼ 
            img_path = os.path.join(image_dir, img_file)
            img = cv2.imread(img_path)
            if img is not None:
                # è°ƒæ•´å¤§å°åˆ°æ ‡å‡†å°ºå¯¸
                img = cv2.resize(img, (640, 640))
                self.test_images.append(img)
        
        print(f"âœ… åŠ è½½äº† {len(self.test_images)} å¼ çœŸå®å›¾åƒ")
    
    def test_detector_performance(self, detector, detector_name, warmup_runs=5, test_runs=100):
        """æµ‹è¯•æ£€æµ‹å™¨æ€§èƒ½"""
        print(f"\nğŸ”§ æµ‹è¯• {detector_name} æ€§èƒ½...")
        
        if not self.test_images:
            print("âŒ æ²¡æœ‰æµ‹è¯•å›¾åƒ")
            return None
        
        # é¢„çƒ­
        print(f"ğŸ”¥ é¢„çƒ­ {warmup_runs} æ¬¡...")
        for i in range(warmup_runs):
            detector.detect(self.test_images[i % len(self.test_images)])
        
        # æ€§èƒ½æµ‹è¯•
        print(f"â±ï¸  æ‰§è¡Œ {test_runs} æ¬¡æ¨ç†æµ‹è¯•...")
        inference_times = []
        detection_counts = []
        
        start_time = time.time()
        
        for i in range(test_runs):
            img = self.test_images[i % len(self.test_images)]
            
            # å•æ¬¡æ¨ç†è®¡æ—¶
            single_start = time.time()
            detections = detector.detect(img)
            single_time = time.time() - single_start
            
            inference_times.append(single_time)
            detection_counts.append(len(detections))
            
            if (i + 1) % 20 == 0:
                print(f"   å®Œæˆ {i + 1}/{test_runs} æ¬¡æµ‹è¯•...")
        
        total_time = time.time() - start_time
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_inference_time = sum(inference_times) / len(inference_times)
        min_inference_time = min(inference_times)
        max_inference_time = max(inference_times)
        fps = 1.0 / avg_inference_time
        total_fps = test_runs / total_time
        avg_detections = sum(detection_counts) / len(detection_counts)
        
        results = {
            'detector_name': detector_name,
            'total_time': total_time,
            'avg_inference_time': avg_inference_time,
            'min_inference_time': min_inference_time,
            'max_inference_time': max_inference_time,
            'fps': fps,
            'total_fps': total_fps,
            'avg_detections': avg_detections,
            'inference_times': inference_times,
            'detection_counts': detection_counts
        }
        
        # è·å–æ£€æµ‹å™¨ç‰¹å®šç»Ÿè®¡
        if hasattr(detector, 'get_performance_stats'):
            detector_stats = detector.get_performance_stats()
            results.update(detector_stats)
        
        self.results[detector_name] = results
        
        print(f"âœ… {detector_name} æµ‹è¯•å®Œæˆ:")
        print(f"   - å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f}ms")
        print(f"   - å¹³å‡FPS: {fps:.2f}")
        print(f"   - æ€»ä½“FPS: {total_fps:.2f}")
        print(f"   - å¹³å‡æ£€æµ‹æ•°é‡: {avg_detections:.1f}")
        
        return results
    
    def monitor_jetson_during_test(self, duration=60):
        """åœ¨æµ‹è¯•æœŸé—´ç›‘æ§JetsonçŠ¶æ€"""
        if not JTOP_AVAILABLE:
            return
        
        print(f"ğŸ“Š å¼€å§‹ç›‘æ§JetsonçŠ¶æ€ ({duration}ç§’)...")
        
        def monitor():
            stats_history = []
            start_time = time.time()
            
            try:
                with jtop() as jetson:
                    while time.time() - start_time < duration:
                        if jetson.ok():
                            stats = {
                                'timestamp': time.time() - start_time,
                                'gpu_usage': jetson.gpu.get('GR3D', {}).get('val', 0),
                                'cpu_usage': sum(jetson.cpu.values()) / len(jetson.cpu),
                                'memory_used': jetson.memory['RAM']['used'],
                                'memory_total': jetson.memory['RAM']['tot'],
                                'temperature': jetson.temperature.get('CPU', 0),
                                'power': jetson.power.get('cur', 0)
                            }
                            stats_history.append(stats)
                        
                        time.sleep(1)
                
                self.jetson_stats = stats_history
                
            except Exception as e:
                print(f"Jetsonç›‘æ§é”™è¯¯: {e}")
        
        monitor_thread = threading.Thread(target=monitor)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        return monitor_thread
    
    def compare_detectors(self, detectors):
        """å¯¹æ¯”å¤šä¸ªæ£€æµ‹å™¨"""
        print("\nğŸ” å¼€å§‹æ£€æµ‹å™¨æ€§èƒ½å¯¹æ¯”...")
        
        # å¼€å§‹Jetsonç›‘æ§
        monitor_thread = None
        if JTOP_AVAILABLE:
            monitor_thread = self.monitor_jetson_during_test(duration=len(detectors) * 120)
        
        # æµ‹è¯•æ¯ä¸ªæ£€æµ‹å™¨
        for detector_name, detector in detectors.items():
            try:
                self.test_detector_performance(detector, detector_name)
            except Exception as e:
                print(f"âŒ æµ‹è¯• {detector_name} æ—¶å‡ºé”™: {e}")
        
        # ç­‰å¾…ç›‘æ§ç»“æŸ
        if monitor_thread:
            monitor_thread.join(timeout=5)
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self.generate_comparison_report()
    
    def generate_comparison_report(self):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š...")
        
        if len(self.results) < 2:
            print("âš ï¸  éœ€è¦è‡³å°‘2ä¸ªæ£€æµ‹å™¨çš„ç»“æœæ‰èƒ½å¯¹æ¯”")
            return
        
        # æ‰“å°å¯¹æ¯”è¡¨æ ¼
        print("\n" + "="*80)
        print("æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š")
        print("="*80)
        
        # è¡¨å¤´
        print(f"{'æ£€æµ‹å™¨':<20} {'å¹³å‡æ¨ç†æ—¶é—´(ms)':<15} {'FPS':<10} {'æ€»ä½“FPS':<10} {'å¹³å‡æ£€æµ‹æ•°':<10} {'TensorRT':<10}")
        print("-" * 80)
        
        # æ•°æ®è¡Œ
        for name, result in self.results.items():
            using_trt = result.get('using_tensorrt', False)
            print(f"{name:<20} {result['avg_inference_time']*1000:<15.2f} {result['fps']:<10.2f} "
                  f"{result['total_fps']:<10.2f} {result['avg_detections']:<10.1f} {using_trt:<10}")
        
        # è®¡ç®—æ€§èƒ½æå‡
        if len(self.results) == 2:
            results_list = list(self.results.values())
            baseline = results_list[0]
            optimized = results_list[1]
            
            speedup = baseline['avg_inference_time'] / optimized['avg_inference_time']
            fps_improvement = (optimized['fps'] - baseline['fps']) / baseline['fps'] * 100
            
            print(f"\nğŸš€ æ€§èƒ½æå‡:")
            print(f"   - æ¨ç†é€Ÿåº¦æå‡: {speedup:.2f}x")
            print(f"   - FPSæå‡: {fps_improvement:.1f}%")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        self.save_detailed_results()
        
        # ç”Ÿæˆå›¾è¡¨
        self.plot_performance_comparison()
    
    def save_detailed_results(self):
        """ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶"""
        import json
        
        results_file = "performance_test_results.json"
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
        serializable_results = {}
        for name, result in self.results.items():
            serializable_results[name] = {
                k: v for k, v in result.items() 
                if k not in ['inference_times', 'detection_counts']  # æ’é™¤å¤§æ•°ç»„
            }
            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯è€Œä¸æ˜¯åŸå§‹æ•°æ®
            serializable_results[name]['inference_time_std'] = np.std(result['inference_times'])
            serializable_results[name]['detection_count_std'] = np.std(result['detection_counts'])
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                'results': serializable_results,
                'jetson_stats_summary': self._summarize_jetson_stats(),
                'test_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def _summarize_jetson_stats(self):
        """æ±‡æ€»Jetsonç»Ÿè®¡ä¿¡æ¯"""
        if not self.jetson_stats:
            return {}
        
        summary = {}
        for key in ['gpu_usage', 'cpu_usage', 'temperature', 'power']:
            values = [stat[key] for stat in self.jetson_stats if key in stat]
            if values:
                summary[key] = {
                    'avg': sum(values) / len(values),
                    'max': max(values),
                    'min': min(values)
                }
        
        return summary
    
    def plot_performance_comparison(self):
        """ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        try:
            import matplotlib.pyplot as plt
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial']  # æ”¯æŒä¸­æ–‡
            plt.rcParams['axes.unicode_minus'] = False
            
            if len(self.results) < 2:
                return
            
            # åˆ›å»ºå­å›¾
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('YOLOæ£€æµ‹å™¨æ€§èƒ½å¯¹æ¯”', fontsize=16)
            
            names = list(self.results.keys())
            
            # 1. æ¨ç†æ—¶é—´å¯¹æ¯”
            inference_times = [self.results[name]['avg_inference_time'] * 1000 for name in names]
            ax1.bar(names, inference_times, color=['blue', 'red'])
            ax1.set_title('å¹³å‡æ¨ç†æ—¶é—´å¯¹æ¯”')
            ax1.set_ylabel('æ—¶é—´ (ms)')
            ax1.tick_params(axis='x', rotation=45)
            
            # 2. FPSå¯¹æ¯”
            fps_values = [self.results[name]['fps'] for name in names]
            ax2.bar(names, fps_values, color=['green', 'orange'])
            ax2.set_title('FPSå¯¹æ¯”')
            ax2.set_ylabel('FPS')
            ax2.tick_params(axis='x', rotation=45)
            
            # 3. æ¨ç†æ—¶é—´åˆ†å¸ƒï¼ˆå¦‚æœæœ‰è¯¦ç»†æ•°æ®ï¼‰
            if 'inference_times' in self.results[names[0]]:
                for i, name in enumerate(names):
                    times = np.array(self.results[name]['inference_times']) * 1000
                    ax3.hist(times, bins=30, alpha=0.7, label=name)
                ax3.set_title('æ¨ç†æ—¶é—´åˆ†å¸ƒ')
                ax3.set_xlabel('æ—¶é—´ (ms)')
                ax3.set_ylabel('é¢‘æ¬¡')
                ax3.legend()
            
            # 4. Jetsonèµ„æºä½¿ç”¨æƒ…å†µ
            if self.jetson_stats:
                timestamps = [stat['timestamp'] for stat in self.jetson_stats]
                gpu_usage = [stat['gpu_usage'] for stat in self.jetson_stats]
                cpu_usage = [stat['cpu_usage'] for stat in self.jetson_stats]
                
                ax4.plot(timestamps, gpu_usage, label='GPUä½¿ç”¨ç‡', color='red')
                ax4.plot(timestamps, cpu_usage, label='CPUä½¿ç”¨ç‡', color='blue')
                ax4.set_title('Jetsonèµ„æºä½¿ç”¨æƒ…å†µ')
                ax4.set_xlabel('æ—¶é—´ (s)')
                ax4.set_ylabel('ä½¿ç”¨ç‡ (%)')
                ax4.legend()
            
            plt.tight_layout()
            plt.savefig('performance_comparison.png', dpi=300, bbox_inches='tight')
            print("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜åˆ°: performance_comparison.png")
            
        except ImportError:
            print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
        except Exception as e:
            print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ YOLOæ£€æµ‹å™¨æ€§èƒ½æµ‹è¯•å·¥å…·")
    print("="*50)
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    possible_model_dirs = [
        "../weights",
        "weights", 
        "../ready/weights",
        "D:/AirmodelingTeam/CQU_Ground_Recog_Strile_YoloOcr/weights"
    ]
    
    model_dir = None
    for path in possible_model_dirs:
        if os.path.exists(path):
            model_dir = path
            break
    
    if model_dir is None:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹ç›®å½•")
        return
    
    # å‡†å¤‡æ¨¡å‹è·¯å¾„
    pt_model_path = os.path.join(model_dir, "best1.pt")
    trt_model_path = os.path.join(model_dir, "best1.engine")
    
    if not os.path.exists(pt_model_path):
        print(f"âŒ æœªæ‰¾åˆ°PyTorchæ¨¡å‹: {pt_model_path}")
        return
    
    # åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•å™¨
    tester = PerformanceTester()
    
    # ç”Ÿæˆæµ‹è¯•å›¾åƒ
    tester.generate_test_images(count=50, size=(640, 640))
    
    # å°è¯•åŠ è½½çœŸå®å›¾åƒ
    test_image_dirs = ["../datasets/test/images", "test_images", "images"]
    for img_dir in test_image_dirs:
        if os.path.exists(img_dir):
            tester.load_real_images(img_dir)
            break
    
    # å‡†å¤‡æ£€æµ‹å™¨
    detectors = {}
    
    # åŸç‰ˆæ£€æµ‹å™¨
    try:
        print("ğŸ”§ åˆå§‹åŒ–åŸç‰ˆæ£€æµ‹å™¨...")
        original_detector = YOLOTRTDetector(pt_model_path, conf_thres=0.25, use_trt=False)
        detectors["åŸç‰ˆPyTorch"] = original_detector
    except Exception as e:
        print(f"âš ï¸  åŸç‰ˆæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # TensorRTä¼˜åŒ–æ£€æµ‹å™¨
    try:
        print("ğŸ”§ åˆå§‹åŒ–TensorRTä¼˜åŒ–æ£€æµ‹å™¨...")
        if os.path.exists(trt_model_path):
            optimized_detector = JetsonOptimizedYOLODetector(trt_model_path, conf_thres=0.25)
        else:
            optimized_detector = JetsonOptimizedYOLODetector(pt_model_path, conf_thres=0.25)
        detectors["TensorRTä¼˜åŒ–"] = optimized_detector
    except Exception as e:
        print(f"âš ï¸  TensorRTæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    if not detectors:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ£€æµ‹å™¨")
        return
    
    # æ‰§è¡Œæ€§èƒ½å¯¹æ¯”
    tester.compare_detectors(detectors)
    
    print("\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main() 