#!/usr/bin/env python3
# tensorrt_test.py
# TensorRTåŠŸèƒ½éªŒè¯è„šæœ¬ - é’ˆå¯¹Jetsonè®¾å¤‡ä¼˜åŒ–

import sys
import os
import time
import numpy as np
import subprocess
import psutil
import gc
from pathlib import Path

def check_jetson_device():
    """æ£€æŸ¥æ˜¯å¦ä¸ºJetsonè®¾å¤‡"""
    print("ğŸ” æ£€æŸ¥è®¾å¤‡ç±»å‹")
    print("-" * 40)
    
    try:
        # æ£€æŸ¥è®¾å¤‡æ ‘æ–‡ä»¶
        if os.path.exists('/proc/device-tree/model'):
            with open('/proc/device-tree/model', 'r') as f:
                model = f.read().strip('\x00')
                if 'jetson' in model.lower():
                    print(f"âœ… æ£€æµ‹åˆ°Jetsonè®¾å¤‡: {model}")
                    return True, model
        
        # æ£€æŸ¥CPUä¿¡æ¯
        with open('/proc/cpuinfo', 'r') as f:
            cpuinfo = f.read()
            if 'tegra' in cpuinfo.lower() or 'nvidia' in cpuinfo.lower():
                print("âœ… æ£€æµ‹åˆ°Jetsonè®¾å¤‡ (é€šè¿‡CPUä¿¡æ¯)")
                return True, "Jetsonè®¾å¤‡"
        
        print("âš ï¸  æœªæ£€æµ‹åˆ°Jetsonè®¾å¤‡ï¼Œä½†å¯èƒ½æ˜¯Jetson")
        return False, "æœªçŸ¥è®¾å¤‡"
        
    except Exception as e:
        print(f"âŒ è®¾å¤‡æ£€æŸ¥å¤±è´¥: {e}")
        return False, "æ£€æŸ¥å¤±è´¥"

def check_memory_status():
    """æ£€æŸ¥å†…å­˜çŠ¶æ€"""
    print("\nğŸ’¾ å†…å­˜çŠ¶æ€æ£€æŸ¥")
    print("-" * 40)
    
    # è·å–å†…å­˜ä¿¡æ¯
    memory = psutil.virtual_memory()
    swap = psutil.swap_memory()
    
    total_gb = memory.total / (1024**3)
    available_gb = memory.available / (1024**3)
    used_gb = memory.used / (1024**3)
    
    print(f"æ€»å†…å­˜: {total_gb:.1f} GB")
    print(f"å¯ç”¨å†…å­˜: {available_gb:.1f} GB")
    print(f"å·²ç”¨å†…å­˜: {used_gb:.1f} GB")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%")
    
    if swap.total > 0:
        swap_gb = swap.total / (1024**3)
        swap_used_gb = swap.used / (1024**3)
        print(f"Swapæ€»é‡: {swap_gb:.1f} GB")
        print(f"Swapå·²ç”¨: {swap_used_gb:.1f} GB")
        print(f"Swapä½¿ç”¨ç‡: {swap.percent:.1f}%")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°Swapç©ºé—´")
    
    # å†…å­˜å»ºè®®
    if available_gb < 1.0:
        print("âš ï¸  å¯ç”¨å†…å­˜ä¸è¶³1GBï¼Œå»ºè®®é‡Šæ”¾å†…å­˜æˆ–å¢åŠ Swap")
        return False
    elif available_gb < 2.0:
        print("âš ï¸  å¯ç”¨å†…å­˜è¾ƒå°‘ï¼Œå»ºè®®è°¨æ…è¿›è¡ŒTensorRTè½¬æ¢")
        return True
    else:
        print("âœ… å†…å­˜çŠ¶æ€è‰¯å¥½")
        return True

def setup_swap_if_needed():
    """å¦‚æœéœ€è¦ï¼Œè®¾ç½®Swapç©ºé—´"""
    print("\nğŸ”„ Swapç©ºé—´ç®¡ç†")
    print("-" * 40)
    
    swap = psutil.swap_memory()
    memory = psutil.virtual_memory()
    
    if swap.total == 0:
        print("âŒ æœªæ£€æµ‹åˆ°Swapç©ºé—´")
        print("å»ºè®®åˆ›å»ºSwapç©ºé—´ä»¥é¿å…å†…å­˜ä¸è¶³å´©æºƒ")
        
        response = input("æ˜¯å¦è‡ªåŠ¨åˆ›å»º4GB Swapæ–‡ä»¶? (y/n): ")
        if response.lower() == 'y':
            return create_swap_file()
        else:
            print("âš ï¸  è·³è¿‡Swapåˆ›å»ºï¼Œè½¬æ¢æ—¶å¯èƒ½å› å†…å­˜ä¸è¶³è€Œå¤±è´¥")
            return False
    else:
        swap_gb = swap.total / (1024**3)
        print(f"âœ… å·²æœ‰Swapç©ºé—´: {swap_gb:.1f} GB")
        return True

def create_swap_file():
    """åˆ›å»ºSwapæ–‡ä»¶"""
    print("ğŸ”§ åˆ›å»ºSwapæ–‡ä»¶...")
    
    try:
        swap_file = "/tmp/tensorrt_swap"
        swap_size = "4G"  # 4GB Swap
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        disk_usage = psutil.disk_usage('/')
        free_gb = disk_usage.free / (1024**3)
        
        if free_gb < 5:
            print(f"âŒ ç£ç›˜ç©ºé—´ä¸è¶³ ({free_gb:.1f}GB)ï¼Œæ— æ³•åˆ›å»ºSwap")
            return False
        
        # åˆ›å»ºSwapæ–‡ä»¶
        commands = [
            f"sudo fallocate -l {swap_size} {swap_file}",
            f"sudo chmod 600 {swap_file}",
            f"sudo mkswap {swap_file}",
            f"sudo swapon {swap_file}"
        ]
        
        for cmd in commands:
            print(f"æ‰§è¡Œ: {cmd}")
            result = subprocess.run(cmd.split(), capture_output=True, text=True)
            if result.returncode != 0:
                print(f"âŒ å‘½ä»¤å¤±è´¥: {result.stderr}")
                return False
        
        print(f"âœ… Swapæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {swap_file}")
        return True
        
    except Exception as e:
        print(f"âŒ Swapåˆ›å»ºå¤±è´¥: {e}")
        return False

def cleanup_swap():
    """æ¸…ç†ä¸´æ—¶Swapæ–‡ä»¶"""
    swap_file = "/tmp/tensorrt_swap"
    if os.path.exists(swap_file):
        try:
            subprocess.run(f"sudo swapoff {swap_file}".split(), capture_output=True)
            os.remove(swap_file)
            print(f"ğŸ§¹ ä¸´æ—¶Swapæ–‡ä»¶å·²æ¸…ç†: {swap_file}")
        except:
            pass

def free_memory():
    """é‡Šæ”¾å†…å­˜"""
    print("ğŸ§¹ é‡Šæ”¾å†…å­˜...")
    
    # Pythonåƒåœ¾å›æ”¶
    gc.collect()
    
    # æ¸…ç†ç³»ç»Ÿç¼“å­˜
    try:
        subprocess.run("sudo sync".split(), capture_output=True)
        subprocess.run("sudo sh -c 'echo 3 > /proc/sys/vm/drop_caches'".split(), capture_output=True)
        print("âœ… ç³»ç»Ÿç¼“å­˜å·²æ¸…ç†")
    except:
        print("âš ï¸  æ— æ³•æ¸…ç†ç³»ç»Ÿç¼“å­˜ï¼ˆéœ€è¦sudoæƒé™ï¼‰")

def test_tensorrt_import():
    """æµ‹è¯•TensorRTå¯¼å…¥"""
    print("ğŸ”§ æµ‹è¯•TensorRTå¯¼å…¥")
    print("-" * 40)
    
    try:
        import tensorrt as trt
        print(f"âœ… TensorRTç‰ˆæœ¬: {trt.__version__}")
        return True
    except ImportError as e:
        print(f"âŒ TensorRTå¯¼å…¥å¤±è´¥: {e}")
        print("   è§£å†³æ–¹æ¡ˆ: pip install tensorrt")
        return False

def test_pycuda():
    """æµ‹è¯•PyCUDA"""
    print("\nğŸ”¥ æµ‹è¯•PyCUDA")
    print("-" * 40)
    
    try:
        import pycuda.driver as cuda
        import pycuda.autoinit
        print("âœ… PyCUDAå¯¼å…¥æˆåŠŸ")
        
        # è·å–GPUä¿¡æ¯
        device = cuda.Device(0)
        print(f"GPUåç§°: {device.name()}")
        print(f"è®¡ç®—èƒ½åŠ›: {device.compute_capability()}")
        
        # è·å–GPUå†…å­˜ä¿¡æ¯
        free_mem, total_mem = cuda.mem_get_info()
        free_gb = free_mem / (1024**3)
        total_gb = total_mem / (1024**3)
        
        print(f"GPUå†…å­˜: {free_gb:.1f}GB å¯ç”¨ / {total_gb:.1f}GB æ€»è®¡")
        
        if free_gb < 0.5:
            print("âš ï¸  GPUå†…å­˜ä¸è¶³ï¼Œå¯èƒ½å½±å“TensorRTè½¬æ¢")
        
        return True
    except Exception as e:
        print(f"âŒ PyCUDAæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_yolo_model_exists():
    """æ£€æŸ¥YOLOæ¨¡å‹æ–‡ä»¶"""
    print("\nğŸ“ æ£€æŸ¥YOLOæ¨¡å‹æ–‡ä»¶")
    print("-" * 40)
    
    model_paths = [
        "best1.pt",
        "runs/detect/train/weights/best1.pt",
        "yolov8n.pt",
        "yolov8s.pt",
        "../weights/best1.pt",
        "./weights/best1.pt"
    ]
    
    found_models = []
    for path in model_paths:
        if os.path.exists(path):
            size_mb = os.path.getsize(path) / (1024 * 1024)
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {path} ({size_mb:.1f} MB)")
            found_models.append(path)
        else:
            print(f"âŒ æœªæ‰¾åˆ°: {path}")
    
    return found_models

def test_ultralytics_export_jetson_optimized():
    """Jetsonä¼˜åŒ–çš„TensorRTå¯¼å‡ºåŠŸèƒ½"""
    print("\nğŸ¯ Jetsonä¼˜åŒ–çš„YOLO TensorRTå¯¼å‡º")
    print("-" * 40)
    
    try:
        from ultralytics import YOLO
        print("âœ… Ultralyticså¯¼å…¥æˆåŠŸ")
        
        # æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹
        model_paths = test_yolo_model_exists()
        if not model_paths:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°YOLOæ¨¡å‹æ–‡ä»¶")
            print("   è¯·ç¡®ä¿æœ‰best.ptæˆ–å…¶ä»–.ptæ¨¡å‹æ–‡ä»¶")
            return False
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ¨¡å‹
        model_path = model_paths[0]
        print(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰TensorRTå¼•æ“
        engine_path = model_path.replace('.pt', '_jetson.engine')
        if os.path.exists(engine_path):
            print(f"âœ… å·²å­˜åœ¨TensorRTå¼•æ“: {engine_path}")
            return engine_path
        
        # å†…å­˜é¢„æ£€æŸ¥
        if not check_memory_status():
            print("âŒ å†…å­˜ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒTensorRTè½¬æ¢")
            return False
        
        # é‡Šæ”¾å†…å­˜
        free_memory()
        
        print("å¼€å§‹Jetsonä¼˜åŒ–çš„TensorRTå¯¼å‡º...")
        print("â³ è¿™å¯èƒ½éœ€è¦10-30åˆ†é’Ÿæ—¶é—´...")
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ”„ åŠ è½½YOLOæ¨¡å‹...")
        model = YOLO(model_path)
        
        # Jetsonä¼˜åŒ–å‚æ•°
        jetson_export_params = {
            'format': 'engine',
            'device': 0,  # ä½¿ç”¨GPU
            'half': True,  # ä½¿ç”¨FP16ç²¾åº¦ï¼ˆJetsonå‹å¥½ï¼‰
            'workspace': 1,  # 1GBå·¥ä½œç©ºé—´ï¼ˆJetson Nanoé€‚ç”¨ï¼‰
            'verbose': True,
            'batch': 1,  # å›ºå®šæ‰¹æ¬¡å¤§å°
            'simplify': True,  # ç®€åŒ–æ¨¡å‹
        }
        
        # æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´å‚æ•°
        memory = psutil.virtual_memory()
        available_gb = memory.available / (1024**3)
        
        if available_gb < 2:
            jetson_export_params['workspace'] = 0.5  # å‡å°‘å·¥ä½œç©ºé—´
            print("âš ï¸  å†…å­˜æœ‰é™ï¼Œä½¿ç”¨è¾ƒå°çš„å·¥ä½œç©ºé—´")
        elif available_gb > 4:
            jetson_export_params['workspace'] = 2  # å¢åŠ å·¥ä½œç©ºé—´
        
        start_time = time.time()
        
        try:
            # æ‰§è¡Œå¯¼å‡º
            success = model.export(**jetson_export_params)
            
            export_time = time.time() - start_time
            
            if success:
                print(f"âœ… TensorRTå¯¼å‡ºæˆåŠŸ! è€—æ—¶: {export_time:.1f}ç§’")
                return engine_path
            else:
                print("âŒ TensorRTå¯¼å‡ºå¤±è´¥")
                return False
                
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                print("âŒ å†…å­˜ä¸è¶³å¯¼è‡´å¯¼å‡ºå¤±è´¥")
                print("å»ºè®®è§£å†³æ–¹æ¡ˆ:")
                print("1. å¢åŠ Swapç©ºé—´")
                print("2. å…³é—­å…¶ä»–ç¨‹åºé‡Šæ”¾å†…å­˜")
                print("3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚yolov8n.ptï¼‰")
                print("4. å‡å°‘workspaceå‚æ•°")
                return False
            else:
                raise e
            
    except Exception as e:
        print(f"âŒ TensorRTå¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_tensorrt_inference():
    """æµ‹è¯•TensorRTæ¨ç†"""
    print("\nâš¡ æµ‹è¯•TensorRTæ¨ç†æ€§èƒ½")
    print("-" * 40)
    
    try:
        from ultralytics import YOLO
        import cv2
        
        # æŸ¥æ‰¾TensorRTå¼•æ“
        engine_files = []
        for ext in ['*_jetson.engine', '*.engine']:
            engine_files.extend(Path('.').glob(ext))
        
        if not engine_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°TensorRTå¼•æ“æ–‡ä»¶")
            print("   è¯·å…ˆè¿è¡Œå¯¼å‡ºæµ‹è¯•")
            return False
        
        engine_path = str(engine_files[0])
        print(f"ä½¿ç”¨å¼•æ“: {engine_path}")
        
        # åŠ è½½TensorRTæ¨¡å‹
        model = YOLO(engine_path)
        print("âœ… TensorRTæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # é¢„çƒ­
        print("é¢„çƒ­æ¨¡å‹...")
        for _ in range(3):
            _ = model(test_img, verbose=False)
        
        # æ€§èƒ½æµ‹è¯•
        print("å¼€å§‹æ€§èƒ½æµ‹è¯•...")
        times = []
        num_tests = 10
        
        for i in range(num_tests):
            start_time = time.time()
            results = model(test_img, verbose=False)
            inference_time = time.time() - start_time
            times.append(inference_time * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            print(f"æ¨ç† {i+1}/{num_tests}: {inference_time*1000:.1f}ms")
        
        # ç»Ÿè®¡ç»“æœ
        avg_time = np.mean(times)
        min_time = np.min(times)
        max_time = np.max(times)
        fps = 1000 / avg_time
        
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.1f}ms")
        print(f"æœ€å¿«æ¨ç†æ—¶é—´: {min_time:.1f}ms")
        print(f"æœ€æ…¢æ¨ç†æ—¶é—´: {max_time:.1f}ms")
        print(f"ç†è®ºFPS: {fps:.1f}")
        
        # Jetsonæ€§èƒ½è¯„ä¼°
        if avg_time < 50:  # å°äº50ms
            print("âœ… TensorRTæ¨ç†æ€§èƒ½ä¼˜ç§€! (Jetsonè®¾å¤‡)")
        elif avg_time < 100:
            print("âœ… TensorRTæ¨ç†æ€§èƒ½è‰¯å¥½! (Jetsonè®¾å¤‡)")
        elif avg_time < 200:
            print("âš ï¸  TensorRTæ¨ç†æ€§èƒ½ä¸€èˆ¬ (Jetsonè®¾å¤‡)")
        else:
            print("âŒ TensorRTæ¨ç†æ€§èƒ½è¾ƒå·®ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–")
        
        return True
        
    except Exception as e:
        print(f"âŒ TensorRTæ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def compare_pytorch_vs_tensorrt():
    """å¯¹æ¯”PyTorchå’ŒTensorRTæ€§èƒ½"""
    print("\nâš”ï¸  PyTorch vs TensorRT æ€§èƒ½å¯¹æ¯”")
    print("-" * 50)
    
    try:
        from ultralytics import YOLO
        import cv2
        
        # æŸ¥æ‰¾æ¨¡å‹
        pt_models = [f for f in os.listdir('.') if f.endswith('.pt')]
        engine_models = [f for f in os.listdir('.') if f.endswith('.engine')]
        
        if not pt_models:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°PyTorchæ¨¡å‹(.pt)")
            return False
        
        if not engine_models:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°TensorRTå¼•æ“(.engine)")
            return False
        
        pt_model = YOLO(pt_models[0])
        trt_model = YOLO(engine_models[0])
        
        # æµ‹è¯•å›¾åƒ
        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # é¢„çƒ­
        for model in [pt_model, trt_model]:
            for _ in range(3):
                _ = model(test_img, verbose=False)
        
        # æµ‹è¯•PyTorch
        print("æµ‹è¯•PyTorchæ€§èƒ½...")
        pt_times = []
        for _ in range(5):
            start = time.time()
            _ = pt_model(test_img, verbose=False)
            pt_times.append((time.time() - start) * 1000)
        
        # æµ‹è¯•TensorRT
        print("æµ‹è¯•TensorRTæ€§èƒ½...")
        trt_times = []
        for _ in range(5):
            start = time.time()
            _ = trt_model(test_img, verbose=False)
            trt_times.append((time.time() - start) * 1000)
        
        pt_avg = np.mean(pt_times)
        trt_avg = np.mean(trt_times)
        speedup = pt_avg / trt_avg
        
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
        print(f"PyTorchå¹³å‡æ—¶é—´: {pt_avg:.1f}ms ({1000/pt_avg:.1f} FPS)")
        print(f"TensorRTå¹³å‡æ—¶é—´: {trt_avg:.1f}ms ({1000/trt_avg:.1f} FPS)")
        print(f"ğŸš€ TensorRTåŠ é€Ÿå€æ•°: {speedup:.1f}x")
        
        # Jetsonè®¾å¤‡åŠ é€Ÿè¯„ä¼°
        if speedup > 3:
            print("âœ… TensorRTåŠ é€Ÿæ•ˆæœä¼˜ç§€! (Jetsonè®¾å¤‡)")
        elif speedup > 2:
            print("âœ… TensorRTåŠ é€Ÿæ•ˆæœè‰¯å¥½! (Jetsonè®¾å¤‡)")
        elif speedup > 1.2:
            print("âš ï¸  TensorRTåŠ é€Ÿæ•ˆæœä¸€èˆ¬ (Jetsonè®¾å¤‡)")
        else:
            print("âŒ TensorRTåŠ é€Ÿæ•ˆæœä¸æ˜æ˜¾")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½å¯¹æ¯”å¤±è´¥: {e}")
        return False

def jetson_optimization_tips():
    """Jetsonä¼˜åŒ–å»ºè®®"""
    print("\nğŸ’¡ Jetson TensorRTä¼˜åŒ–å»ºè®®")
    print("-" * 50)
    
    is_jetson, device_model = check_jetson_device()
    
    if is_jetson:
        print("ğŸ¯ é’ˆå¯¹Jetsonè®¾å¤‡çš„ä¼˜åŒ–å»ºè®®:")
        print("1. è®¾ç½®æœ€é«˜æ€§èƒ½æ¨¡å¼:")
        print("   sudo nvpmodel -m 0")
        print("   sudo jetson_clocks")
        
        print("\n2. å¢åŠ Swapç©ºé—´ (4-6GB):")
        print("   sudo fallocate -l 4G /swapfile")
        print("   sudo chmod 600 /swapfile") 
        print("   sudo mkswap /swapfile")
        print("   sudo swapon /swapfile")
        
        print("\n3. TensorRTå¯¼å‡ºä¼˜åŒ–å‚æ•°:")
        print("   - ä½¿ç”¨FP16ç²¾åº¦ (half=True)")
        print("   - å‡å°‘å·¥ä½œç©ºé—´ (workspace=1-2)")
        print("   - å›ºå®šæ‰¹æ¬¡å¤§å° (batch=1)")
        print("   - ç®€åŒ–æ¨¡å‹ (simplify=True)")
        
        print("\n4. å†…å­˜ç®¡ç†:")
        print("   - å…³é—­ä¸å¿…è¦çš„ç¨‹åº")
        print("   - å®šæœŸæ¸…ç†ç¼“å­˜")
        print("   - ç›‘æ§å†…å­˜ä½¿ç”¨ (htop/jtop)")
        
        print("\n5. æ¨¡å‹é€‰æ‹©:")
        print("   - ä¼˜å…ˆä½¿ç”¨è½»é‡çº§æ¨¡å‹ (YOLOv8n)")
        print("   - é¿å…è¿‡å¤§çš„è¾“å…¥åˆ†è¾¨ç‡")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°Jetsonè®¾å¤‡ï¼Œé€šç”¨ä¼˜åŒ–å»ºè®®:")
        print("1. ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPUå†…å­˜")
        print("2. ä½¿ç”¨åˆé€‚çš„TensorRTç‰ˆæœ¬")
        print("3. é€‰æ‹©åˆé€‚çš„ç²¾åº¦æ¨¡å¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Jetson TensorRTåŠŸèƒ½éªŒè¯")
    print("=" * 50)
    
    # æ£€æŸ¥è®¾å¤‡ç±»å‹
    is_jetson, device_model = check_jetson_device()
    
    # æµ‹è¯•æ­¥éª¤
    tests = [
        ("è®¾å¤‡æ£€æŸ¥", lambda: is_jetson),
        ("å†…å­˜çŠ¶æ€", check_memory_status),
        ("Swapç®¡ç†", setup_swap_if_needed),
        ("TensorRTå¯¼å…¥", test_tensorrt_import),
        ("PyCUDA", test_pycuda),
        ("YOLOæ¨¡å‹", lambda: len(test_yolo_model_exists()) > 0),
        ("TensorRTå¯¼å‡º", test_ultralytics_export_jetson_optimized),
        ("TensorRTæ¨ç†", test_tensorrt_inference),
        ("æ€§èƒ½å¯¹æ¯”", compare_pytorch_vs_tensorrt)
    ]
    
    results = {}
    for name, test_func in tests:
        print(f"\n{'='*20} {name} {'='*20}")
        try:
            result = test_func()
            results[name] = result
            if result:
                print(f"âœ… {name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {name} æµ‹è¯•å¼‚å¸¸: {e}")
            results[name] = False
    
    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
    jetson_optimization_tips()
    
    # æ€»ç»“
    print(f"\n{'='*20} æµ‹è¯•æ€»ç»“ {'='*20}")
    passed = sum(1 for r in results.values() if r)
    total = len(results)
    
    for name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡ ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼TensorRTå®Œå…¨å¯ç”¨ï¼")
    elif passed >= total * 0.8:
        print("âœ… å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼ŒTensorRTåŸºæœ¬å¯ç”¨")
    else:
        print("âš ï¸  å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ’æŸ¥é—®é¢˜")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleanup_swap()

if __name__ == "__main__":
    main() 