#!/usr/bin/env python3
# yolo_trt_utils_optimized.py
# é’ˆå¯¹Jetson Orin Nanoä¼˜åŒ–çš„YOLO TensorRTæ£€æµ‹å™¨

import cv2
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import torch
from ultralytics import YOLO
import time
import os
from typing import List, Dict, Tuple, Optional

class JetsonOptimizedYOLODetector:
    """é’ˆå¯¹Jetson Orin Nanoä¼˜åŒ–çš„YOLO TensorRTæ£€æµ‹å™¨"""
    
    def __init__(self, model_path: str, conf_thres: float = 0.25, 
                 iou_thres: float = 0.45, max_det: int = 300, 
                 device: str = 'cuda:0'):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ (.pt, .engine, .onnx)
            conf_thres: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_thres: IoUé˜ˆå€¼
            max_det: æœ€å¤§æ£€æµ‹æ•°é‡
            device: è®¾å¤‡
        """
        self.model_path = model_path
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres
        self.max_det = max_det
        self.device = device
        
        # TensorRTç›¸å…³
        self.engine = None
        self.context = None
        self.stream = None
        self.host_inputs = []
        self.cuda_inputs = []
        self.host_outputs = []
        self.cuda_outputs = []
        self.bindings = []
        
        # æ¨¡å‹ä¿¡æ¯
        self.input_shape = None
        self.output_shapes = []
        self.class_names = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.inference_times = []
        self.using_trt = False
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_model()
        
    def _initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        if self.model_path.endswith('.engine'):
            print("ğŸš€ åŠ è½½TensorRTå¼•æ“...")
            self._load_tensorrt_engine()
            self.using_trt = True
        elif self.model_path.endswith('.pt'):
            print("ğŸ“¦ åŠ è½½PyTorchæ¨¡å‹...")
            self._load_pytorch_model()
            # å°è¯•è½¬æ¢ä¸ºTensorRT
            self._try_convert_to_tensorrt()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {self.model_path}")
    
    def _load_tensorrt_engine(self):
        """åŠ è½½TensorRTå¼•æ“"""
        # åˆ›å»ºTensorRT logger
        TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
        
        # åŠ è½½å¼•æ“
        with open(self.model_path, 'rb') as f:
            engine_data = f.read()
        
        runtime = trt.Runtime(TRT_LOGGER)
        self.engine = runtime.deserialize_cuda_engine(engine_data)
        self.context = self.engine.create_execution_context()
        
        # åˆ›å»ºCUDAæµ
        self.stream = cuda.Stream()
        
        # åˆ†é…å†…å­˜
        self._allocate_buffers()
        
        print(f"âœ… TensorRTå¼•æ“åŠ è½½æˆåŠŸ")
        print(f"   - è¾“å…¥å½¢çŠ¶: {self.input_shape}")
        print(f"   - è¾“å‡ºå½¢çŠ¶: {self.output_shapes}")
    
    def _load_pytorch_model(self):
        """åŠ è½½PyTorchæ¨¡å‹"""
        self.model = YOLO(self.model_path)
        self.model.to(self.device)
        
        # è·å–ç±»åˆ«åç§°
        if hasattr(self.model.model, 'names'):
            self.class_names = list(self.model.model.names.values())
        
        print(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   - ç±»åˆ«æ•°é‡: {len(self.class_names)}")
    
    def _try_convert_to_tensorrt(self):
        """å°è¯•å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºTensorRT"""
        try:
            engine_path = self.model_path.replace('.pt', '_orin_fp16.engine')
            
            if not os.path.exists(engine_path):
                print("ğŸ”„ è½¬æ¢PyTorchæ¨¡å‹ä¸ºTensorRTå¼•æ“...")
                
                # ä½¿ç”¨Ultralyticså¯¼å‡º
                self.model.export(
                    format='engine',
                    half=True,  # FP16
                    device=self.device,
                    workspace=2,  # 2GB workspace for Orin Nano
                    verbose=True
                )
                
                print(f"âœ… TensorRTå¼•æ“è½¬æ¢å®Œæˆ: {engine_path}")
            
            # é‡æ–°åŠ è½½TensorRTå¼•æ“
            if os.path.exists(engine_path):
                self.model_path = engine_path
                self._load_tensorrt_engine()
                self.using_trt = True
                
        except Exception as e:
            print(f"âš ï¸  TensorRTè½¬æ¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨PyTorch: {e}")
    
    def _allocate_buffers(self):
        """åˆ†é…CUDAå†…å­˜"""
        self.host_inputs = []
        self.cuda_inputs = []
        self.host_outputs = []
        self.cuda_outputs = []
        self.bindings = []
        
        for i in range(self.engine.num_bindings):
            binding = self.engine.get_binding_name(i)
            size = trt.volume(self.engine.get_binding_shape(i))
            dtype = trt.nptype(self.engine.get_binding_dtype(i))
            
            # åˆ†é…ä¸»æœºå’Œè®¾å¤‡å†…å­˜
            host_mem = cuda.pagelocked_empty(size, dtype)
            cuda_mem = cuda.mem_alloc(host_mem.nbytes)
            
            self.bindings.append(int(cuda_mem))
            
            if self.engine.binding_is_input(i):
                self.input_shape = self.engine.get_binding_shape(i)
                self.host_inputs.append(host_mem)
                self.cuda_inputs.append(cuda_mem)
            else:
                self.output_shapes.append(self.engine.get_binding_shape(i))
                self.host_outputs.append(host_mem)
                self.cuda_outputs.append(cuda_mem)
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç†"""
        if self.using_trt:
            # TensorRTé¢„å¤„ç†
            input_h, input_w = self.input_shape[2], self.input_shape[3]
        else:
            # PyTorché¢„å¤„ç†
            input_h, input_w = 640, 640
        
        # è°ƒæ•´å¤§å°å¹¶ä¿æŒå®½é«˜æ¯”
        img = cv2.resize(image, (input_w, input_h))
        
        # å½’ä¸€åŒ–
        img = img.astype(np.float32) / 255.0
        
        # HWC -> CHW
        img = np.transpose(img, (2, 0, 1))
        
        # æ·»åŠ batchç»´åº¦
        img = np.expand_dims(img, axis=0)
        
        return img
    
    def _tensorrt_inference(self, preprocessed_img: np.ndarray) -> List[np.ndarray]:
        """TensorRTæ¨ç†"""
        # æ‹·è´è¾“å…¥æ•°æ®åˆ°GPU
        np.copyto(self.host_inputs[0], preprocessed_img.ravel())
        cuda.memcpy_htod_async(self.cuda_inputs[0], self.host_inputs[0], self.stream)
        
        # æ‰§è¡Œæ¨ç†
        self.context.execute_async_v2(bindings=self.bindings, stream_handle=self.stream.handle)
        
        # æ‹·è´è¾“å‡ºæ•°æ®åˆ°CPU
        outputs = []
        for i in range(len(self.host_outputs)):
            cuda.memcpy_dtoh_async(self.host_outputs[i], self.cuda_outputs[i], self.stream)
            outputs.append(self.host_outputs[i].copy())
        
        # åŒæ­¥
        self.stream.synchronize()
        
        return outputs
    
    def _pytorch_inference(self, image: np.ndarray) -> List[np.ndarray]:
        """PyTorchæ¨ç†"""
        results = self.model(image, conf=self.conf_thres, iou=self.iou_thres, 
                           max_det=self.max_det, verbose=False)
        return results
    
    def _postprocess_outputs(self, outputs, original_shape) -> List[Dict]:
        """åå¤„ç†è¾“å‡º"""
        if self.using_trt:
            return self._postprocess_tensorrt_outputs(outputs, original_shape)
        else:
            return self._postprocess_pytorch_outputs(outputs, original_shape)
    
    def _postprocess_tensorrt_outputs(self, outputs, original_shape) -> List[Dict]:
        """TensorRTè¾“å‡ºåå¤„ç†"""
        detections = []
        
        # é‡å¡‘è¾“å‡º
        output = outputs[0].reshape(self.output_shapes[0])
        
        # è§£ææ£€æµ‹ç»“æœ
        for detection in output[0]:  # batch_size = 1
            if detection[4] > self.conf_thres:  # ç½®ä¿¡åº¦è¿‡æ»¤
                x1, y1, x2, y2, conf = detection[:5]
                class_id = int(np.argmax(detection[5:]))
                
                # åæ ‡è½¬æ¢å›åŸå›¾å°ºå¯¸
                orig_h, orig_w = original_shape[:2]
                input_h, input_w = self.input_shape[2], self.input_shape[3]
                
                x1 = int(x1 * orig_w / input_w)
                y1 = int(y1 * orig_h / input_h)
                x2 = int(x2 * orig_w / input_w)
                y2 = int(y2 * orig_h / input_h)
                
                detections.append({
                    'box': [x1, y1, x2, y2],
                    'confidence': float(conf),
                    'class_id': class_id,
                    'class_name': self.class_names[class_id] if self.class_names else str(class_id)
                })
        
        return detections
    
    def _postprocess_pytorch_outputs(self, results, original_shape) -> List[Dict]:
        """PyTorchè¾“å‡ºåå¤„ç†"""
        detections = []
        
        for result in results:
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                class_ids = result.boxes.cls.cpu().numpy().astype(int)
                
                for box, conf, class_id in zip(boxes, confidences, class_ids):
                    x1, y1, x2, y2 = map(int, box)
                    
                    detections.append({
                        'box': [x1, y1, x2, y2],
                        'confidence': float(conf),
                        'class_id': int(class_id),
                        'class_name': self.class_names[class_id] if self.class_names else str(class_id)
                    })
        
        return detections
    
    def detect(self, image: np.ndarray) -> List[Dict]:
        """
        æ‰§è¡Œç›®æ ‡æ£€æµ‹
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        # é¢„å¤„ç†
        preprocessed_img = self._preprocess_image(image)
        
        # æ¨ç†
        if self.using_trt:
            outputs = self._tensorrt_inference(preprocessed_img)
        else:
            outputs = self._pytorch_inference(image)
        
        # åå¤„ç†
        detections = self._postprocess_outputs(outputs, image.shape)
        
        # è®°å½•æ¨ç†æ—¶é—´
        inference_time = time.time() - start_time
        self.inference_times.append(inference_time)
        if len(self.inference_times) > 100:
            self.inference_times.pop(0)
        
        return detections
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.inference_times:
            return {}
        
        avg_time = sum(self.inference_times) / len(self.inference_times)
        fps = 1.0 / avg_time if avg_time > 0 else 0
        
        return {
            'avg_inference_time': avg_time,
            'fps': fps,
            'using_tensorrt': self.using_trt,
            'model_path': self.model_path
        }
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'stream') and self.stream:
            self.stream.synchronize()


# å…¼å®¹æ€§åŒ…è£…å™¨
class YOLOTRTDetector(JetsonOptimizedYOLODetector):
    """å…¼å®¹åŸæœ‰ä»£ç çš„åŒ…è£…å™¨"""
    def __init__(self, model_path: str, conf_thres: float = 0.25, use_trt: bool = True):
        super().__init__(model_path, conf_thres)
        # ä¿æŒå…¼å®¹æ€§
        pass


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•æ£€æµ‹å™¨
    detector = JetsonOptimizedYOLODetector("../weights/best.pt")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
    
    # é¢„çƒ­
    print("é¢„çƒ­ä¸­...")
    for _ in range(5):
        detector.detect(test_image)
    
    # æ€§èƒ½æµ‹è¯•
    print("æ€§èƒ½æµ‹è¯•ä¸­...")
    start_time = time.time()
    for _ in range(100):
        detections = detector.detect(test_image)
    
    total_time = time.time() - start_time
    print(f"100æ¬¡æ¨ç†æ€»æ—¶é—´: {total_time:.2f}s")
    print(f"å¹³å‡FPS: {100/total_time:.2f}")
    
    # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
    stats = detector.get_performance_stats()
    print("æ€§èƒ½ç»Ÿè®¡:", stats) 