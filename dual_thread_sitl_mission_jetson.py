#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒçº¿ç¨‹SITLä»¿çœŸæ‰“å‡»ä»»åŠ¡ç³»ç»Ÿ - Jetsonä¼˜åŒ–ç‰ˆæœ¬
ä¸»çº¿ç¨‹ï¼šå®æ—¶YOLOæ£€æµ‹ + GPSæ•°æ®æ”¶é›† + è§†é¢‘æ˜¾ç¤º
å‰¯çº¿ç¨‹ï¼šå›¾åƒè½¬æ­£ + OCRè¯†åˆ« + GPSåæ ‡è®¡ç®—
é’ˆå¯¹Jetson Orin Nanoä¼˜åŒ–ï¼šå†…å­˜ç®¡ç†ã€GPUåŠ é€Ÿã€åŠŸè€—æ§åˆ¶
"""

import time
import sys
import os
import threading
import queue
import json
import cv2
import numpy as np
from dataclasses import dataclass, asdict
from typing import Optional, Tuple, List
from pathlib import Path
import psutil
import gc

# Jetsonç‰¹å®šä¼˜åŒ–å¯¼å…¥
try:
    import jetson.inference
    import jetson.utils
    JETSON_INFERENCE_AVAILABLE = True
    print("âœ… Jetson Inferenceåº“å¯ç”¨")
except ImportError:
    JETSON_INFERENCE_AVAILABLE = False
    print("ğŸ“ ä½¿ç”¨æ ‡å‡†æ¨ç†åº“")

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from target_geo_calculator import FlightData, TargetGeoCalculator, TargetInfo
from yolo_trt_utils_jetson import YOLOTRTDetectorJetson
import easyocr

# MAVLinkç›¸å…³
try:
    from pymavlink import mavutil
    MAVLINK_AVAILABLE = True
    print("âœ… MAVLinkåº“å¯ç”¨")
except ImportError:
    MAVLINK_AVAILABLE = False
    print("âŒ MAVLinkåº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

@dataclass
class DetectionPackage:
    """æ£€æµ‹æ•°æ®åŒ… - ä¸»çº¿ç¨‹ä¼ é€’ç»™å‰¯çº¿ç¨‹çš„æ•°æ®ç»“æ„"""
    frame_id: int
    timestamp: float
    crop_image: np.ndarray
    detection_box: Tuple[int, int, int, int]  # x1, y1, x2, y2
    pixel_center: Tuple[int, int]  # center_x, center_y
    confidence: float
    flight_data: FlightData
    target_id: str

class JetsonSystemMonitor:
    """Jetsonç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self):
        self.cpu_temps = []
        self.gpu_temps = []
        self.memory_usage = []
        self.power_usage = []
        
    def get_system_stats(self):
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            # CPUæ¸©åº¦å’Œä½¿ç”¨ç‡
            cpu_temp = self._read_thermal_zone('/sys/class/thermal/thermal_zone0/temp')
            cpu_usage = psutil.cpu_percent()
            
            # GPUæ¸©åº¦
            gpu_temp = self._read_thermal_zone('/sys/class/thermal/thermal_zone1/temp')
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_usage = memory.percent
            
            # åŠŸè€—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            power = self._read_power_consumption()
            
            stats = {
                'cpu_temp': cpu_temp,
                'cpu_usage': cpu_usage,
                'gpu_temp': gpu_temp,
                'memory_usage': memory_usage,
                'memory_available': memory.available / (1024**3),  # GB
                'power_consumption': power
            }
            
            # è®°å½•å†å²æ•°æ®
            self.cpu_temps.append(cpu_temp)
            self.gpu_temps.append(gpu_temp)
            self.memory_usage.append(memory_usage)
            self.power_usage.append(power)
            
            # ä¿æŒæœ€è¿‘100ä¸ªè®°å½•
            for hist in [self.cpu_temps, self.gpu_temps, self.memory_usage, self.power_usage]:
                if len(hist) > 100:
                    hist.pop(0)
            
            return stats
            
        except Exception as e:
            print(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {}
    
    def _read_thermal_zone(self, path):
        """è¯»å–æ¸©åº¦ä¼ æ„Ÿå™¨"""
        try:
            with open(path, 'r') as f:
                temp = int(f.read().strip()) / 1000.0  # è½¬æ¢ä¸ºæ‘„æ°åº¦
            return temp
        except:
            return 0.0
    
    def _read_power_consumption(self):
        """è¯»å–åŠŸè€—ä¿¡æ¯"""
        try:
            # JetsonåŠŸè€—ç›‘æ§è·¯å¾„
            power_paths = [
                '/sys/bus/i2c/drivers/ina3221x/1-0040/iio:device0/in_power0_input',
                '/sys/bus/i2c/drivers/ina3221x/1-0040/iio:device0/in_power1_input'
            ]
            
            total_power = 0
            for path in power_paths:
                if os.path.exists(path):
                    with open(path, 'r') as f:
                        power = int(f.read().strip()) / 1000.0  # è½¬æ¢ä¸ºç“¦ç‰¹
                        total_power += power
            
            return total_power
        except:
            return 0.0
    
    def check_thermal_throttling(self):
        """æ£€æŸ¥æ˜¯å¦å‘ç”Ÿæ¸©åº¦é™æµ"""
        cpu_temp = self._read_thermal_zone('/sys/class/thermal/thermal_zone0/temp')
        gpu_temp = self._read_thermal_zone('/sys/class/thermal/thermal_zone1/temp')
        
        # Jetson Orin Nanoæ¸©åº¦é˜ˆå€¼
        cpu_throttle_temp = 85.0  # CPUé™æµæ¸©åº¦
        gpu_throttle_temp = 85.0  # GPUé™æµæ¸©åº¦
        
        return {
            'cpu_throttling': cpu_temp > cpu_throttle_temp,
            'gpu_throttling': gpu_temp > gpu_throttle_temp,
            'cpu_temp': cpu_temp,
            'gpu_temp': gpu_temp
        }

class ImageOrientationCorrectorJetson:
    """Jetsonä¼˜åŒ–çš„å›¾åƒæ–¹å‘æ ¡æ­£å™¨"""
    
    def __init__(self, debug_mode: bool = False):
        self.debug_mode = debug_mode
        self.correction_stats = {
            'total_processed': 0,
            'successful_corrections': 0,
            'failed_corrections': 0
        }
        
        # Jetsonä¼˜åŒ–è®¾ç½®
        self._optimize_opencv()
    
    def _optimize_opencv(self):
        """ä¼˜åŒ–OpenCVè®¾ç½®"""
        cv2.setUseOptimized(True)
        cv2.setNumThreads(6)  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        
        # å¯ç”¨OpenCVçš„GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            if cv2.cuda.getCudaEnabledDeviceCount() > 0:
                print("âœ… OpenCV CUDAåŠ é€Ÿå¯ç”¨")
            else:
                print("ğŸ“ OpenCV CUDAåŠ é€Ÿä¸å¯ç”¨")
        except:
            print("ğŸ“ OpenCV CUDAæ”¯æŒæœªå¯ç”¨")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç†ï¼šåŸºäºçº¢è‰²é¢œè‰²è¯†åˆ«è¿›è¡ŒäºŒå€¼åŒ–ï¼ˆJetsonä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if len(image.shape) != 3:
            return None
        
        # ä½¿ç”¨æ›´å°çš„æ ¸è¿›è¡Œé«˜æ–¯æ»¤æ³¢ä»¥æé«˜æ€§èƒ½
        blurred = cv2.GaussianBlur(image, (3, 3), 0)
        
        # å¤šé¢œè‰²ç©ºé—´çº¢è‰²æ£€æµ‹ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        red_mask_hsv = self._create_red_mask_hsv_optimized(blurred)
        red_mask_bgr = self._create_red_mask_bgr_optimized(blurred)
        
        # ç»„åˆæ©ç 
        combined_mask = cv2.bitwise_or(red_mask_hsv, red_mask_bgr)
        
        # ç®€åŒ–çš„å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        opened = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
        
        return closed
    
    def _create_red_mask_hsv_optimized(self, image: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–çš„HSVçº¢è‰²æ©ç åˆ›å»º"""
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ä»¥æé«˜æ£€æµ‹ç‡
        lower_red1 = np.array([0, 40, 40])
        upper_red1 = np.array([15, 255, 255])
        lower_red2 = np.array([165, 40, 40])
        upper_red2 = np.array([180, 255, 255])
        
        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
        return cv2.bitwise_or(mask1, mask2)
    
    def _create_red_mask_bgr_optimized(self, image: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–çš„BGRçº¢è‰²æ©ç åˆ›å»º"""
        lower_red = np.array([0, 0, 120])
        upper_red = np.array([100, 100, 255])
        return cv2.inRange(image, lower_red, upper_red)
    
    def find_largest_contour(self, binary_image: np.ndarray) -> Optional[np.ndarray]:
        """æ‰¾åˆ°æœ€å¤§çš„è½®å»“ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None
        
        # å¿«é€Ÿç­›é€‰æœ‰æ•ˆè½®å»“
        valid_contours = [c for c in contours if cv2.contourArea(c) > 50]
        if not valid_contours:
            return None
        
        return max(valid_contours, key=cv2.contourArea)
    
    def find_tip_point(self, contour: np.ndarray) -> Optional[Tuple[int, int]]:
        """æ‰¾åˆ°è½®å»“çš„å°–ç«¯ç‚¹ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if contour is None or len(contour) < 3:
            return None
        
        moments = cv2.moments(contour)
        if moments['m00'] == 0:
            return None
        
        # è®¡ç®—è´¨å¿ƒ
        centroid_x = int(moments['m10'] / moments['m00'])
        centroid_y = int(moments['m01'] / moments['m00'])
        
        # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ‰¾åˆ°æœ€è¿œç‚¹
        points = contour.reshape(-1, 2)
        distances = np.sqrt(np.sum((points - [centroid_x, centroid_y])**2, axis=1))
        max_idx = np.argmax(distances)
        
        return tuple(points[max_idx])
    
    def calculate_rotation_angle(self, tip_point: Tuple[int, int], 
                               image_center: Tuple[int, int]) -> float:
        """è®¡ç®—ä½¿å°–ç«¯æœä¸Šæ‰€éœ€çš„æ—‹è½¬è§’åº¦"""
        dx = tip_point[0] - image_center[0]
        dy = tip_point[1] - image_center[1]
        angle_rad = np.arctan2(dx, -dy)
        angle_deg = np.degrees(angle_rad)
        return angle_deg
    
    def rotate_image(self, image: np.ndarray, angle: float) -> np.ndarray:
        """æ—‹è½¬å›¾åƒï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        center = (image.shape[1] // 2, image.shape[0] // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        
        # ä½¿ç”¨æ›´å¿«çš„æ’å€¼æ–¹æ³•
        rotated = cv2.warpAffine(image, rotation_matrix, 
                                (image.shape[1], image.shape[0]),
                                flags=cv2.INTER_LINEAR,
                                borderMode=cv2.BORDER_CONSTANT,
                                borderValue=(255, 255, 255))
        return rotated
    
    def correct_orientation(self, image: np.ndarray) -> Tuple[np.ndarray, dict]:
        """ä¸»è¦çš„æ–¹å‘æ ¡æ­£å‡½æ•°ï¼ˆJetsonä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        self.correction_stats['total_processed'] += 1
        
        info = {
            'success': False,
            'rotation_angle': 0,
            'tip_point': None,
            'contour_area': 0,
            'error_message': None
        }
        
        try:
            # é¢„å¤„ç†
            processed = self.preprocess_image(image)
            if processed is None:
                info['error_message'] = "é¢„å¤„ç†å¤±è´¥"
                self.correction_stats['failed_corrections'] += 1
                return image, info
            
            # æ‰¾åˆ°æœ€å¤§è½®å»“
            contour = self.find_largest_contour(processed)
            if contour is None:
                info['error_message'] = "æœªæ‰¾åˆ°æœ‰æ•ˆè½®å»“"
                self.correction_stats['failed_corrections'] += 1
                return image, info
            
            info['contour_area'] = cv2.contourArea(contour)
            
            # æ‰¾åˆ°å°–ç«¯ç‚¹
            tip_point = self.find_tip_point(contour)
            if tip_point is None:
                info['error_message'] = "æœªæ‰¾åˆ°å°–ç«¯ç‚¹"
                self.correction_stats['failed_corrections'] += 1
                return image, info
            
            info['tip_point'] = tip_point
            
            # è®¡ç®—æ—‹è½¬è§’åº¦
            image_center = (image.shape[1] // 2, image.shape[0] // 2)
            angle = self.calculate_rotation_angle(tip_point, image_center)
            info['rotation_angle'] = angle
            
            # æ—‹è½¬å›¾åƒ
            corrected_image = self.rotate_image(image, angle)
            
            info['success'] = True
            self.correction_stats['successful_corrections'] += 1
            
            return corrected_image, info
            
        except Exception as e:
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            info['error_message'] = error_msg
            self.correction_stats['failed_corrections'] += 1
            return image, info
    
    def get_stats(self):
        """è·å–æ ¡æ­£ç»Ÿè®¡ä¿¡æ¯"""
        return self.correction_stats.copy()

class DualThreadSITLMissionJetson:
    """Jetsonä¼˜åŒ–çš„åŒçº¿ç¨‹SITLä»»åŠ¡ç³»ç»Ÿ"""
    
    def __init__(self, config=None):
        """åˆå§‹åŒ–Jetsonä¼˜åŒ–çš„åŒçº¿ç¨‹SITLä»»åŠ¡ç³»ç»Ÿ"""
        self.config = config or self._default_config()
        
        # æ ¸å¿ƒç»„ä»¶
        self.yolo_detector = None
        self.orientation_corrector = ImageOrientationCorrectorJetson()
        self.geo_calculator = TargetGeoCalculator()
        self.system_monitor = JetsonSystemMonitor()
        
        # çº¿ç¨‹å’Œé˜Ÿåˆ—
        self.detection_queue = queue.Queue(maxsize=self.config['detection_queue_size'])
        self.result_queue = queue.Queue(maxsize=self.config['result_queue_size'])
        self.processing_thread = None
        self.is_running = False
        
        # æ•°æ®å­˜å‚¨
        self.raw_detections = []
        self.processing_results = []
        self.processing_display = {}
        self.target_processing_status = {}
        
        # æ€§èƒ½ç›‘æ§
        self.frame_count = 0
        self.detection_count = 0
        self.processing_start_time = time.time()
        
        # Jetsonç‰¹å®šä¼˜åŒ–
        self._setup_jetson_optimizations()
        
        print("ğŸš€ Jetsonä¼˜åŒ–çš„åŒçº¿ç¨‹SITLä»»åŠ¡ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _default_config(self):
        """Jetsonä¼˜åŒ–çš„é»˜è®¤é…ç½®"""
        return {
            'model_path': 'weights/best1.pt',
            'confidence_threshold': 0.25,
            'detection_queue_size': 300,  # å‡å°‘é˜Ÿåˆ—å¤§å°ä»¥èŠ‚çœå†…å­˜
            'result_queue_size': 150,
            'queue_wait_timeout': 3.0,    # å‡å°‘ç­‰å¾…æ—¶é—´
            'use_tensorrt': True,
            'max_fps': 30,                # é™åˆ¶æœ€å¤§FPS
            'memory_cleanup_interval': 50, # å†…å­˜æ¸…ç†é—´éš”
            'thermal_check_interval': 100, # æ¸©åº¦æ£€æŸ¥é—´éš”
            'power_mode': 'balanced'       # åŠŸè€—æ¨¡å¼ï¼šbalanced, performance, power_save
        }
    
    def _setup_jetson_optimizations(self):
        """è®¾ç½®Jetsonç‰¹å®šä¼˜åŒ–"""
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
        os.environ['CUDA_CACHE_DISABLE'] = '0'
        
        # è®¾ç½®åŠŸè€—æ¨¡å¼
        self._set_power_mode(self.config['power_mode'])
        
        # ä¼˜åŒ–å†…å­˜ç®¡ç†
        self._setup_memory_optimization()
        
        print("âš¡ Jetsonç³»ç»Ÿä¼˜åŒ–è®¾ç½®å®Œæˆ")
    
    def _set_power_mode(self, mode):
        """è®¾ç½®JetsonåŠŸè€—æ¨¡å¼"""
        mode_map = {
            'power_save': 0,   # 7Wæ¨¡å¼
            'balanced': 1,     # 15Wæ¨¡å¼
            'performance': 2   # 25Wæ¨¡å¼
        }
        
        if mode in mode_map:
            try:
                os.system(f'sudo nvpmodel -m {mode_map[mode]}')
                print(f"ğŸ”‹ è®¾ç½®åŠŸè€—æ¨¡å¼ä¸º: {mode}")
            except:
                print(f"âš ï¸ æ— æ³•è®¾ç½®åŠŸè€—æ¨¡å¼: {mode}")
    
    def _setup_memory_optimization(self):
        """è®¾ç½®å†…å­˜ä¼˜åŒ–"""
        # å¯ç”¨å†…å­˜æ˜ å°„ä¼˜åŒ–
        import mmap
        
        # è®¾ç½®åƒåœ¾å›æ”¶
        gc.set_threshold(700, 10, 10)
        
        print("ğŸ’¾ å†…å­˜ä¼˜åŒ–è®¾ç½®å®Œæˆ")
    
    def initialize(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        print("ğŸ”§ åˆå§‹åŒ–Jetsonç³»ç»Ÿç»„ä»¶...")
        
        # åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
        try:
            self.yolo_detector = YOLOTRTDetectorJetson(
                model_path=self.config['model_path'],
                conf_thres=self.config['confidence_threshold'],
                use_trt=self.config['use_tensorrt']
            )
            self.yolo_detector.optimize_for_jetson()
            print("âœ… YOLOæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ YOLOæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
        
        # åˆå§‹åŒ–OCR
        try:
            self.ocr_reader = easyocr.Reader(['en'], gpu=True)
            print("âœ… OCRè¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ OCRè¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
        
        return True
    
    def start_processing_thread(self):
        """å¯åŠ¨å‰¯çº¿ç¨‹å¤„ç†"""
        if self.processing_thread and self.processing_thread.is_alive():
            return
        
        self.is_running = True
        self.processing_thread = threading.Thread(target=self._processing_loop_jetson, daemon=True)
        self.processing_thread.start()
        print("ğŸ”„ Jetsonä¼˜åŒ–å‰¯çº¿ç¨‹å¤„ç†å·²å¯åŠ¨")
    
    def _processing_loop_jetson(self):
        """Jetsonä¼˜åŒ–çš„å‰¯çº¿ç¨‹å¤„ç†å¾ªç¯"""
        cleanup_counter = 0
        thermal_check_counter = 0
        
        while self.is_running:
            try:
                # è·å–æ£€æµ‹åŒ…
                detection_pkg = self.detection_queue.get(timeout=1.0)
                
                # æ›´æ–°å¤„ç†çŠ¶æ€
                self.target_processing_status[detection_pkg.target_id] = {
                    'status': 'processing',
                    'start_time': time.time(),
                    'stage': 'orientation_correction'
                }
                
                # å›¾åƒè½¬æ­£
                corrected_image, correction_info = self.orientation_corrector.correct_orientation(
                    detection_pkg.crop_image
                )
                
                # æ›´æ–°çŠ¶æ€
                self.target_processing_status[detection_pkg.target_id]['stage'] = 'ocr_recognition'
                
                # OCRè¯†åˆ«
                ocr_results = []
                detected_number = ""
                
                if correction_info['success']:
                    try:
                        ocr_results = self.ocr_reader.readtext(corrected_image)
                        if ocr_results:
                            detected_number = ''.join([result[1] for result in ocr_results if result[2] > 0.5])
                    except Exception as e:
                        print(f"OCRè¯†åˆ«é”™è¯¯: {e}")
                
                # æ›´æ–°çŠ¶æ€
                self.target_processing_status[detection_pkg.target_id]['stage'] = 'coordinate_calculation'
                
                # GPSåæ ‡è®¡ç®—
                target_lat, target_lon = self.geo_calculator.calculate_target_position(
                    detection_pkg.pixel_center[0],
                    detection_pkg.pixel_center[1], 
                    detection_pkg.flight_data
                )
                
                # åˆ›å»ºå¤„ç†ç»“æœ
                result = {
                    'target_id': detection_pkg.target_id,
                    'frame_id': detection_pkg.frame_id,
                    'timestamp': detection_pkg.timestamp,
                    'original_image': detection_pkg.crop_image,
                    'corrected_image': corrected_image,
                    'correction_info': correction_info,
                    'detected_number': detected_number,
                    'ocr_confidence': max([r[2] for r in ocr_results]) if ocr_results else 0.0,
                    'target_coordinates': {
                        'latitude': target_lat,
                        'longitude': target_lon
                    },
                    'flight_data': asdict(detection_pkg.flight_data),
                    'detection_confidence': detection_pkg.confidence,
                    'processing_time': time.time() - self.target_processing_status[detection_pkg.target_id]['start_time']
                }
                
                # æ·»åŠ åˆ°ç»“æœé˜Ÿåˆ—
                try:
                    self.result_queue.put(result, timeout=1.0)
                    self.processing_results.append(result)
                    
                    # æ›´æ–°å¤„ç†æ˜¾ç¤º
                    self.processing_display[detection_pkg.target_id] = result
                    
                    # æ›´æ–°çŠ¶æ€
                    self.target_processing_status[detection_pkg.target_id] = {
                        'status': 'completed',
                        'completion_time': time.time(),
                        'stage': 'completed'
                    }
                    
                except queue.Full:
                    print("âš ï¸ ç»“æœé˜Ÿåˆ—å·²æ»¡")
                
                # å®šæœŸæ¸…ç†å†…å­˜
                cleanup_counter += 1
                if cleanup_counter >= self.config['memory_cleanup_interval']:
                    self._cleanup_memory()
                    cleanup_counter = 0
                
                # å®šæœŸæ£€æŸ¥æ¸©åº¦
                thermal_check_counter += 1
                if thermal_check_counter >= self.config['thermal_check_interval']:
                    self._check_thermal_throttling()
                    thermal_check_counter = 0
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"å‰¯çº¿ç¨‹å¤„ç†é”™è¯¯: {e}")
    
    def _cleanup_memory(self):
        """æ¸…ç†å†…å­˜"""
        # é™åˆ¶å¤„ç†ç»“æœæ•°é‡
        if len(self.processing_results) > 200:
            self.processing_results = self.processing_results[-100:]
        
        # é™åˆ¶åŸå§‹æ£€æµ‹æ•°é‡
        if len(self.raw_detections) > 500:
            self.raw_detections = self.raw_detections[-300:]
        
        # æ¸…ç†å¤„ç†æ˜¾ç¤º
        if len(self.processing_display) > 50:
            # ä¿ç•™æœ€æ–°çš„20ä¸ª
            latest_keys = list(self.processing_display.keys())[-20:]
            self.processing_display = {k: self.processing_display[k] for k in latest_keys}
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
    
    def _check_thermal_throttling(self):
        """æ£€æŸ¥æ¸©åº¦é™æµ"""
        thermal_status = self.system_monitor.check_thermal_throttling()
        
        if thermal_status['cpu_throttling'] or thermal_status['gpu_throttling']:
            print(f"ğŸŒ¡ï¸ æ¸©åº¦è­¦å‘Š - CPU: {thermal_status['cpu_temp']:.1f}Â°C, GPU: {thermal_status['gpu_temp']:.1f}Â°C")
            
            # è‡ªåŠ¨é™ä½å¤„ç†é¢‘ç‡
            time.sleep(0.1)
    
    def run_video_mission_jetson(self, video_source):
        """è¿è¡ŒJetsonä¼˜åŒ–çš„è§†é¢‘ä»»åŠ¡"""
        print(f"ğŸ¥ å¯åŠ¨Jetsonä¼˜åŒ–è§†é¢‘ä»»åŠ¡: {video_source}")
        
        # åˆå§‹åŒ–è§†é¢‘æ•è·
        cap = cv2.VideoCapture(video_source)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
            return
        
        # è®¾ç½®è§†é¢‘å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
        cap.set(cv2.CAP_PROP_FPS, self.config['max_fps'])
        
        # å¯åŠ¨å‰¯çº¿ç¨‹
        self.start_processing_thread()
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # å¤„ç†å¸§
                self._main_thread_process_jetson(frame)
                
                # æ˜¾ç¤ºç»“æœ
                display_frame = self._draw_jetson_interface(frame)
                cv2.imshow('Jetson SITL Mission', display_frame)
                
                # æŒ‰é”®å¤„ç†
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    self._save_current_data()
                elif key == ord('p'):
                    self._show_performance_stats()
                
        except KeyboardInterrupt:
            print("ğŸ›‘ ç”¨æˆ·ä¸­æ–­")
        finally:
            self._cleanup_jetson(cap)
    
    def _main_thread_process_jetson(self, frame):
        """Jetsonä¼˜åŒ–çš„ä¸»çº¿ç¨‹å¤„ç†"""
        self.frame_count += 1
        current_time = time.time()
        
        # æ¨¡æ‹Ÿé£è¡Œæ•°æ®
        flight_data = FlightData(
            timestamp=current_time,
            latitude=39.7462 + (self.frame_count * 0.0001),
            longitude=116.4166 + (self.frame_count * 0.0001),
            altitude=500.0,
            pitch=-10.0,
            roll=0.0,
            yaw=90.0,
            ground_speed=30.0,
            heading=90.0
        )
        
        # YOLOæ£€æµ‹
        detections = self.yolo_detector.detect(frame)
        
        # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
        for detection in detections:
            self.detection_count += 1
            
            x1, y1, x2, y2 = detection['box']
            confidence = detection['confidence']
            
            # è£å‰ªç›®æ ‡å›¾åƒ
            crop_image = frame[int(y1):int(y2), int(x1):int(x2)]
            if crop_image.size == 0:
                continue
            
            # è®¡ç®—åƒç´ ä¸­å¿ƒ
            pixel_center = ((x1 + x2) / 2, (y1 + y2) / 2)
            
            # åˆ›å»ºæ£€æµ‹åŒ…
            target_id = f"T{self.detection_count:04d}"
            detection_pkg = DetectionPackage(
                frame_id=self.frame_count,
                timestamp=current_time,
                crop_image=crop_image,
                detection_box=(int(x1), int(y1), int(x2), int(y2)),
                pixel_center=pixel_center,
                confidence=confidence,
                flight_data=flight_data,
                target_id=target_id
            )
            
            # è®°å½•åŸå§‹æ£€æµ‹
            self.raw_detections.append({
                'frame_id': self.frame_count,
                'timestamp': current_time,
                'target_id': target_id,
                'detection_box': (int(x1), int(y1), int(x2), int(y2)),
                'confidence': confidence,
                'flight_data': asdict(flight_data)
            })
            
            # å°è¯•æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
            try:
                self.detection_queue.put(detection_pkg, block=False)
                self.target_processing_status[target_id] = {
                    'status': 'queued',
                    'queue_time': current_time,
                    'stage': 'waiting'
                }
            except queue.Full:
                # é˜Ÿåˆ—æ»¡æ—¶ç­‰å¾…
                wait_start = time.time()
                while time.time() - wait_start < self.config['queue_wait_timeout']:
                    try:
                        self.detection_queue.put(detection_pkg, timeout=0.1)
                        break
                    except queue.Full:
                        continue
                else:
                    print(f"âš ï¸ ç›®æ ‡ {target_id} ç­‰å¾…è¶…æ—¶")
    
    def _draw_jetson_interface(self, frame):
        """ç»˜åˆ¶Jetsonä¼˜åŒ–çš„ç•Œé¢"""
        display_frame = frame.copy()
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        system_stats = self.system_monitor.get_system_stats()
        
        # ç»˜åˆ¶ç³»ç»Ÿä¿¡æ¯
        info_y = 30
        cv2.putText(display_frame, f"Jetson Orin Nano - Frame: {self.frame_count}", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        info_y += 25
        cv2.putText(display_frame, f"CPU: {system_stats.get('cpu_temp', 0):.1f}C {system_stats.get('cpu_usage', 0):.1f}%", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        info_y += 25
        cv2.putText(display_frame, f"GPU: {system_stats.get('gpu_temp', 0):.1f}C", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        info_y += 25
        cv2.putText(display_frame, f"Memory: {system_stats.get('memory_usage', 0):.1f}%", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        info_y += 25
        cv2.putText(display_frame, f"Power: {system_stats.get('power_consumption', 0):.1f}W", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ç»˜åˆ¶æ€§èƒ½ç»Ÿè®¡
        perf_stats = self.yolo_detector.get_performance_stats()
        if perf_stats:
            info_y += 25
            cv2.putText(display_frame, f"YOLO FPS: {perf_stats.get('fps', 0):.1f}", 
                       (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        return display_frame
    
    def _show_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        print("\n" + "="*50)
        print("ğŸš€ Jetsonæ€§èƒ½ç»Ÿè®¡")
        print("="*50)
        
        # ç³»ç»Ÿç»Ÿè®¡
        system_stats = self.system_monitor.get_system_stats()
        print(f"CPUæ¸©åº¦: {system_stats.get('cpu_temp', 0):.1f}Â°C")
        print(f"GPUæ¸©åº¦: {system_stats.get('gpu_temp', 0):.1f}Â°C")
        print(f"CPUä½¿ç”¨ç‡: {system_stats.get('cpu_usage', 0):.1f}%")
        print(f"å†…å­˜ä½¿ç”¨ç‡: {system_stats.get('memory_usage', 0):.1f}%")
        print(f"å¯ç”¨å†…å­˜: {system_stats.get('memory_available', 0):.1f}GB")
        print(f"åŠŸè€—: {system_stats.get('power_consumption', 0):.1f}W")
        
        # YOLOæ€§èƒ½
        perf_stats = self.yolo_detector.get_performance_stats()
        if perf_stats:
            print(f"YOLOå¹³å‡æ¨ç†æ—¶é—´: {perf_stats.get('avg_inference_time', 0)*1000:.1f}ms")
            print(f"YOLO FPS: {perf_stats.get('fps', 0):.1f}")
            print(f"ä½¿ç”¨TensorRT: {'æ˜¯' if perf_stats.get('using_tensorrt', False) else 'å¦'}")
        
        # å¤„ç†ç»Ÿè®¡
        print(f"å¤„ç†å¸§æ•°: {self.frame_count}")
        print(f"æ£€æµ‹æ€»æ•°: {self.detection_count}")
        print(f"å‰¯çº¿ç¨‹å¤„ç†: {len(self.processing_results)}")
        
        # è½¬æ­£ç»Ÿè®¡
        correction_stats = self.orientation_corrector.get_stats()
        print(f"è½¬æ­£æˆåŠŸç‡: {correction_stats['successful_corrections']}/{correction_stats['total_processed']}")
        
        print("="*50)
    
    def _save_current_data(self):
        """ä¿å­˜å½“å‰æ•°æ®"""
        timestamp = int(time.time())
        
        # ä¿å­˜åŸå§‹æ£€æµ‹æ•°æ®
        raw_file = f"raw_detections_jetson_{timestamp}.json"
        with open(raw_file, 'w', encoding='utf-8') as f:
            json.dump(self.raw_detections, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜å¤„ç†ç»“æœ
        results_file = f"dual_thread_results_jetson_{timestamp}.json" 
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.processing_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {raw_file}, {results_file}")
    
    def _cleanup_jetson(self, cap):
        """Jetsonç³»ç»Ÿæ¸…ç†"""
        print("ğŸ§¹ æ¸…ç†Jetsonç³»ç»Ÿèµ„æº...")
        
        self.is_running = False
        
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=2.0)
        
        if cap:
            cap.release()
        
        cv2.destroyAllWindows()
        
        # æœ€ç»ˆæ•°æ®ä¿å­˜
        self._save_current_data()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self._show_performance_stats()
        
        print("âœ… Jetsonç³»ç»Ÿæ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Jetsonä¼˜åŒ–çš„åŒçº¿ç¨‹SITLä»»åŠ¡ç³»ç»Ÿ")
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    mission = DualThreadSITLMissionJetson()
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if not mission.initialize():
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        return
    
    # è¿è¡Œè§†é¢‘ä»»åŠ¡
    video_source = 0  # ä½¿ç”¨æ‘„åƒå¤´ï¼Œæˆ–æŒ‡å®šè§†é¢‘æ–‡ä»¶è·¯å¾„
    mission.run_video_mission_jetson(video_source)

if __name__ == "__main__":
    main() 